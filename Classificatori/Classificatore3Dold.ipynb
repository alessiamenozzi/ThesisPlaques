{"cells":[{"cell_type":"markdown","metadata":{},"source":["## import"]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T14:41:29.243721Z","iopub.status.busy":"2024-09-12T14:41:29.243296Z","iopub.status.idle":"2024-09-12T14:41:29.260564Z","shell.execute_reply":"2024-09-12T14:41:29.259665Z","shell.execute_reply.started":"2024-09-12T14:41:29.243682Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","# Import libraries\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import ttest_ind\n","from xgboost import XGBClassifier\n","import statistics\n","\n","sc = StandardScaler()\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["## caricamento dati"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento labels pazienti"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Labels: [0 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0\n"," 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0\n"," 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0\n"," 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1]\n","Number of labels: 129\n","Patient Names:  [5, 12, 15, 16, 17, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 56, 57, 58, 59, 60, 61, 62, 64, 65, 68, 69, 70, 71, 74, 75, 76, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 133, 135, 136, 137, 138, 139, 141, 142, 144, 146, 147, 149, 150, 153, 155, 158, 159, 161, 163, 166, 168, 169, 170, 171, 175, 176, 178, 182, 183, 188, 189, 190, 193, 197, 199, 200, 205]\n"]}],"source":["\n","file_path = \"../CSV/data_rad_clin_DEF.csv\"\n","\n","data = pd.read_csv(file_path)\n","labels_column = data['label']\n","labels = labels_column.astype(int).tolist()\n","\n","labels=np.array(labels)\n","\n","# Estrazione dei numeri dai nomi dei pazienti\n","loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n","\n","print(\"Labels:\", labels)\n","print(\"Number of labels:\", len(labels))\n","print(\"Patient Names: \", loaded_patients )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features encoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","file_path = \"../CSV/Features_VGG16.csv\"\n","df = pd.read_csv(file_path, sep=',')\n","\n","\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","df_features = df_ordered.drop(columns=['Unnamed: 0'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features radiomica"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.576941Z","iopub.status.busy":"2024-09-12T14:41:29.576572Z","iopub.status.idle":"2024-09-12T14:41:29.706641Z","shell.execute_reply":"2024-09-12T14:41:29.705694Z","shell.execute_reply.started":"2024-09-12T14:41:29.576895Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[[6.42638351e-01 4.34811323e-01 1.16096656e+01 ... 2.69972505e+03\n","  2.80963106e-02 1.00514866e+01]\n"," [6.29082835e-01 5.34401455e-01 1.06699125e+01 ... 5.06730171e+03\n","  4.13964322e-02 9.21642811e+00]\n"," [5.33839928e-01 4.15372150e-01 1.11671922e+01 ... 3.95715175e+03\n","  1.13273940e-02 2.75076797e+01]\n"," ...\n"," [4.66390756e-01 3.69394607e-01 1.32282545e+01 ... 1.36263582e+02\n","  6.99679621e-02 4.97074683e-01]\n"," [4.14375204e-01 3.85297007e-01 1.19250944e+01 ... 8.96173941e+03\n","  5.69615647e-02 1.52012405e+01]\n"," [4.85039433e-01 3.32916705e-01 9.71060636e+00 ... 4.02397749e+03\n","  7.17804108e-02 4.97083572e+00]]\n","(129, 107)\n"]}],"source":["\n","file_path=\"../CSV/Radiomica_3D.csv\"\n","df = pd.read_csv(file_path, sep=';')\n","df = df.astype(float)\n","\n","# Colonne da rimuovere SOLO PER RADIOMICA\n","columns_to_remove = [\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","df_cleaned = df.drop(columns=columns_to_remove)\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)  \n"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.774442Z","iopub.status.busy":"2024-09-12T14:41:29.774064Z","iopub.status.idle":"2024-09-12T14:41:29.814876Z","shell.execute_reply":"2024-09-12T14:41:29.813996Z","shell.execute_reply.started":"2024-09-12T14:41:29.774406Z"},"trusted":true},"outputs":[],"source":["\n","## Rimozione feature correlation\n","def remove_highly_correlated_features(X, threshold=0.85):\n","    corr_matrix = np.corrcoef(X, rowvar=False)\n","    upper_triangle = np.triu(corr_matrix, k=1)\n","    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n","    X_reduced = np.delete(X, to_drop, axis=1)\n","    return X_reduced, to_drop\n","\n","## Rimozione features p_value\n","def remove_high_pvalue_features(X, y, alpha=0.05):\n","    selector = SelectKBest(score_func=f_classif, k='all')\n","    selector.fit(X, y)\n","    p_values = selector.pvalues_\n","    features_to_keep = np.where(p_values < alpha)[0]\n","    X_reduced = X[:, features_to_keep]\n","    return X_reduced, features_to_keep\n","\n","## FEATURE SELECTION LASSO\n","def select_features_with_lasso(X, y, alpha=0.001):\n","    \n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X, y)\n","    coefficients = lasso.coef_\n","    selected_features = np.where(coefficients != 0)[0]\n","    X_selected = X[:, selected_features]\n","\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION LOGISTIC\n","def logistic_regression_feature_selection(X, y, num_features):\n","    lr = LogisticRegression(max_iter=1000, random_state=42)\n","    lr.fit(X, y)\n","    coef_abs = np.abs(lr.coef_)\n","    feature_importances = np.mean(coef_abs, axis=0)\n","    selected_features = feature_importances.argsort()[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION MRMR\n","def mrmr_feature_selection(X, y, num_features):\n","    mi = mutual_info_classif(X, y)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n","    \n","    selected_features = []\n","    selected_indices = []\n","\n","    first_feature_index = np.argmax(mi)\n","    selected_features.append(first_feature_index)\n","    selected_indices.append(first_feature_index)\n","    \n","    for _ in range(num_features - 1):\n","        max_relevance = -np.inf\n","        selected_feature_index = -1\n","        \n","        for i in range(X.shape[1]):\n","            if i in selected_indices:\n","                continue\n","            \n","            relevance = mi[i]\n","            redundancy = np.mean(distances[i, selected_indices])\n","            \n","            mrmr_score = relevance - redundancy\n","            \n","            if mrmr_score > max_relevance:\n","                max_relevance = mrmr_score\n","                selected_feature_index = i\n","        \n","        selected_features.append(selected_feature_index)\n","        selected_indices.append(selected_feature_index)\n","\n","    X_selected = X[:, selected_indices]\n","    return X_selected, selected_indices\n","\n","## FEATURE SELECTION RANDOM FOREST\n","def rf_feature_selection(X, y, num_features):\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf.fit(X, y)\n","    feature_importances = rf.feature_importances_\n","    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","\n","## FEATURE SELECTION P_VALUE\n","# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n","# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n","\n","def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n","    p_values = []\n","    num_features_total = x_train_expanded.shape[1]\n","\n","    # Calcolo dei p-value per ciascuna feature\n","    for i in range(num_features_total):\n","        feature = x_train_expanded[:, i]\n","        group_0 = feature[y_train_expanded == 0]\n","        group_1 = feature[y_train_expanded == 1]\n","        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n","        p_values.append(p_val)\n","\n","\n","    p_values = np.array(p_values)\n","\n","    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n","    sorted_indices = np.argsort(p_values)\n","    sorted_indices = sorted_indices[:num_features]\n","\n","    x_train_selected = x_train_expanded[:, sorted_indices]\n","\n","    return x_train_selected, sorted_indices\n","\n","\n","\n","## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n","def filter_patients_features(filtered_patients, selected_features):\n","    filtered_patients_selected = []\n","\n","    for patient_features in filtered_patients:\n","        # Select only the features specified in selected_features\n","        patient_features_selected = patient_features[:, selected_features]\n","        filtered_patients_selected.append(patient_features_selected)\n","\n","    return filtered_patients_selected\n","\n","\n","\n","## FUNZIONE DI CLASSIFICAZIONE\n","def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n","    best_f1_score = 0\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n","        thresholds=[thresholds]\n","        \n","    \n","    for threshold in thresholds:\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            best_precision = precision[np.argmax(recall)]\n","            best_recall = recall[np.argmax(recall)]\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n","                best_f1_score = f1\n","                best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'best_precision': best_precision,\n","                    'best_recall': best_recall,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'best_threshold': threshold\n","                }\n","\n","    return best_case\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## split"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.977584Z","iopub.status.busy":"2024-09-12T14:41:29.977021Z","iopub.status.idle":"2024-09-12T14:41:29.982827Z","shell.execute_reply":"2024-09-12T14:41:29.981953Z","shell.execute_reply.started":"2024-09-12T14:41:29.977546Z"},"trusted":true},"outputs":[],"source":["#y_train1, y_test, x_train1, X_test= train_test_split(Y_train, x_train, test_size=0.2, shuffle=False, random_state=1)\n","#y_train, y_val, X_train, X_val= train_test_split(y_train1, x_train1, test_size=0.3, shuffle=True, stratify=y_train1, random_state=2)\n","#y_train, y_val, X_train, X_val= train_test_split(y_train1, x_train1, test_size=0.3, shuffle=False, random_state=7)\n","\n","Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False, random_state=1)"]},{"cell_type":"markdown","metadata":{},"source":["## correlation e p_value"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.617818Z","iopub.status.busy":"2024-09-12T14:41:30.616974Z","iopub.status.idle":"2024-09-12T14:41:30.650271Z","shell.execute_reply":"2024-09-12T14:41:30.649099Z","shell.execute_reply.started":"2024-09-12T14:41:30.617778Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(90, 37)\n","(39, 37)\n"]}],"source":["\n","## FEATURE CORRELATION\n","\n","X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.9)\n","#X_val_reduced = np.delete(X_val, dropped_features, axis=1)\n","X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n","\n","#print(X_train_reduced.shape)\n","#print(X_test_reduced.shape)\n","#print(X_val_reduced.shape)\n","\n","# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n","\n","#X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train, Y_train, alpha=0.05)\n","#X_val_reduced = X_val_reduced[:, features_to_keep]\n","#X_test_reduced = X_test[:, features_to_keep]\n","\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","#print(X_val_reduced.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## parametri"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.820390Z","iopub.status.busy":"2024-09-12T14:41:30.820019Z","iopub.status.idle":"2024-09-12T14:41:30.825775Z","shell.execute_reply":"2024-09-12T14:41:30.824852Z","shell.execute_reply.started":"2024-09-12T14:41:30.820355Z"},"trusted":true},"outputs":[],"source":["alpha_values = np.linspace(0, 0.006, 30).tolist()\n","\n","thresholds=np.arange(0.4, 0.6, 0.01) \n","\n","\n","selectors=['p_value', 'mrmr','rf', 'logistic', 'lasso']\n","#selectors=['p_value', 'mrmr','rf', 'logistic']\n","\n","classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n","#classifiers = ['MLP']"]},{"cell_type":"markdown","metadata":{},"source":["# CODICE CHE PROVA SUL TEST LA THRESHOLD MIGLIORE (errato)"]},{"cell_type":"markdown","metadata":{},"source":["## loop cross val"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:31.611017Z","iopub.status.busy":"2024-09-12T14:41:31.610666Z"},"trusted":true},"outputs":[],"source":["n_folds=5\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","#scores = []\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'best_precision': None,\n","                'best_recall': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'best_threshold': None,\n","                'selected_features': []\n","            }\n","\n","## creazione di dizionari vuoti (range con numero elevato casuale)\n","results_val = [template_dict.copy() for _ in range(900000)]\n","results_val.append(template_dict.copy())\n","\n","\n","k=0\n","for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    for i, classifier in enumerate(classifiers):\n","        print(\"Starting with classifier:\", classifier)\n","        for j, selector in enumerate(selectors):\n","            print(\"Starting with selector:\", selector)\n","\n","            best_f1 = 0\n","            best_case = None\n","\n","            if(selector=='lasso'):\n","                for alpha in alpha_values:\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                    \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    best_case = classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, num_features=0, mode=\"Val\", selected_features=[0], thresholds=thresholds)\n","\n","                    if best_case:\n","                        results_val[k]['fold']=fold_idx\n","                        results_val[k]['classifier']=classifier\n","                        results_val[k]['selector']=selector\n","                        results_val[k]['alpha']=best_case['alpha']\n","                        results_val[k]['selected_features']=best_case['selected_features']\n","                        results_val[k]['pr_auc']=best_case['pr_auc']\n","                        results_val[k]['best_precision']=best_case['best_precision']\n","                        results_val[k]['best_recall']=best_case['best_recall']\n","                        results_val[k]['roc_auc']=best_case['roc_auc']\n","                        results_val[k]['f1']=best_case['f1']\n","                        results_val[k]['accuracy']=best_case['accuracy']\n","                        results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                        results_val[k]['threshold']=best_case['best_threshold']\n","\n","                        k=k+1\n","            \n","            else: \n","                limit=len(x_train_reduced[0]) + 1\n","                for t in range(1, limit):\n","                    #print(\"Number of features \", t)\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                        \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    best_case = classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n","\n","\n","                    if best_case:\n","                        results_val[k]['num_features']=best_case['num_features']\n","                        results_val[k]['fold']=fold_idx\n","                        results_val[k]['classifier']=classifier\n","                        results_val[k]['selector']=selector\n","                        results_val[k]['selected_features']=best_case['selected_features']\n","                        results_val[k]['pr_auc']=best_case['pr_auc']\n","                        results_val[k]['best_precision']=best_case['best_precision']\n","                        results_val[k]['best_recall']=best_case['best_recall']\n","                        results_val[k]['roc_auc']=best_case['roc_auc']\n","                        results_val[k]['f1']=best_case['f1']\n","                        results_val[k]['accuracy']=best_case['accuracy']\n","                        results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                        results_val[k]['best_threshold']=best_case['best_threshold']\n","                        k=k+1\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_val\n"]},{"cell_type":"markdown","metadata":{},"source":["## trova configurazione migliore con gridsearch\n","fa una lista di tutte le combinazioni di configurazioni dalla migliore (considerando average f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import statistics\n","\n","# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value', 'lasso']\n","#num_features_range = list(range(2, len(X_train_reduced[0]) + 1))\n","num_features_range=list(range(1,50))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features)\n","for classifier in classifiers:\n","    print(f\"sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        print(f\"sto iniziando selector {selector}\")\n","\n","        if (selector)=='lasso':\n","            for alpha in alpha_values:\n","                filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha]\n","\n","                if filtered_results:\n","                    pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                    f1_values = [res['f1'] for res in filtered_results]\n","                    accuracy_values = [res['accuracy'] for res in filtered_results]\n","                    \n","                    # Calcola le medie delle metriche\n","                    avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                    avg_f1 = sum(f1_values) / len(f1_values)\n","                    avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","                    \n","                    # Calcola la deviazione standard delle metriche\n","                    std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                    std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                    std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","                    \n","                    # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                    grid_results[(classifier, selector, alpha)] = {\n","                        'avg_pr_auc': avg_pr_auc,\n","                        'std_pr_auc': std_pr_auc,\n","                        'avg_f1': avg_f1,\n","                        'std_f1': std_f1,\n","                        'avg_accuracy': avg_accuracy,\n","                        'std_accuracy': std_accuracy\n","                    }\n","        \n","        else:\n","            for num_features in num_features_range:\n","                # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features]\n","                \n","                if filtered_results:\n","                    pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                    f1_values = [res['f1'] for res in filtered_results]\n","                    accuracy_values = [res['accuracy'] for res in filtered_results]\n","                    \n","                    # Calcola le medie delle metriche\n","                    avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                    avg_f1 = sum(f1_values) / len(f1_values)\n","                    avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","                    \n","                    # Calcola la deviazione standard delle metriche\n","                    std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                    std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                    std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","                    \n","                    # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                    grid_results[(classifier, selector, num_features)] = {\n","                        'avg_pr_auc': avg_pr_auc,\n","                        'std_pr_auc': std_pr_auc,\n","                        'avg_f1': avg_f1,\n","                        'std_f1': std_f1,\n","                        'avg_accuracy': avg_accuracy,\n","                        'std_accuracy': std_accuracy\n","                    }\n","\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']), reverse=True)"]},{"cell_type":"markdown","metadata":{},"source":["## salvataggio array"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Salva il dizionario in un file pickle\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_5foldVGG_max50_0.3', 'wb') as pickle_file:\n","    pickle.dump(sorted_results, pickle_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carica il dizionario dal file pickle\n","\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_5foldVGG_max50_0.3', 'rb') as pickle_file:\n","    sorted_results = pickle.load(pickle_file)\n","\n","# Ora 'results_val' contiene i dati che hai salvato\n","print(\"Dati caricati correttamente:\", type(sorted_results))"]},{"cell_type":"markdown","metadata":{},"source":["## Stampa n risultati migliori per validation + performance su test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:28:28.238893Z","iopub.status.idle":"2024-09-12T14:28:28.239275Z","shell.execute_reply":"2024-09-12T14:28:28.239084Z","shell.execute_reply.started":"2024-09-12T14:28:28.239066Z"},"trusted":true},"outputs":[],"source":["n=10\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    #thresholds=np.arange(0.4, 0.6, 0.01)\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n","    print(f\"Best Threshold: {best_case['best_threshold']}\")"]},{"cell_type":"markdown","metadata":{},"source":["## codice che prende solo le configurazioni migliori per il test con una soglia di f1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["threshold_f1 = 0.6 # soglia minima dell'F1 Score\n","best_combination_found = False  # Flag per indicare se è stata trovata una buona combinazione\n","i = 0\n","\n","while not best_combination_found and i < len(sorted_results):\n","    params, metrics = sorted_results[i]\n","\n","    if params[0] == 'RandomForest':\n","        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","        classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","        classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","        logistic_model = LogisticRegression(random_state=42)\n","        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","        classi = VotingClassifier(\n","            estimators=[\n","                ('random_forest', rf_model),\n","                ('logistic', logistic_model),\n","                ('svc', svc_model)\n","            ],\n","            voting='soft'\n","        )\n","\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.3, 0.6, 0.01))\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=np.arange(0.3, 0.6, 0.01))\n","\n","\n","    # Controlla se l'F1 Score supera la soglia\n","    if best_case['f1'] >= threshold_f1:\n","        print(f\"\\n#Analizzando combinazione {i + 1}:\")\n","        print(f\"Classifier: {params[0]}\")\n","        print(f\"Selector: {params[1]}\")\n","        if(params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","        else: \n","            print(f\"Num_features: {params[2]}\")\n","\n","        print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","        #print(f\"\\nTrovata una combinazione con F1 Score >= {threshold_f1}\")\n","        \n","        #best_combination_found = True\n","        print(\"Metrics from best_case ON THE TEST SET:\")\n","        if(params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","        print(f\"Number of Features: {best_case['num_features']}\")\n","        print(f\"Selected Features: {best_case['selected_features']}\")\n","        print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","        #print(f\"Best Precision: {best_case['best_precision']}\")\n","        #print(f\"Best Recall: {best_case['best_recall']}\")\n","        print(f\"ROC AUC: {best_case['roc_auc']}\")\n","        print(f\"F1 Score: {best_case['f1']}\")\n","        print(f\"Accuracy: {best_case['accuracy']}\")\n","        print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n","        print(f\"Best Threshold: {best_case['best_threshold']}\")\n","        i += 1\n","    else:\n","        i += 1  # Passa alla prossima combinazione\n","\n","if not best_combination_found:\n","    print(f\"\\nNessuna combinazione con F1 Score >= {threshold_f1} è stata trovata.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## PLOT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Crea un pivot per visualizzare i dati nella heatmap\n","results_df = pd.DataFrame(results_val)\n","heatmap_data = results_df.pivot_table(index='classifier', columns='selector', values='f1', aggfunc='mean')\n","\n","# Crea la heatmap\n","plt.figure(figsize=(10, 6))\n","sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".3f\")\n","plt.title('F1-score medio per combinazione di Classifier e Selector')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Converto i risultati in un DataFrame per visualizzare meglio\n","results_df = pd.DataFrame(results_val)\n","\n","# Crea un boxplot per l'F1-score\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='classifier', y='f1', data=results_df)\n","plt.title('Distribuzione degli F1-score per ogni classificatore')\n","plt.show()\n","\n","# Crea un boxplot per PR AUC\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='classifier', y='pr_auc', data=results_df)\n","plt.title('Distribuzione di PR AUC per ogni classificatore')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# codice tuning threshold NON DINAMICA"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni diverse"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            best_precision = precision[np.argmax(recall)]\n","            best_recall = recall[np.argmax(recall)]\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'best_precision': best_precision,\n","                    'best_recall': best_recall,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold\n","                }\n","                \n","            if not best_case:\n","                 print(\"Attenzione caso vuoto\") \n","            return best_case\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Loop validation"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting with fold: 0\n","Numero di 0 nel train: 10\n","Numero di 1 nel train: 8\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 1\n","Numero di 0 nel train: 10\n","Numero di 1 nel train: 8\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 2\n","Numero di 0 nel train: 10\n","Numero di 1 nel train: 8\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 3\n","Numero di 0 nel train: 10\n","Numero di 1 nel train: 8\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with fold: 4\n","Numero di 0 nel train: 9\n","Numero di 1 nel train: 9\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: SVM\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: ensemble\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: RandomForest\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: Logistic\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n","Starting with classifier: MLP\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n"]}],"source":["n_folds=5\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","thresholds=np.arange(0.42, 0.6, 0.01) \n","\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'best_precision': None,\n","                'best_recall': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'threshold': None,\n","                'selected_features': []\n","            }\n","\n","## creazione di dizionari vuoti (range con numero elevato casuale)\n","results_val = [template_dict.copy() for _ in range(300000)]\n","results_val.append(template_dict.copy())\n","\n","smote = SMOTE()\n","\n","k=0\n","old_count = 0\n","for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_red, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train_red, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    x_train_reduced, y_train = smote.fit_resample(x_train_red, y_train_red)\n","\n","    zero_count = np.sum(y_val == 0)\n","    one_count = np.sum(y_val == 1)\n","\n","    print(f\"Numero di 0 nel train: {zero_count}\")\n","    print(f\"Numero di 1 nel train: {one_count}\")\n","\n","    for i, classifier in enumerate(classifiers):\n","        print(\"Starting with classifier:\", classifier)\n","        for j, selector in enumerate(selectors):\n","            print(\"Starting with selector:\", selector)\n","            \n","            if(selector=='lasso'):\n","                for alpha in alpha_values:\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, num_features=0, mode=\"Val\", selected_features=[0])\n","\n","                    # Variabili per tenere traccia del miglior F1 score e threshold\n","                    best_f1 = -1\n","                    best_case = None\n","                    best_threshold = 0\n","\n","                    # Itera su tutte le soglie e trova la migliore\n","                    for threshold in thresholds:\n","                        current_case = classification_threshold(y_proba_test, y_val, threshold, alpha, 0, selected_features)\n","                        \n","                        if current_case['f1'] > best_f1:\n","                            best_threshold = threshold\n","                            best_f1 = current_case['f1']\n","                            best_case = current_case\n","                    \n","                    # Salva solo il miglior caso dopo aver iterato su tutte le soglie\n","                    if best_case:\n","                        results_val[k] = {\n","                            'fold': fold_idx,\n","                            'classifier': classifier,\n","                            'selector': selector,\n","                            'alpha': best_case['alpha'],\n","                            'num_features': number_features,\n","                            'selected_features': best_case['selected_features'],\n","                            'pr_auc': best_case['pr_auc'],\n","                            'best_precision': best_case['best_precision'],\n","                            'best_recall': best_case['best_recall'],\n","                            'roc_auc': best_case['roc_auc'],\n","                            'f1': best_case['f1'],\n","                            'accuracy': best_case['accuracy'],\n","                            'confusion_matrix': best_case['confusion_matrix'],\n","                            'threshold': best_threshold\n","                        }\n","                        k = k + 1\n","            \n","            else: \n","                limit=len(x_train_reduced[0]) + 1\n","                \n","                for t in range(1, limit):\n","                    #print(\"Number of features \", t)\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation='logistic')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n","        \n","                    # Variabili per tenere traccia del miglior F1 score e threshold\n","                    best_f1 = -1\n","                    best_case = None\n","                    best_threshold = 0\n","                    # Itera su tutte le soglie e trova la migliore\n","                    for threshold in thresholds:\n","                        current_case = classification_threshold(y_proba_test, y_val, threshold, 0, t, selected_features)\n","                        if current_case['f1'] > best_f1:\n","                            best_threshold = threshold\n","                            best_f1 = current_case['f1']\n","                            best_case = current_case\n","                            \n","                    \n","                    # Salva solo il miglior caso dopo aver iterato su tutte le soglie\n","                    if best_case:\n","                        results_val[k] = {\n","                            'fold': fold_idx,\n","                            'classifier': classifier,\n","                            'selector': selector,\n","                            'alpha': 0,\n","                            'num_features': t,\n","                            'selected_features': best_case['selected_features'],\n","                            'pr_auc': best_case['pr_auc'],\n","                            'best_precision': best_case['best_precision'],\n","                            'best_recall': best_case['best_recall'],\n","                            'roc_auc': best_case['roc_auc'],\n","                            'f1': best_case['f1'],\n","                            'accuracy': best_case['accuracy'],\n","                            'confusion_matrix': best_case['confusion_matrix'],\n","                            'threshold': best_threshold\n","                        }\n","                        k = k + 1\n","                    else:\n","                        print('saltata', t)\n","\n","            #count = sum(1 for result in results_val if result['f1'] is not None)\n","            #print(count - old_count)\n","            #if (((count - old_count) != 30)):\n","            #    if((count- old_count) != 22):\n","            #        print(\"ERRORE\")\n","            #old_count = count\n","            #print(f\"Count of non-None 'f1': {count}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## sorted_results che itera su tutte le threshold NO LASSO"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sto iniziando classifier SVM\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier RandomForest\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier ensemble\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier XgBoost\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier Logistic\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier MLP\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n"]}],"source":["# Definizione delle possibili configurazioni di classificatori, selettori e numero di features\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value']\n","thresholds = np.arange(0.42, 0.6, 0.01) \n","num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                for threshold in thresholds:\n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val:\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features and res['threshold'] == threshold):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results[(classifier, selector, num_features, threshold)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy\n","                        }\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']),reverse=True)"]},{"cell_type":"markdown","metadata":{},"source":["## sorted_results che non itera su tutte le threshold NO LASSO"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sto iniziando classifier SVM\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier RandomForest\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier ensemble\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier XgBoost\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier Logistic\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier MLP\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n"]}],"source":["# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value']\n","thresholds = np.arange(0.42, 0.6, 0.01) \n","num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                    filtered_results=[]\n","                    for res in results_val:\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","                        thresholds_values = [res['threshold'] for res in filtered_results] \n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        avg_threshold = sum(thresholds_values) / len(thresholds_values) ## trova la media delle threshold per i vari fold\n","\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results[(classifier, selector, num_features)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy,\n","                            'avg_threshold': avg_threshold\n","                        }\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']),reverse=True)"]},{"cell_type":"markdown","metadata":{},"source":["## mostrando le n migliori configurazioni per validation NO LASSO e applicandole al test"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(('SVM', 'p_value', 6), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.496}), (('SVM', 'p_value', 7), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.496}), (('SVM', 'p_value', 8), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.49399999999999994}), (('SVM', 'p_value', 9), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.49399999999999994}), (('SVM', 'p_value', 10), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.49800000000000005}), (('SVM', 'p_value', 11), {'avg_pr_auc': 0.7708333333333333, 'std_pr_auc': 0.035067725480423875, 'avg_f1': 0.7133333333333332, 'std_f1': 0.050552502960343706, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.04969039949999535, 'avg_threshold': 0.49800000000000005}), (('SVM', 'p_value', 4), {'avg_pr_auc': 0.7705128205128206, 'std_pr_auc': 0.04765304594293745, 'avg_f1': 0.7113725490196077, 'std_f1': 0.06487500180566387, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.08425417160057279, 'avg_threshold': 0.492}), (('SVM', 'p_value', 5), {'avg_pr_auc': 0.7705128205128206, 'std_pr_auc': 0.04765304594293745, 'avg_f1': 0.7113725490196077, 'std_f1': 0.06487500180566387, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.08425417160057279, 'avg_threshold': 0.492}), (('SVM', 'rf', 11), {'avg_pr_auc': 0.7675213675213675, 'std_pr_auc': 0.03992389998273281, 'avg_f1': 0.7053679653679652, 'std_f1': 0.05630502135685314, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.06804138174397716, 'avg_threshold': 0.4720000000000001}), (('SVM', 'rf', 12), {'avg_pr_auc': 0.7675213675213675, 'std_pr_auc': 0.03992389998273281, 'avg_f1': 0.7053679653679652, 'std_f1': 0.05630502135685314, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.06804138174397716, 'avg_threshold': 0.4720000000000001}), (('SVM', 'rf', 13), {'avg_pr_auc': 0.7675213675213675, 'std_pr_auc': 0.03992389998273281, 'avg_f1': 0.7053679653679652, 'std_f1': 0.05630502135685314, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.06804138174397716, 'avg_threshold': 0.4720000000000001}), (('Logistic', 'rf', 4), {'avg_pr_auc': 0.7677994227994228, 'std_pr_auc': 0.04768681500056514, 'avg_f1': 0.7042341030441717, 'std_f1': 0.0641592133990826, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.06804138174397716, 'avg_threshold': 0.47000000000000003}), (('SVM', 'p_value', 20), {'avg_pr_auc': 0.7646428571428572, 'std_pr_auc': 0.03781034968711384, 'avg_f1': 0.7016161616161616, 'std_f1': 0.054637034978722986, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.4800000000000001}), (('SVM', 'p_value', 12), {'avg_pr_auc': 0.7625, 'std_pr_auc': 0.043200919486099394, 'avg_f1': 0.7006060606060605, 'std_f1': 0.0615606638623227, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.48600000000000004}), (('SVM', 'p_value', 13), {'avg_pr_auc': 0.7625, 'std_pr_auc': 0.043200919486099394, 'avg_f1': 0.7006060606060605, 'std_f1': 0.0615606638623227, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.48600000000000004}), (('SVM', 'p_value', 14), {'avg_pr_auc': 0.7625, 'std_pr_auc': 0.043200919486099394, 'avg_f1': 0.7006060606060605, 'std_f1': 0.0615606638623227, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.48600000000000004}), (('SVM', 'p_value', 15), {'avg_pr_auc': 0.7625, 'std_pr_auc': 0.043200919486099394, 'avg_f1': 0.7006060606060605, 'std_f1': 0.0615606638623227, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.48600000000000004}), (('SVM', 'p_value', 16), {'avg_pr_auc': 0.7625, 'std_pr_auc': 0.043200919486099394, 'avg_f1': 0.7006060606060605, 'std_f1': 0.0615606638623227, 'avg_accuracy': 0.6666666666666666, 'std_accuracy': 0.07856742013183861, 'avg_threshold': 0.48600000000000004}), (('SVM', 'p_value', 1), {'avg_pr_auc': 0.7652056277056277, 'std_pr_auc': 0.06811186305299156, 'avg_f1': 0.697822966507177, 'std_f1': 0.08322025744818658, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.1009216784699164, 'avg_threshold': 0.47800000000000004}), (('SVM', 'p_value', 3), {'avg_pr_auc': 0.7607905982905983, 'std_pr_auc': 0.055436519828175095, 'avg_f1': 0.6963725490196078, 'std_f1': 0.07589622156286954, 'avg_accuracy': 0.6888888888888889, 'std_accuracy': 0.08425417160057279, 'avg_threshold': 0.502}), (('SVM', 'logistic', 20), {'avg_pr_auc': 0.7579761904761905, 'std_pr_auc': 0.04354184636337405, 'avg_f1': 0.6945986177565124, 'std_f1': 0.06200471139017067, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.08240220541217402, 'avg_threshold': 0.47000000000000003}), (('Logistic', 'p_value', 1), {'avg_pr_auc': 0.7600602665308548, 'std_pr_auc': 0.0174553284761758, 'avg_f1': 0.6936292906178491, 'std_f1': 0.03461292465765969, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.08240220541217402, 'avg_threshold': 0.49400000000000005}), (('Logistic', 'logistic', 3), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.058157745815575056, 'avg_f1': 0.6933827321928009, 'std_f1': 0.07804323342108109, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.09128709291752767, 'avg_threshold': 0.44400000000000006}), (('SVM', 'rf', 9), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.4640000000000001}), (('SVM', 'rf', 10), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.46799999999999997}), (('SVM', 'rf', 14), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.4720000000000001}), (('SVM', 'rf', 15), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.4720000000000001}), (('SVM', 'p_value', 17), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.466}), (('SVM', 'p_value', 18), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.466}), (('SVM', 'p_value', 19), {'avg_pr_auc': 0.7573717948717948, 'std_pr_auc': 0.03301048659910262, 'avg_f1': 0.6929870129870129, 'std_f1': 0.04676266539728635, 'avg_accuracy': 0.6555555555555556, 'std_accuracy': 0.060858061945018437, 'avg_threshold': 0.45600000000000007})]\n","Migliori 30 combinazioni di parametri:\n","\n","#1:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 6\n","Threshold: 0.496\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 6\n","Threshold: 0.496\n","Selected Features: [19 18 12 14  7  0]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#2:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.496\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.496\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#3:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 8\n","Threshold: 0.49399999999999994\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 8\n","Threshold: 0.49399999999999994\n","Selected Features: [19 18 12 14  7  0  8 20]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#4:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 9\n","Threshold: 0.49399999999999994\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 9\n","Threshold: 0.49399999999999994\n","Selected Features: [19 18 12 14  7  0  8 20 13]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#5:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 10\n","Threshold: 0.49800000000000005\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 10\n","Threshold: 0.49800000000000005\n","Selected Features: [19 18 12 14  7  0  8 20 13  2]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#6:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 11\n","Threshold: 0.49800000000000005\n","Performance medie: F1 = 0.7133333333333332 (std = 0.050552502960343706), PR AUC = 0.7708333333333333 (std = 0.035067725480423875), Accuracy = 0.6888888888888889 (std = 0.04969039949999535)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 11\n","Threshold: 0.49800000000000005\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#7:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 4\n","Threshold: 0.492\n","Performance medie: F1 = 0.7113725490196077 (std = 0.06487500180566387), PR AUC = 0.7705128205128206 (std = 0.04765304594293745), Accuracy = 0.6888888888888889 (std = 0.08425417160057279)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 4\n","Threshold: 0.492\n","Selected Features: [19 18 12 14]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#8:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 5\n","Threshold: 0.492\n","Performance medie: F1 = 0.7113725490196077 (std = 0.06487500180566387), PR AUC = 0.7705128205128206 (std = 0.04765304594293745), Accuracy = 0.6888888888888889 (std = 0.08425417160057279)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 5\n","Threshold: 0.492\n","Selected Features: [19 18 12 14  7]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#9:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 11\n","Threshold: 0.4720000000000001\n","Performance medie: F1 = 0.7053679653679652 (std = 0.05630502135685314), PR AUC = 0.7675213675213675 (std = 0.03992389998273281), Accuracy = 0.6666666666666666 (std = 0.06804138174397716)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 11\n","Threshold: 0.4720000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10]\n","Precision-Recall AUC: 0.5951417004048583\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296295\n","F1 Score: 0.5161290322580645\n","Accuracy: 0.6153846153846154\n","Confusion Matrix: \n","[[16 11]\n"," [ 4  8]]\n","\n","#10:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 12\n","Threshold: 0.4720000000000001\n","Performance medie: F1 = 0.7053679653679652 (std = 0.05630502135685314), PR AUC = 0.7675213675213675 (std = 0.03992389998273281), Accuracy = 0.6666666666666666 (std = 0.06804138174397716)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 12\n","Threshold: 0.4720000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14]\n","Precision-Recall AUC: 0.5951417004048583\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296295\n","F1 Score: 0.5161290322580645\n","Accuracy: 0.6153846153846154\n","Confusion Matrix: \n","[[16 11]\n"," [ 4  8]]\n","\n","#11:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 13\n","Threshold: 0.4720000000000001\n","Performance medie: F1 = 0.7053679653679652 (std = 0.05630502135685314), PR AUC = 0.7675213675213675 (std = 0.03992389998273281), Accuracy = 0.6666666666666666 (std = 0.06804138174397716)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 13\n","Threshold: 0.4720000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14 13]\n","Precision-Recall AUC: 0.5951417004048583\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296295\n","F1 Score: 0.5161290322580645\n","Accuracy: 0.6153846153846154\n","Confusion Matrix: \n","[[16 11]\n"," [ 4  8]]\n","\n","#12:\n","Classifier: Logistic\n","Selector: rf\n","Num_features: 4\n","Threshold: 0.47000000000000003\n","Performance medie: F1 = 0.7042341030441717 (std = 0.0641592133990826), PR AUC = 0.7677994227994228 (std = 0.04768681500056514), Accuracy = 0.6666666666666666 (std = 0.06804138174397716)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 4\n","Threshold: 0.47000000000000003\n","Selected Features: [19 18 15  9]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#13:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 20\n","Threshold: 0.4800000000000001\n","Performance medie: F1 = 0.7016161616161616 (std = 0.054637034978722986), PR AUC = 0.7646428571428572 (std = 0.03781034968711384), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 20\n","Threshold: 0.4800000000000001\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15 10  3 11  1  4]\n","Precision-Recall AUC: 0.6199095022624435\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6666666666666667\n","F1 Score: 0.5517241379310345\n","Accuracy: 0.6666666666666666\n","Confusion Matrix: \n","[[18  9]\n"," [ 4  8]]\n","\n","#14:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 12\n","Threshold: 0.48600000000000004\n","Performance medie: F1 = 0.7006060606060605 (std = 0.0615606638623227), PR AUC = 0.7625 (std = 0.043200919486099394), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 12\n","Threshold: 0.48600000000000004\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#15:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 13\n","Threshold: 0.48600000000000004\n","Performance medie: F1 = 0.7006060606060605 (std = 0.0615606638623227), PR AUC = 0.7625 (std = 0.043200919486099394), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 13\n","Threshold: 0.48600000000000004\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#16:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 14\n","Threshold: 0.48600000000000004\n","Performance medie: F1 = 0.7006060606060605 (std = 0.0615606638623227), PR AUC = 0.7625 (std = 0.043200919486099394), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 14\n","Threshold: 0.48600000000000004\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#17:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 15\n","Threshold: 0.48600000000000004\n","Performance medie: F1 = 0.7006060606060605 (std = 0.0615606638623227), PR AUC = 0.7625 (std = 0.043200919486099394), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 15\n","Threshold: 0.48600000000000004\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15]\n","Precision-Recall AUC: 0.6199095022624435\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6666666666666667\n","F1 Score: 0.5517241379310345\n","Accuracy: 0.6666666666666666\n","Confusion Matrix: \n","[[18  9]\n"," [ 4  8]]\n","\n","#18:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 16\n","Threshold: 0.48600000000000004\n","Performance medie: F1 = 0.7006060606060605 (std = 0.0615606638623227), PR AUC = 0.7625 (std = 0.043200919486099394), Accuracy = 0.6666666666666666 (std = 0.07856742013183861)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 16\n","Threshold: 0.48600000000000004\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15 10]\n","Precision-Recall AUC: 0.5745192307692308\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6250000000000001\n","F1 Score: 0.5\n","Accuracy: 0.6410256410256411\n","Confusion Matrix: \n","[[18  9]\n"," [ 5  7]]\n","\n","#19:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 1\n","Threshold: 0.47800000000000004\n","Performance medie: F1 = 0.697822966507177 (std = 0.08322025744818658), PR AUC = 0.7652056277056277 (std = 0.06811186305299156), Accuracy = 0.6888888888888889 (std = 0.1009216784699164)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 1\n","Threshold: 0.47800000000000004\n","Selected Features: [19]\n","Precision-Recall AUC: 0.43696581196581197\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.46759259259259267\n","F1 Score: 0.3333333333333333\n","Accuracy: 0.48717948717948717\n","Confusion Matrix: \n","[[14 13]\n"," [ 7  5]]\n","\n","#20:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 3\n","Threshold: 0.502\n","Performance medie: F1 = 0.6963725490196078 (std = 0.07589622156286954), PR AUC = 0.7607905982905983 (std = 0.055436519828175095), Accuracy = 0.6888888888888889 (std = 0.08425417160057279)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 3\n","Threshold: 0.502\n","Selected Features: [19 18 12]\n","Precision-Recall AUC: 0.5846153846153845\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6111111111111112\n","F1 Score: 0.5\n","Accuracy: 0.5897435897435898\n","Confusion Matrix: \n","[[15 12]\n"," [ 4  8]]\n","\n","#21:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 20\n","Threshold: 0.47000000000000003\n","Performance medie: F1 = 0.6945986177565124 (std = 0.06200471139017067), PR AUC = 0.7579761904761905 (std = 0.04354184636337405), Accuracy = 0.6555555555555556 (std = 0.08240220541217402)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 20\n","Threshold: 0.47000000000000003\n","Selected Features: [16  7  1  0  9  3 14 20  2  5  6  8 19 11 12 10  4 17 13 18]\n","Precision-Recall AUC: 0.575091575091575\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5925925925925926\n","F1 Score: 0.48484848484848486\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[14 13]\n"," [ 4  8]]\n","\n","#22:\n","Classifier: Logistic\n","Selector: p_value\n","Num_features: 1\n","Threshold: 0.49400000000000005\n","Performance medie: F1 = 0.6936292906178491 (std = 0.03461292465765969), PR AUC = 0.7600602665308548 (std = 0.0174553284761758), Accuracy = 0.6222222222222222 (std = 0.08240220541217402)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 1\n","Threshold: 0.49400000000000005\n","Selected Features: [19]\n","Precision-Recall AUC: 0.6538461538461539\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[27  0]\n"," [12  0]]\n","\n","#23:\n","Classifier: Logistic\n","Selector: logistic\n","Num_features: 3\n","Threshold: 0.44400000000000006\n","Performance medie: F1 = 0.6933827321928009 (std = 0.07804323342108109), PR AUC = 0.7573717948717948 (std = 0.058157745815575056), Accuracy = 0.6555555555555556 (std = 0.09128709291752767)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 3\n","Threshold: 0.44400000000000006\n","Selected Features: [16  7  1]\n","Precision-Recall AUC: 0.4067725752508361\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.37500000000000006\n","F1 Score: 0.2857142857142857\n","Accuracy: 0.358974358974359\n","Confusion Matrix: \n","[[ 9 18]\n"," [ 7  5]]\n","\n","#24:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 9\n","Threshold: 0.4640000000000001\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 9\n","Threshold: 0.4640000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20]\n","Precision-Recall AUC: 0.5664335664335665\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5740740740740741\n","F1 Score: 0.47058823529411764\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[13 14]\n"," [ 4  8]]\n","\n","#25:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 10\n","Threshold: 0.46799999999999997\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 10\n","Threshold: 0.46799999999999997\n","Selected Features: [19 18 15  9  4  6  2  0 20  7]\n","Precision-Recall AUC: 0.575091575091575\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5925925925925926\n","F1 Score: 0.48484848484848486\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[14 13]\n"," [ 4  8]]\n","\n","#26:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 14\n","Threshold: 0.4720000000000001\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 14\n","Threshold: 0.4720000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14 13  8]\n","Precision-Recall AUC: 0.5951417004048583\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296295\n","F1 Score: 0.5161290322580645\n","Accuracy: 0.6153846153846154\n","Confusion Matrix: \n","[[16 11]\n"," [ 4  8]]\n","\n","#27:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 15\n","Threshold: 0.4720000000000001\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 15\n","Threshold: 0.4720000000000001\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14 13  8 16]\n","Precision-Recall AUC: 0.5951417004048583\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296295\n","F1 Score: 0.5161290322580645\n","Accuracy: 0.6153846153846154\n","Confusion Matrix: \n","[[16 11]\n"," [ 4  8]]\n","\n","#28:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 17\n","Threshold: 0.466\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 17\n","Threshold: 0.466\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15 10  3]\n","Precision-Recall AUC: 0.575091575091575\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5925925925925926\n","F1 Score: 0.48484848484848486\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[14 13]\n"," [ 4  8]]\n","\n","#29:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 18\n","Threshold: 0.466\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 18\n","Threshold: 0.466\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15 10  3 11]\n","Precision-Recall AUC: 0.575091575091575\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5925925925925926\n","F1 Score: 0.48484848484848486\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[14 13]\n"," [ 4  8]]\n","\n","#30:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 19\n","Threshold: 0.45600000000000007\n","Performance medie: F1 = 0.6929870129870129 (std = 0.04676266539728635), PR AUC = 0.7573717948717948 (std = 0.03301048659910262), Accuracy = 0.6555555555555556 (std = 0.060858061945018437)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 19\n","Threshold: 0.45600000000000007\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6 17 15 10  3 11  1]\n","Precision-Recall AUC: 0.5664335664335665\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5740740740740741\n","F1 Score: 0.47058823529411764\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[13 14]\n"," [ 4  8]]\n"]}],"source":["n=30\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Threshold: {metrics['avg_threshold']}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","   \n","     \n","    best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=metrics['avg_threshold'])\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {metrics['avg_threshold']}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## sorted_results che itera su tutte le threshold LASSO"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sto iniziando classifier SVM\n","Sto iniziando selector lasso\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[101], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alpha_values:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;66;03m# Filtra i risultati che corrispondono a questa combinazione di parametri\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m             filtered_results \u001b[38;5;241m=\u001b[39m [res \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results_val \u001b[38;5;28;01mif\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m classifier \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m selector \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m alpha \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m threshold]\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m filtered_results:\n\u001b[0;32m     20\u001b[0m                 pr_auc_values \u001b[38;5;241m=\u001b[39m [res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr_auc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m filtered_results]\n","Cell \u001b[1;32mIn[101], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m alpha_values:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[0;32m     15\u001b[0m             \u001b[38;5;66;03m# Filtra i risultati che corrispondono a questa combinazione di parametri\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m             filtered_results \u001b[38;5;241m=\u001b[39m [res \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results_val \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m selector \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m alpha \u001b[38;5;129;01mand\u001b[39;00m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m threshold]\n\u001b[0;32m     18\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m filtered_results:\n\u001b[0;32m     20\u001b[0m                 pr_auc_values \u001b[38;5;241m=\u001b[39m [res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpr_auc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m filtered_results]\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['lasso']\n","thresholds = np.arange(0.42, 0.6, 0.01) \n","\n","grid_results_lasso = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        print(f\"Sto iniziando selector {selector}\")\n","        for alpha in alpha_values:\n","                for threshold in thresholds:\n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha and res['threshold'] == threshold]\n","\n","                    if filtered_results:\n","                        \n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results_lasso[(classifier, selector, alpha, threshold)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy\n","                        }\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results_lasso = sorted(grid_results_lasso.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']),reverse=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["## mostrando le n migliori configurazioni per validation LASSO e applicandole al test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n=10\n","best_3_combinations = sorted_results_lasso[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    print(f\"Alpha: {params[2]}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=params[3])\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## salvataggio dizionario"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# Salva il dizionario in un file pickle\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_VGG_max50_0.3_threshold', 'wb') as pickle_file:\n","    pickle.dump(sorted_results, pickle_file)"]},{"cell_type":"markdown","metadata":{},"source":["## mostrando le n migliori configurazioni per validation PER TUTTI e applicandole al test (pero non funziona non usarlo)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n=10\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    #thresholds=np.arange(0.4, 0.6, 0.01)\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=params[3])\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=params[3])\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["# CODICE CHE PROVA I DUE METODI \n","1) threshold migliore trovata sul validation e applicata al test \n","2) threshold ottimizzata attraverso distanze sul test"]},{"cell_type":"markdown","metadata":{},"source":["## nuovo classification method"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["\n","### questo ritorna le il vettore di probabilità senza fare la classificazione\n","def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","#####################################################################################################################################\n","\n","\n","### classificazione effettuata con una threshold specifica\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_proba_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","            pr_auc = auc(recall, precision)\n","\n","            best_precision = precision[np.argmax(recall)]\n","            best_recall = recall[np.argmax(recall)]\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'best_precision': best_precision,\n","                    'best_recall': best_recall,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold\n","                }\n","                \n","            if not best_case:\n","                 print(\"Attenzione caso vuoto\") \n","            return best_case\n","\n","#####################################################################################################################################\n","\n","\n","## metodo che \n","def classification_method_new(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, thresholds, mode=\"Val\", selected_features=[0]):\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    roc_auc = roc_auc_score(y_test, y_proba_test)\n","    precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n","    pr_auc = auc(recall, precision)\n","        \n","    fpr,tpr,threshold=roc_curve(y_test,y_proba_test,pos_label=1)\n","    youden_j = tpr - fpr\n","    optimal_threshold = threshold[np.argmax(youden_j)]\n","\n","    ## due modalità \n","    if thresholds == 'y':\n","        youden_j = tpr - fpr\n","        optimal_threshold = threshold[np.argmax(youden_j)]\n","    elif thresholds == 'd':\n","        distances = np.sqrt((1 - tpr) ** 2 + fpr ** 2)\n","        optimal_threshold = threshold[np.argmin(distances)]\n","    else:\n","        print('Threshold non valida!')\n","        return None\n","\n","    \n","    y_pred_custom_test = (y_proba_test >= optimal_threshold).astype(int)\n","\n","    accuracy = accuracy_score(y_test, y_pred_custom_test)\n","    f1 = f1_score(y_test, y_pred_custom_test)\n","    conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","    # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","    best_case = {\n","        'alpha': alpha,\n","        'num_features': number_features,\n","        'selected_features': selected_features,\n","        'pr_auc': pr_auc,\n","        'roc_auc': roc_auc,\n","        'f1': f1,\n","        'accuracy': accuracy,\n","        'confusion_matrix': conf,\n","        'best_threshold': optimal_threshold,\n","        'threshold_mode': thresholds\n","    }\n","\n","    return best_case"]},{"cell_type":"markdown","metadata":{},"source":["## Loop per Validation"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting with fold: 0\n","Numero di 0 nel train: 10\n","Numero di 1 nel train: 8\n","Starting with classifier: XgBoost\n","Starting with selector: p_value\n","Starting with selector: mrmr\n","Starting with selector: rf\n","Starting with selector: logistic\n","Starting with selector: lasso\n"]},{"ename":"NameError","evalue":"name 'best_case' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[1;32m     97\u001b[0m     best_case_val \u001b[38;5;241m=\u001b[39m classification_threshold(y_proba_test, y_val, threshold, alpha, number_features, selected_features)\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbest_case\u001b[49m:\n\u001b[1;32m    100\u001b[0m         results_val[k] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    101\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m: fold_idx,\n\u001b[1;32m    102\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: classifier,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: classi \u001b[38;5;66;03m## salva il classificatore già trainato\u001b[39;00m\n\u001b[1;32m    119\u001b[0m                 }\n\u001b[1;32m    120\u001b[0m         k \u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'best_case' is not defined"]}],"source":["n_folds=5\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","thresholds=np.arange(0.4, 0.6, 0.01) \n","\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'best_precision': None,\n","                'best_recall': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'threshold': None,\n","                'selected_features': [],\n","                'fpr': None,\n","                'tpr': None,\n","                'model': None,\n","                'roc_thresholds_val': None\n","            }\n","\n","## creazione di dizionari vuoti (range con numero elevato casuale)\n","results_val = [template_dict.copy() for _ in range(300000)]\n","results_val.append(template_dict.copy())\n","\n","smote = SMOTE()\n","\n","k=0\n","old_count = 0\n","for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_red, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train_red, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    x_train_reduced, y_train = smote.fit_resample(x_train_red, y_train_red)\n","\n","    zero_count = np.sum(y_val == 0)\n","    one_count = np.sum(y_val == 1)\n","\n","    print(f\"Numero di 0 nel train: {zero_count}\")\n","    print(f\"Numero di 1 nel train: {one_count}\")\n","\n","    for i, classifier in enumerate(classifiers):\n","        print(\"Starting with classifier:\", classifier)\n","        for j, selector in enumerate(selectors):\n","            print(\"Starting with selector:\", selector)\n","\n","            if(selector=='lasso'):\n","                for alpha in alpha_values:\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, num_features=0, mode=\"Val\", selected_features=[0])\n","\n","                    fpr_val, tpr_val, roc_thresholds_val = roc_curve(y_val, y_proba_test)\n","                    #print(roc_thresholds_val)\n","\n","                    # Calcola il ROC AUC\n","                    roc_auc_val = roc_auc_score(y_val, y_proba_test)\n","                    precision, recall, _ = precision_recall_curve(y_val, y_proba_test)\n","                    pr_auc = auc(recall, precision)\n","\n","                    # Variabili per tenere traccia del miglior F1 score e threshold sul validation\n","                    best_f1_val = -1\n","                    best_threshold_val = 0\n","                    best_case_val = None\n","\n","                    # Itera su tutte le soglie e trova la migliore\n","                    for threshold in thresholds:\n","                        best_case_val = classification_threshold(y_proba_test, y_val, threshold, alpha, number_features, selected_features)\n","                        \n","                        if best_case:\n","                            results_val[k] = {\n","                                        'fold': fold_idx,\n","                                        'classifier': classifier,\n","                                        'selector': selector,\n","                                        'alpha': alpha,\n","                                        'num_features': number_features,\n","                                        'selected_features': best_case_val['selected_features'],\n","                                        'pr_auc': pr_auc,\n","                                        'best_precision': best_case_val['best_precision'],\n","                                        'best_recall': best_case_val['best_recall'],\n","                                        'roc_auc': roc_auc_val,\n","                                        'f1': best_case_val['f1'],\n","                                        'accuracy': best_case_val['accuracy'],\n","                                        'confusion_matrix': best_case_val['confusion_matrix'],\n","                                        'threshold': threshold,\n","                                        'fpr': fpr_val,  # Salva fpr per la ROC curve (il False Positive Rate per ogni soglia)\n","                                        'tpr': tpr_val,   # Salva tpr per la ROC curve (Il True Positive Rate per ogni soglia)\n","                                        'roc_thresholds_val':roc_thresholds_val, #( I valori di thresholds corrispondenti)\n","                                        'model': classi ## salva il classificatore già trainato\n","                                    }\n","                            k = k + 1\n","            \n","            \n","\n","            else:\n","\n","                limit=len(x_train_reduced[0]) + 1\n","                    \n","                for t in range(1, limit):\n","                        #print(\"Number of features \", t)\n","\n","                        if classifier == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        elif classifier == 'Logistic':\n","                            classi = LogisticRegression()\n","                        elif classifier == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                        elif classifier == 'XgBoost':\n","                            classi = XGBClassifier()\n","                        elif classifier == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation='logistic')\n","                        elif classifier == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'\n","                                )\n","\n","                        y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n","\n","                        fpr_val, tpr_val, roc_thresholds_val = roc_curve(y_val, y_proba_test)\n","                        #print(roc_thresholds_val)\n","                        # Calcola il ROC AUC\n","                        roc_auc_val = roc_auc_score(y_val, y_proba_test)\n","                        precision, recall, _ = precision_recall_curve(y_val, y_proba_test)\n","                        pr_auc = auc(recall, precision)\n","\n","                        # Variabili per tenere traccia del miglior F1 score e threshold sul validation\n","                        best_f1_val = -1\n","                        best_threshold_val = 0\n","                        best_case_val = None\n","                        \n","                        # Ciclo per trovare la soglia ottimale basata sulla ROC curve per il validation set\n","                        for threshold in thresholds:\n","                            #print(threshold)\n","                            best_case_val = classification_threshold(y_proba_test, y_val, threshold, 0, t, selected_features)\n","                                \n","                            # Salva solo il miglior caso dopo aver iterato su tutte le soglie ->> eh no\n","                            if best_case_val:\n","                                results_val[k] = {\n","                                    'fold': fold_idx,\n","                                    'classifier': classifier,\n","                                    'selector': selector,\n","                                    'alpha': 0,\n","                                    'num_features': t,\n","                                    'selected_features': best_case_val['selected_features'],\n","                                    'pr_auc': pr_auc,\n","                                    'best_precision': best_case_val['best_precision'],\n","                                    'best_recall': best_case_val['best_recall'],\n","                                    'roc_auc': roc_auc_val,\n","                                    'f1': best_case_val['f1'],\n","                                    'accuracy': best_case_val['accuracy'],\n","                                    'confusion_matrix': best_case_val['confusion_matrix'],\n","                                    'threshold': threshold,\n","                                    'fpr': fpr_val,  # Salva fpr per la ROC curve (il False Positive Rate per ogni soglia)\n","                                    'tpr': tpr_val,   # Salva tpr per la ROC curve (Il True Positive Rate per ogni soglia)\n","                                    'roc_thresholds_val':roc_thresholds_val, #( I valori di thresholds corrispondenti)\n","                                    'model': classi ## salva il classificatore già trainato\n","                                }\n","                                k = k + 1\n","                            else:\n","                                print(\"sono vuoto\")"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["filtered_result = [result for result in sorted_results if result[0] == ('ensemble', 'rf', 7, 0.39)]\n","\n","# Stampa il risultato filtrato\n","if filtered_result:\n","    for res in filtered_result:\n","        print(f\"Classifier: {res[0][0]}, Selector: {res[0][1]}, Num Features: {res[0][2]}, Threshold: {res[0][3]}\")\n","        print(f\"Avg F1 Score: {res[1]['avg_f1']}\")\n","        print(f\"Avg PR AUC: {res[1]['avg_pr_auc']}\")\n","        print(f\"Avg Accuracy: {res[1]['avg_accuracy']}\")\n","        print(f\"Std F1: {res[1]['std_f1']}\")\n","        print(f\"Std PR AUC: {res[1]['std_pr_auc']}\")\n","        print(f\"Std Accuracy: {res[1]['std_accuracy']}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Ricerca threshold val\n","gridsearch per classificatore, selector, num_features e threshold\n","ordinati per f1 e se parità threshold auc"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sto iniziando classifier SVM\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier RandomForest\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier ensemble\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier XgBoost\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier Logistic\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier MLP\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n"]}],"source":["# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value']\n","thresholds = np.arange(0.4, 0.6, 0.01) \n","num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","            print(f\"Sto iniziando selector {selector}\")\n","            for num_features in num_features_range:\n","                for threshold in thresholds:\n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val:\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features and res['threshold'] == threshold):\n","                            filtered_results.append(res)\n","                \n","                    if filtered_results:\n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results[(classifier, selector, num_features, threshold)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy\n","                        }\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']),reverse=True)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(('ensemble', 'p_value', 7, 0.37000000000000005), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.7088274044795785, 'std_f1': 0.027257128940154442, 'avg_accuracy': 0.6444444444444444, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 7, 0.35000000000000003), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.7025032938076416, 'std_f1': 0.025520527036212413, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 7, 0.36000000000000004), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.7025032938076416, 'std_f1': 0.025520527036212413, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 8, 0.36000000000000004), {'avg_pr_auc': 0.49881372009435737, 'std_pr_auc': 0.11877632300526667, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 8, 0.37000000000000005), {'avg_pr_auc': 0.49881372009435737, 'std_pr_auc': 0.11877632300526667, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 10, 0.36000000000000004), {'avg_pr_auc': 0.4953026040771139, 'std_pr_auc': 0.11082234791624038, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 7, 0.38000000000000006), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 9, 0.35000000000000003), {'avg_pr_auc': 0.4658435629820434, 'std_pr_auc': 0.08499507986747122, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 9, 0.36000000000000004), {'avg_pr_auc': 0.4658435629820434, 'std_pr_auc': 0.08499507986747122, 'avg_f1': 0.6967061923583663, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'p_value', 8, 0.32), {'avg_pr_auc': 0.49881372009435737, 'std_pr_auc': 0.11877632300526667, 'avg_f1': 0.6967061923583662, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.046481112585226386}), (('ensemble', 'p_value', 6, 0.34), {'avg_pr_auc': 0.4923323950468558, 'std_pr_auc': 0.1027034159683143, 'avg_f1': 0.6967061923583662, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.046481112585226386}), (('ensemble', 'p_value', 7, 0.33), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.6967061923583662, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.046481112585226386}), (('ensemble', 'p_value', 7, 0.34), {'avg_pr_auc': 0.48828741225187305, 'std_pr_auc': 0.10694289733679635, 'avg_f1': 0.6967061923583662, 'std_f1': 0.030308758122815544, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.046481112585226386}), (('RandomForest', 'rf', 15, 0.32), {'avg_pr_auc': 0.5138705854330855, 'std_pr_auc': 0.11376775645381668, 'avg_f1': 0.6907246376811594, 'std_f1': 0.013579949884199978, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.024845199749997625}), (('ensemble', 'mrmr', 11, 0.4000000000000001), {'avg_pr_auc': 0.5112774201560966, 'std_pr_auc': 0.10769145693400774, 'avg_f1': 0.6906418219461697, 'std_f1': 0.057948531576335366, 'avg_accuracy': 0.6333333333333334, 'std_accuracy': 0.06334307917217431}), (('ensemble', 'mrmr', 11, 0.4100000000000001), {'avg_pr_auc': 0.5112774201560966, 'std_pr_auc': 0.10769145693400774, 'avg_f1': 0.6906418219461697, 'std_f1': 0.057948531576335366, 'avg_accuracy': 0.6333333333333334, 'std_accuracy': 0.06334307917217431}), (('ensemble', 'mrmr', 10, 0.4100000000000001), {'avg_pr_auc': 0.5095668050631286, 'std_pr_auc': 0.12930804862214917, 'avg_f1': 0.6906418219461697, 'std_f1': 0.057948531576335366, 'avg_accuracy': 0.6333333333333334, 'std_accuracy': 0.06334307917217431}), (('RandomForest', 'mrmr', 11, 0.34), {'avg_pr_auc': 0.5645457150420385, 'std_pr_auc': 0.1263835045039376, 'avg_f1': 0.6903820816864294, 'std_f1': 0.025205700223595532, 'avg_accuracy': 0.6333333333333333, 'std_accuracy': 0.03042903097250918}), (('ensemble', 'rf', 12, 0.32), {'avg_pr_auc': 0.5061940801799871, 'std_pr_auc': 0.09741668591275293, 'avg_f1': 0.6903820816864294, 'std_f1': 0.025205700223595532, 'avg_accuracy': 0.6111111111111112, 'std_accuracy': 0.03928371006591928}), (('ensemble', 'p_value', 13, 0.36000000000000004), {'avg_pr_auc': 0.5025369206864305, 'std_pr_auc': 0.11474309181458987, 'avg_f1': 0.6903820816864294, 'std_f1': 0.025205700223595532, 'avg_accuracy': 0.6222222222222222, 'std_accuracy': 0.024845199749997625})]\n","Migliori 20 combinazioni di parametri:\n","\n","#1:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.37000000000000005\n","Performance medie: F1 = 0.7088274044795785 (std = 0.027257128940154442), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6444444444444444 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#2:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.35000000000000003\n","Performance medie: F1 = 0.7025032938076416 (std = 0.025520527036212413), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#3:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.36000000000000004\n","Performance medie: F1 = 0.7025032938076416 (std = 0.025520527036212413), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#4:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 8\n","Threshold: 0.36000000000000004\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.49881372009435737 (std = 0.11877632300526667), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 8\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20]\n","Precision-Recall AUC: 0.33723234269243435\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5555555555555556\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#5:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 8\n","Threshold: 0.37000000000000005\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.49881372009435737 (std = 0.11877632300526667), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 8\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20]\n","Precision-Recall AUC: 0.33723234269243435\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5555555555555556\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#6:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 10\n","Threshold: 0.36000000000000004\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.4953026040771139 (std = 0.11082234791624038), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 10\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20 13  2]\n","Precision-Recall AUC: 0.38000607692342225\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5308641975308642\n","F1 Score: 0.25\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[18  9]\n"," [ 9  3]]\n","\n","#7:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.38000000000000006\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#8:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 9\n","Threshold: 0.35000000000000003\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.4658435629820434 (std = 0.08499507986747122), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 9\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20 13]\n","Precision-Recall AUC: 0.3880714376558366\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5432098765432098\n","F1 Score: 0.41379310344827586\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[16 11]\n"," [ 6  6]]\n","\n","#9:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 9\n","Threshold: 0.36000000000000004\n","Performance medie: F1 = 0.6967061923583663 (std = 0.030308758122815544), PR AUC = 0.4658435629820434 (std = 0.08499507986747122), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 9\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20 13]\n","Precision-Recall AUC: 0.3880714376558366\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5432098765432098\n","F1 Score: 0.41379310344827586\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[16 11]\n"," [ 6  6]]\n","\n","#10:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 8\n","Threshold: 0.32\n","Performance medie: F1 = 0.6967061923583662 (std = 0.030308758122815544), PR AUC = 0.49881372009435737 (std = 0.11877632300526667), Accuracy = 0.6222222222222222 (std = 0.046481112585226386)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 8\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20]\n","Precision-Recall AUC: 0.33723234269243435\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5555555555555556\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#11:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 6\n","Threshold: 0.34\n","Performance medie: F1 = 0.6967061923583662 (std = 0.030308758122815544), PR AUC = 0.4923323950468558 (std = 0.1027034159683143), Accuracy = 0.6222222222222222 (std = 0.046481112585226386)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 6\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0]\n","Precision-Recall AUC: 0.32669208987943005\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5432098765432098\n","F1 Score: 0.2962962962962963\n","Accuracy: 0.5128205128205128\n","Confusion Matrix: \n","[[16 11]\n"," [ 8  4]]\n","\n","#12:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.33\n","Performance medie: F1 = 0.6967061923583662 (std = 0.030308758122815544), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6222222222222222 (std = 0.046481112585226386)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#13:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 7\n","Threshold: 0.34\n","Performance medie: F1 = 0.6967061923583662 (std = 0.030308758122815544), PR AUC = 0.48828741225187305 (std = 0.10694289733679635), Accuracy = 0.6222222222222222 (std = 0.046481112585226386)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8]\n","Precision-Recall AUC: 0.3375232338763349\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5401234567901234\n","F1 Score: 0.35714285714285715\n","Accuracy: 0.5384615384615384\n","Confusion Matrix: \n","[[16 11]\n"," [ 7  5]]\n","\n","#14:\n","Classifier: RandomForest\n","Selector: rf\n","Num_features: 15\n","Threshold: 0.32\n","Performance medie: F1 = 0.6907246376811594 (std = 0.013579949884199978), PR AUC = 0.5138705854330855 (std = 0.11376775645381668), Accuracy = 0.6222222222222222 (std = 0.024845199749997625)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 15\n","Threshold: 0.54\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14 13  8 16]\n","Precision-Recall AUC: 0.42915139642586664\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5462962962962963\n","F1 Score: 0.41379310344827586\n","Accuracy: 0.5641025641025641\n","Confusion Matrix: \n","[[16 11]\n"," [ 6  6]]\n","\n","#15:\n","Classifier: ensemble\n","Selector: mrmr\n","Num_features: 11\n","Threshold: 0.4000000000000001\n","Performance medie: F1 = 0.6906418219461697 (std = 0.057948531576335366), PR AUC = 0.5112774201560966 (std = 0.10769145693400774), Accuracy = 0.6333333333333334 (std = 0.06334307917217431)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 11\n","Threshold: 0.54\n","Selected Features: [18, 19, 12, 14, 9, 20, 10, 4, 1, 8, 11]\n","Precision-Recall AUC: 0.4877907537794047\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6604938271604938\n","F1 Score: 0.46153846153846156\n","Accuracy: 0.6410256410256411\n","Confusion Matrix: \n","[[19  8]\n"," [ 6  6]]\n","\n","#16:\n","Classifier: ensemble\n","Selector: mrmr\n","Num_features: 11\n","Threshold: 0.4100000000000001\n","Performance medie: F1 = 0.6906418219461697 (std = 0.057948531576335366), PR AUC = 0.5112774201560966 (std = 0.10769145693400774), Accuracy = 0.6333333333333334 (std = 0.06334307917217431)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 11\n","Threshold: 0.54\n","Selected Features: [18, 19, 12, 14, 9, 20, 10, 4, 1, 8, 11]\n","Precision-Recall AUC: 0.4877907537794047\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6604938271604938\n","F1 Score: 0.46153846153846156\n","Accuracy: 0.6410256410256411\n","Confusion Matrix: \n","[[19  8]\n"," [ 6  6]]\n","\n","#17:\n","Classifier: ensemble\n","Selector: mrmr\n","Num_features: 10\n","Threshold: 0.4100000000000001\n","Performance medie: F1 = 0.6906418219461697 (std = 0.057948531576335366), PR AUC = 0.5095668050631286 (std = 0.12930804862214917), Accuracy = 0.6333333333333334 (std = 0.06334307917217431)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 10\n","Threshold: 0.54\n","Selected Features: [18, 19, 12, 14, 9, 20, 10, 4, 1, 8]\n","Precision-Recall AUC: 0.4284643462525327\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.638888888888889\n","F1 Score: 0.4166666666666667\n","Accuracy: 0.6410256410256411\n","Confusion Matrix: \n","[[20  7]\n"," [ 7  5]]\n","\n","#18:\n","Classifier: RandomForest\n","Selector: mrmr\n","Num_features: 11\n","Threshold: 0.34\n","Performance medie: F1 = 0.6903820816864294 (std = 0.025205700223595532), PR AUC = 0.5645457150420385 (std = 0.1263835045039376), Accuracy = 0.6333333333333333 (std = 0.03042903097250918)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 11\n","Threshold: 0.54\n","Selected Features: [18, 19, 12, 14, 9, 20, 10, 4, 1, 8, 11]\n","Precision-Recall AUC: 0.48190974182822005\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6512345679012345\n","F1 Score: 0.5\n","Accuracy: 0.6410256410256411\n","Confusion Matrix: \n","[[18  9]\n"," [ 5  7]]\n","\n","#19:\n","Classifier: ensemble\n","Selector: rf\n","Num_features: 12\n","Threshold: 0.32\n","Performance medie: F1 = 0.6903820816864294 (std = 0.025205700223595532), PR AUC = 0.5061940801799871 (std = 0.09741668591275293), Accuracy = 0.6111111111111112 (std = 0.03928371006591928)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 12\n","Threshold: 0.54\n","Selected Features: [19 18 15  9  4  6  2  0 20  7 10 14]\n","Precision-Recall AUC: 0.5023959904474611\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.6296296296296297\n","F1 Score: 0.5185185185185185\n","Accuracy: 0.6666666666666666\n","Confusion Matrix: \n","[[19  8]\n"," [ 5  7]]\n","\n","#20:\n","Classifier: ensemble\n","Selector: p_value\n","Num_features: 13\n","Threshold: 0.36000000000000004\n","Performance medie: F1 = 0.6903820816864294 (std = 0.025205700223595532), PR AUC = 0.5025369206864305 (std = 0.11474309181458987), Accuracy = 0.6222222222222222 (std = 0.024845199749997625)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 13\n","Threshold: 0.54\n","Selected Features: [19 18 12 14  7  0  8 20 13  2  5  9  6]\n","Precision-Recall AUC: 0.280398319863507\n","Best Precision: 0.3076923076923077\n","Best Recall: 1.0\n","ROC AUC: 0.5\n","F1 Score: 0.2857142857142857\n","Accuracy: 0.48717948717948717\n","Confusion Matrix: \n","[[15 12]\n"," [ 8  4]]\n"]}],"source":["n=20\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    #thresholds=np.arange(0.4, 0.6, 0.01)\n","\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=params[3])\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=0.54)\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {best_case['best_threshold']}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Ricerca threshold test\n","usa la classification new"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sto iniziando classifier SVM\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier RandomForest\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier ensemble\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier XgBoost\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier Logistic\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n","Sto iniziando classifier MLP\n","Sto iniziando selector mrmr\n","Sto iniziando selector rf\n","Sto iniziando selector logistic\n","Sto iniziando selector p_value\n"]}],"source":["# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value']\n","num_features_range = list(range(1, (len(x_train_reduced[0]) + 1)))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        print(f\"Sto iniziando selector {selector}\")\n","        for num_features in num_features_range:\n","            # Filtra i risultati che corrispondono a questa combinazione di parametri\n","            filtered_results = []\n","            for res in results_val:\n","                if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features):\n","                    filtered_results.append(res)\n","            \n","            if filtered_results:\n","                pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                roc_auc_values = [res['roc_auc'] for res in filtered_results]\n","                f1_values = [res['f1'] for res in filtered_results]\n","                accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","                # Calcola le medie delle metriche\n","                avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                avg_roc_auc = sum(roc_auc_values) / len(roc_auc_values)\n","                avg_f1 = sum(f1_values) / len(f1_values)\n","                avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                # Calcola la deviazione standard delle metriche\n","                std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                std_roc_auc = statistics.stdev(roc_auc_values) if len(roc_auc_values) > 1 else 0\n","                std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                grid_results[(classifier, selector, num_features)] = {\n","                    'avg_roc_auc': avg_roc_auc,\n","                    'std_roc_auc': std_roc_auc,\n","                    'avg_pr_auc': avg_pr_auc,\n","                    'std_pr_auc': std_pr_auc,\n","                    'avg_f1': avg_f1,\n","                    'std_f1': std_f1,\n","                    'avg_accuracy': avg_accuracy,\n","                    'std_accuracy': std_accuracy\n","                }\n","\n","# Ordina le combinazioni per 'avg_roc_auc', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_roc_auc'], x[1]['avg_pr_auc']), reverse=True)"]},{"cell_type":"code","execution_count":144,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[(('SVM', 'logistic', 17), {'avg_roc_auc': 0.6399831649831662, 'std_roc_auc': 0.05283774153830145, 'avg_pr_auc': 0.6380613855910553, 'std_pr_auc': 0.08050154951191432, 'avg_f1': 0.5335733560740394, 'std_f1': 0.13844830116218654, 'avg_accuracy': 0.5107142857142859, 'std_accuracy': 0.08519012971319455}), (('MLP', 'mrmr', 17), {'avg_roc_auc': 0.6728956228956252, 'std_roc_auc': 0.09669741694170386, 'avg_pr_auc': 0.6147410727673874, 'std_pr_auc': 0.13430911066188864, 'avg_f1': 0.39158118127083646, 'std_f1': 0.29330725555022275, 'avg_accuracy': 0.48598412698412696, 'std_accuracy': 0.06562240663932026}), (('MLP', 'p_value', 10), {'avg_roc_auc': 0.5991582491582491, 'std_roc_auc': 0.09398581635394379, 'avg_pr_auc': 0.6020815561669544, 'std_pr_auc': 0.0726434439418605, 'avg_f1': 0.0, 'std_f1': 0.0, 'avg_accuracy': 0.5628571428571415, 'std_accuracy': 0.01053298183524477}), (('SVM', 'p_value', 21), {'avg_roc_auc': 0.632828282828283, 'std_roc_auc': 0.09770249499173127, 'avg_pr_auc': 0.5998517180560522, 'std_pr_auc': 0.06785367658752627, 'avg_f1': 0.5537746111540471, 'std_f1': 0.14196222577230597, 'avg_accuracy': 0.5312380952380952, 'std_accuracy': 0.08599211037865945}), (('MLP', 'rf', 17), {'avg_roc_auc': 0.6503367003367028, 'std_roc_auc': 0.051811784790879195, 'avg_pr_auc': 0.5970176037603794, 'std_pr_auc': 0.11265881852321169, 'avg_f1': 0.3959915078535768, 'std_f1': 0.2891837080458148, 'avg_accuracy': 0.4873174603174604, 'std_accuracy': 0.0651084251259116}), (('SVM', 'rf', 8), {'avg_roc_auc': 0.6181818181818183, 'std_roc_auc': 0.0864612816133021, 'avg_pr_auc': 0.5937728894772237, 'std_pr_auc': 0.05270449911770797, 'avg_f1': 0.5485758957549867, 'std_f1': 0.1370792887008598, 'avg_accuracy': 0.5344285714285714, 'std_accuracy': 0.08308053240642352}), (('SVM', 'rf', 9), {'avg_roc_auc': 0.6181818181818183, 'std_roc_auc': 0.0864612816133021, 'avg_pr_auc': 0.5937728894772237, 'std_pr_auc': 0.05270449911770797, 'avg_f1': 0.5491241201807854, 'std_f1': 0.1364880573889532, 'avg_accuracy': 0.5344285714285714, 'std_accuracy': 0.08287833141391615}), (('SVM', 'logistic', 16), {'avg_roc_auc': 0.607407407407408, 'std_roc_auc': 0.0978967933160981, 'avg_pr_auc': 0.5936417218641165, 'std_pr_auc': 0.11923582227140848, 'avg_f1': 0.5257492994072394, 'std_f1': 0.16340150782600912, 'avg_accuracy': 0.4967619047619053, 'std_accuracy': 0.08484623122819822}), (('MLP', 'rf', 14), {'avg_roc_auc': 0.5981481481481492, 'std_roc_auc': 0.0684458839891237, 'avg_pr_auc': 0.5921813466318117, 'std_pr_auc': 0.03638441901549053, 'avg_f1': 0.4318325782163864, 'std_f1': 0.2724524240945729, 'avg_accuracy': 0.47903174603174636, 'std_accuracy': 0.06284151041525177}), (('SVM', 'mrmr', 17), {'avg_roc_auc': 0.6106060606060603, 'std_roc_auc': 0.06807806348825804, 'avg_pr_auc': 0.5914047637757642, 'std_pr_auc': 0.05130310660132817, 'avg_f1': 0.5458460793870334, 'std_f1': 0.13771893809296656, 'avg_accuracy': 0.5270952380952382, 'std_accuracy': 0.08061076472954087}), (('SVM', 'mrmr', 18), {'avg_roc_auc': 0.6106060606060603, 'std_roc_auc': 0.06807806348825804, 'avg_pr_auc': 0.5914047637757642, 'std_pr_auc': 0.05130310660132817, 'avg_f1': 0.5459105788710377, 'std_f1': 0.1379218099624367, 'avg_accuracy': 0.5274285714285715, 'std_accuracy': 0.08039291191650133}), (('SVM', 'mrmr', 19), {'avg_roc_auc': 0.6106060606060603, 'std_roc_auc': 0.06807806348825804, 'avg_pr_auc': 0.5914047637757642, 'std_pr_auc': 0.05130310660132817, 'avg_f1': 0.5464174014831233, 'std_f1': 0.13809706092653695, 'avg_accuracy': 0.5277460317460317, 'std_accuracy': 0.08084985266831193}), (('SVM', 'mrmr', 20), {'avg_roc_auc': 0.6106060606060603, 'std_roc_auc': 0.06807806348825804, 'avg_pr_auc': 0.5914047637757642, 'std_pr_auc': 0.05130310660132817, 'avg_f1': 0.5460686835344054, 'std_f1': 0.13779189693796692, 'avg_accuracy': 0.5274285714285715, 'std_accuracy': 0.08058199251219271}), (('MLP', 'mrmr', 7), {'avg_roc_auc': 0.6037037037037031, 'std_roc_auc': 0.14299099709243743, 'avg_pr_auc': 0.5834549992109352, 'std_pr_auc': 0.09544335810945123, 'avg_f1': 0.4866206896551725, 'std_f1': 0.2442948593271215, 'avg_accuracy': 0.46228571428571485, 'std_accuracy': 0.05154190133745888}), (('MLP', 'mrmr', 15), {'avg_roc_auc': 0.6528619528619538, 'std_roc_auc': 0.02845890261689779, 'avg_pr_auc': 0.5820934074907247, 'std_pr_auc': 0.08994966942976657, 'avg_f1': 0.42741906800436347, 'std_f1': 0.27592941800899934, 'avg_accuracy': 0.484809523809524, 'std_accuracy': 0.0646805400842887}), (('SVM', 'mrmr', 21), {'avg_roc_auc': 0.6161616161616159, 'std_roc_auc': 0.07196417131197998, 'avg_pr_auc': 0.5804669978379984, 'std_pr_auc': 0.05252377431947562, 'avg_f1': 0.5482379273530612, 'std_f1': 0.14322951403188458, 'avg_accuracy': 0.5258412698412698, 'std_accuracy': 0.08110844780968925}), (('MLP', 'mrmr', 20), {'avg_roc_auc': 0.5765993265993278, 'std_roc_auc': 0.17979561213995063, 'avg_pr_auc': 0.5776771660762883, 'std_pr_auc': 0.15538759865269147, 'avg_f1': 0.3470516376484275, 'std_f1': 0.300083286152342, 'avg_accuracy': 0.4975714285714283, 'std_accuracy': 0.07077654356597629}), (('MLP', 'rf', 19), {'avg_roc_auc': 0.5828282828282834, 'std_roc_auc': 0.08806990419028786, 'avg_pr_auc': 0.5770815477188038, 'std_pr_auc': 0.09063059120833572, 'avg_f1': 0.6082758620689657, 'std_f1': 0.01016977556506397, 'avg_accuracy': 0.43714285714285817, 'std_accuracy': 0.010532981835244823}), (('MLP', 'logistic', 12), {'avg_roc_auc': 0.6474747474747456, 'std_roc_auc': 0.15375586859061532, 'avg_pr_auc': 0.5759243155747278, 'std_pr_auc': 0.1161727828671399, 'avg_f1': 0.5212782285327926, 'std_f1': 0.21225966269291446, 'avg_accuracy': 0.45626984126984166, 'std_accuracy': 0.048831961470153847}), (('MLP', 'mrmr', 13), {'avg_roc_auc': 0.6365319865319862, 'std_roc_auc': 0.1336466487870601, 'avg_pr_auc': 0.5690459256468041, 'std_pr_auc': 0.07284852532930351, 'avg_f1': 0.0, 'std_f1': 0.0, 'avg_accuracy': 0.5628571428571415, 'std_accuracy': 0.01053298183524477})]\n","Migliori 20 combinazioni di parametri:\n","\n","#1:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 17\n","Performance medie: ROC Auc = 0.6399831649831662 (std = 0.05283774153830145), PR AUC = 0.6380613855910553 (std = 0.08050154951191432), Accuracy = 0.5107142857142859 (std = 0.08519012971319455)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 17\n","Threshold: 0.47742151768264973\n","Threshold Mode:y\n","Selected Features: [17  7  1 15  0 21  9  2  5 20 12  8  3 13  6  4 11]\n","Precision-Recall AUC: 0.6594146350725298\n","ROC AUC: 0.8333333333333333\n","F1 Score: 0.75\n","Accuracy: 0.8461538461538461\n","Confusion Matrix: \n","[[16  2]\n"," [ 2  6]]\n","\n","#2:\n","Classifier: MLP\n","Selector: mrmr\n","Num_features: 17\n","Performance medie: ROC Auc = 0.6728956228956252 (std = 0.09669741694170386), PR AUC = 0.6147410727673874 (std = 0.13430911066188864), Accuracy = 0.48598412698412696 (std = 0.06562240663932026)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 17\n","Threshold: 0.41590748011765644\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4]\n","Precision-Recall AUC: 0.554491341991342\n","ROC AUC: 0.8263888888888888\n","F1 Score: 0.7\n","Accuracy: 0.7692307692307693\n","Confusion Matrix: \n","[[13  5]\n"," [ 1  7]]\n","\n","#3:\n","Classifier: MLP\n","Selector: p_value\n","Num_features: 10\n","Performance medie: ROC Auc = 0.5991582491582491 (std = 0.09398581635394379), PR AUC = 0.6020815561669544 (std = 0.0726434439418605), Accuracy = 0.5628571428571415 (std = 0.01053298183524477)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 10\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [20 19  0 13  8  7 15 21  9  2]\n","Precision-Recall AUC: 0.20561656383187715\n","ROC AUC: 0.25\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#4:\n","Classifier: SVM\n","Selector: p_value\n","Num_features: 21\n","Performance medie: ROC Auc = 0.632828282828283 (std = 0.09770249499173127), PR AUC = 0.5998517180560522 (std = 0.06785367658752627), Accuracy = 0.5312380952380952 (std = 0.08599211037865945)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 21\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [20 19  0 13  8  7 15 21  9  2  5 10 18 11 16 17 14  4  6  3  1]\n","Precision-Recall AUC: 0.18461645212204675\n","ROC AUC: 0.14583333333333334\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#5:\n","Classifier: MLP\n","Selector: rf\n","Num_features: 17\n","Performance medie: ROC Auc = 0.6503367003367028 (std = 0.051811784790879195), PR AUC = 0.5970176037603794 (std = 0.11265881852321169), Accuracy = 0.4873174603174604 (std = 0.0651084251259116)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 17\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [ 6 20  4  9 16  2 17 19  0 15 10  7 13  8 14 11 12]\n","Precision-Recall AUC: 0.20638752764478385\n","ROC AUC: 0.2569444444444444\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#6:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 8\n","Performance medie: ROC Auc = 0.6181818181818183 (std = 0.0864612816133021), PR AUC = 0.5937728894772237 (std = 0.05270449911770797), Accuracy = 0.5344285714285714 (std = 0.08308053240642352)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 8\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [ 6 20  4  9 16  2 17 19]\n","Precision-Recall AUC: 0.19124789080271817\n","ROC AUC: 0.18055555555555558\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#7:\n","Classifier: SVM\n","Selector: rf\n","Num_features: 9\n","Performance medie: ROC Auc = 0.6181818181818183 (std = 0.0864612816133021), PR AUC = 0.5937728894772237 (std = 0.05270449911770797), Accuracy = 0.5344285714285714 (std = 0.08287833141391615)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 9\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [ 6 20  4  9 16  2 17 19  0]\n","Precision-Recall AUC: 0.19124789080271817\n","ROC AUC: 0.18055555555555558\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#8:\n","Classifier: SVM\n","Selector: logistic\n","Num_features: 16\n","Performance medie: ROC Auc = 0.607407407407408 (std = 0.0978967933160981), PR AUC = 0.5936417218641165 (std = 0.11923582227140848), Accuracy = 0.4967619047619053 (std = 0.08484623122819822)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 16\n","Threshold: 0.4775826614314211\n","Threshold Mode:y\n","Selected Features: [17  7  1 15  0 21  9  2  5 20 12  8  3 13  6  4]\n","Precision-Recall AUC: 0.6594146350725298\n","ROC AUC: 0.8333333333333333\n","F1 Score: 0.75\n","Accuracy: 0.8461538461538461\n","Confusion Matrix: \n","[[16  2]\n"," [ 2  6]]\n","\n","#9:\n","Classifier: MLP\n","Selector: rf\n","Num_features: 14\n","Performance medie: ROC Auc = 0.5981481481481492 (std = 0.0684458839891237), PR AUC = 0.5921813466318117 (std = 0.03638441901549053), Accuracy = 0.47903174603174636 (std = 0.06284151041525177)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 14\n","Threshold: 0.47146226442817457\n","Threshold Mode:y\n","Selected Features: [ 6 20  4  9 16  2 17 19  0 15 10  7 13  8]\n","Precision-Recall AUC: 0.46041701354201353\n","ROC AUC: 0.7847222222222223\n","F1 Score: 0.7272727272727273\n","Accuracy: 0.7692307692307693\n","Confusion Matrix: \n","[[12  6]\n"," [ 0  8]]\n","\n","#10:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 17\n","Performance medie: ROC Auc = 0.6106060606060603 (std = 0.06807806348825804), PR AUC = 0.5914047637757642 (std = 0.05130310660132817), Accuracy = 0.5270952380952382 (std = 0.08061076472954087)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 17\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4]\n","Precision-Recall AUC: 0.19265640529547182\n","ROC AUC: 0.18750000000000003\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#11:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 18\n","Performance medie: ROC Auc = 0.6106060606060603 (std = 0.06807806348825804), PR AUC = 0.5914047637757642 (std = 0.05130310660132817), Accuracy = 0.5274285714285715 (std = 0.08039291191650133)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 18\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4, 1]\n","Precision-Recall AUC: 0.19265640529547182\n","ROC AUC: 0.18750000000000003\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#12:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 19\n","Performance medie: ROC Auc = 0.6106060606060603 (std = 0.06807806348825804), PR AUC = 0.5914047637757642 (std = 0.05130310660132817), Accuracy = 0.5277460317460317 (std = 0.08084985266831193)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 19\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4, 1, 12]\n","Precision-Recall AUC: 0.19265640529547182\n","ROC AUC: 0.18750000000000003\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#13:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 20\n","Performance medie: ROC Auc = 0.6106060606060603 (std = 0.06807806348825804), PR AUC = 0.5914047637757642 (std = 0.05130310660132817), Accuracy = 0.5274285714285715 (std = 0.08058199251219271)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 20\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4, 1, 12, 10]\n","Precision-Recall AUC: 0.18461645212204675\n","ROC AUC: 0.14583333333333334\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#14:\n","Classifier: MLP\n","Selector: mrmr\n","Num_features: 7\n","Performance medie: ROC Auc = 0.6037037037037031 (std = 0.14299099709243743), PR AUC = 0.5834549992109352 (std = 0.09544335810945123), Accuracy = 0.46228571428571485 (std = 0.05154190133745888)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 7\n","Threshold: 0.49150172536471504\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5]\n","Precision-Recall AUC: 0.33998369084475893\n","ROC AUC: 0.5694444444444444\n","F1 Score: 0.5333333333333333\n","Accuracy: 0.7307692307692307\n","Confusion Matrix: \n","[[15  3]\n"," [ 4  4]]\n","\n","#15:\n","Classifier: MLP\n","Selector: mrmr\n","Num_features: 15\n","Performance medie: ROC Auc = 0.6528619528619538 (std = 0.02845890261689779), PR AUC = 0.5820934074907247 (std = 0.08994966942976657), Accuracy = 0.484809523809524 (std = 0.0646805400842887)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 15\n","Threshold: 0.48569982185415317\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15]\n","Precision-Recall AUC: 0.6701472445038621\n","ROC AUC: 0.7916666666666667\n","F1 Score: 0.64\n","Accuracy: 0.6538461538461539\n","Confusion Matrix: \n","[[9 9]\n"," [0 8]]\n","\n","#16:\n","Classifier: SVM\n","Selector: mrmr\n","Num_features: 21\n","Performance medie: ROC Auc = 0.6161616161616159 (std = 0.07196417131197998), PR AUC = 0.5804669978379984 (std = 0.05252377431947562), Accuracy = 0.5258412698412698 (std = 0.08110844780968925)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 21\n","Threshold: inf\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4, 1, 12, 10, 8]\n","Precision-Recall AUC: 0.18461645212204675\n","ROC AUC: 0.14583333333333334\n","F1 Score: 0.0\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[18  0]\n"," [ 8  0]]\n","\n","#17:\n","Classifier: MLP\n","Selector: mrmr\n","Num_features: 20\n","Performance medie: ROC Auc = 0.5765993265993278 (std = 0.17979561213995063), PR AUC = 0.5776771660762883 (std = 0.15538759865269147), Accuracy = 0.4975714285714283 (std = 0.07077654356597629)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 20\n","Threshold: 0.42411809011119855\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21, 13, 15, 9, 4, 1, 12, 10]\n","Precision-Recall AUC: 0.7241229256854257\n","ROC AUC: 0.8194444444444444\n","F1 Score: 0.7368421052631579\n","Accuracy: 0.8076923076923077\n","Confusion Matrix: \n","[[14  4]\n"," [ 1  7]]\n","\n","#18:\n","Classifier: MLP\n","Selector: rf\n","Num_features: 19\n","Performance medie: ROC Auc = 0.5828282828282834 (std = 0.08806990419028786), PR AUC = 0.5770815477188038 (std = 0.09063059120833572), Accuracy = 0.43714285714285817 (std = 0.010532981835244823)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 19\n","Threshold: 0.6609052915428535\n","Threshold Mode:y\n","Selected Features: [ 6 20  4  9 16  2 17 19  0 15 10  7 13  8 14 11 12  1  5]\n","Precision-Recall AUC: 0.39776334776334776\n","ROC AUC: 0.6597222222222223\n","F1 Score: 0.6\n","Accuracy: 0.6923076923076923\n","Confusion Matrix: \n","[[12  6]\n"," [ 2  6]]\n","\n","#19:\n","Classifier: MLP\n","Selector: logistic\n","Num_features: 12\n","Performance medie: ROC Auc = 0.6474747474747456 (std = 0.15375586859061532), PR AUC = 0.5759243155747278 (std = 0.1161727828671399), Accuracy = 0.45626984126984166 (std = 0.048831961470153847)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 12\n","Threshold: 0.49318041798177703\n","Threshold Mode:y\n","Selected Features: [17  7  1 15  0 21  9  2  5 20 12  8]\n","Precision-Recall AUC: 0.556063819221714\n","ROC AUC: 0.7361111111111112\n","F1 Score: 0.6086956521739131\n","Accuracy: 0.6538461538461539\n","Confusion Matrix: \n","[[10  8]\n"," [ 1  7]]\n","\n","#20:\n","Classifier: MLP\n","Selector: mrmr\n","Num_features: 13\n","Performance medie: ROC Auc = 0.6365319865319862 (std = 0.1336466487870601), PR AUC = 0.5690459256468041 (std = 0.07284852532930351), Accuracy = 0.5628571428571415 (std = 0.01053298183524477)\n","Metrics from best_case ON THE TEST SET:\n","Number of Features: 13\n","Threshold: 0.28976362023023855\n","Threshold Mode:y\n","Selected Features: [16, 11, 17, 14, 6, 3, 5, 18, 0, 20, 2, 19, 21]\n","Precision-Recall AUC: 0.6306761814574314\n","ROC AUC: 0.7500000000000001\n","F1 Score: 0.6666666666666666\n","Accuracy: 0.7692307692307693\n","Confusion Matrix: \n","[[14  4]\n"," [ 2  6]]\n"]}],"source":["n=20\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Performance medie: ROC Auc = {metrics['avg_roc_auc']} (std = {metrics['std_roc_auc']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive', activation='logistic')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=params[3])\n","    else: \n","        best_case=classification_method_new(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds='y')\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {best_case['best_threshold']}\")\n","    print(f\"Threshold Mode:{best_case['threshold_mode']}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5686764,"sourceId":9375373,"sourceType":"datasetVersion"},{"datasetId":5686788,"sourceId":9375404,"sourceType":"datasetVersion"},{"datasetId":5687116,"sourceId":9375826,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1"}},"nbformat":4,"nbformat_minor":4}
