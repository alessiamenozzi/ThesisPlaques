{"cells":[{"cell_type":"markdown","metadata":{},"source":["## import"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-12T14:41:29.243721Z","iopub.status.busy":"2024-09-12T14:41:29.243296Z","iopub.status.idle":"2024-09-12T14:41:29.260564Z","shell.execute_reply":"2024-09-12T14:41:29.259665Z","shell.execute_reply.started":"2024-09-12T14:41:29.243682Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","# Import libraries\n","import tensorflow as tf\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import LogisticRegression, Lasso\n","from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest, SelectPercentile, f_classif, f_regression, SelectFromModel\n","from scipy.spatial.distance import pdist, squareform\n","from scipy.stats import ttest_ind\n","from xgboost import XGBClassifier\n","\n","sc = StandardScaler()\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["## caricamento dati"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento labels pazienti"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../CSV/data_rad_clin_DEF.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../CSV/data_rad_clin_DEF.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m labels_column \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels_column\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n","File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../CSV/data_rad_clin_DEF.csv'"]}],"source":["\n","file_path = \"../CSV/data_rad_clin_DEF.csv\"\n","\n","data = pd.read_csv(file_path)\n","labels_column = data['label']\n","labels = labels_column.astype(int).tolist()\n","\n","labels=np.array(labels)\n","\n","# Estrazione dei numeri dai nomi dei pazienti\n","loaded_patients = data['IDs_new'].str.extract(r'(\\d+)').astype(int).squeeze().tolist()\n","\n","print(\"Labels:\", labels)\n","print(\"Number of labels:\", len(labels))\n","print(\"Patient Names: \", loaded_patients )\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","file_path = \"../CSV/Features_VGG16.csv\"\n","df = pd.read_csv(file_path, sep=',')\n","\n","\n","df['Unnamed: 0'] = df['Unnamed: 0'].astype(int)\n","\n","df_ordered = df.set_index('Unnamed: 0').loc[loaded_patients].reset_index()\n","\n","df_features = df_ordered.drop(columns=['Unnamed: 0'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)\n"]},{"cell_type":"markdown","metadata":{},"source":["### caricamento features radiomica"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.576941Z","iopub.status.busy":"2024-09-12T14:41:29.576572Z","iopub.status.idle":"2024-09-12T14:41:29.706641Z","shell.execute_reply":"2024-09-12T14:41:29.705694Z","shell.execute_reply.started":"2024-09-12T14:41:29.576895Z"},"trusted":true},"outputs":[],"source":["\n","file_path=\"../CSV/Radiomica_3D.csv\"\n","df = pd.read_csv(file_path, sep=';')\n","df = df.astype(float)\n","\n","# Colonne da rimuovere SOLO PER RADIOMICA\n","columns_to_remove = [\n","    'diagnostics_Image-original_Mean',\n","    'diagnostics_Image-original_Minimum',\n","    'diagnostics_Image-original_Maximum',\n","    'diagnostics_Mask-original_VoxelNum',\n","    'diagnostics_Mask-original_VolumeNum',\n","]\n","\n","df_cleaned = df.drop(columns=columns_to_remove)\n","df_features = df_cleaned.drop(columns=['Paziente'])\n","\n","features = df_features.to_numpy()\n","\n","print(features)\n","print(features.shape)  \n"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.774442Z","iopub.status.busy":"2024-09-12T14:41:29.774064Z","iopub.status.idle":"2024-09-12T14:41:29.814876Z","shell.execute_reply":"2024-09-12T14:41:29.813996Z","shell.execute_reply.started":"2024-09-12T14:41:29.774406Z"},"trusted":true},"outputs":[],"source":["\n","## Rimozione feature correlation\n","def remove_highly_correlated_features(X, threshold=0.85):\n","    corr_matrix = np.corrcoef(X, rowvar=False)\n","    upper_triangle = np.triu(corr_matrix, k=1)\n","    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n","    X_reduced = np.delete(X, to_drop, axis=1)\n","    return X_reduced, to_drop\n","\n","## Rimozione features p_value\n","def remove_high_pvalue_features(X, y, alpha=0.05):\n","    selector = SelectKBest(score_func=f_classif, k='all')\n","    selector.fit(X, y)\n","    p_values = selector.pvalues_\n","    features_to_keep = np.where(p_values < alpha)[0]\n","    X_reduced = X[:, features_to_keep]\n","    return X_reduced, features_to_keep\n","\n","## FEATURE SELECTION LASSO\n","def select_features_with_lasso(X, y, alpha=0.001):\n","    \n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X, y)\n","    coefficients = lasso.coef_\n","    selected_features = np.where(coefficients != 0)[0]\n","    X_selected = X[:, selected_features]\n","\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION LOGISTIC\n","def logistic_regression_feature_selection(X, y, num_features):\n","    lr = LogisticRegression(max_iter=1000, random_state=42)\n","    lr.fit(X, y)\n","    coef_abs = np.abs(lr.coef_)\n","    feature_importances = np.mean(coef_abs, axis=0)\n","    selected_features = feature_importances.argsort()[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","## FEATURE SELECTION MRMR\n","def mrmr_feature_selection(X, y, num_features):\n","    mi = mutual_info_classif(X, y)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n","    \n","    selected_features = []\n","    selected_indices = []\n","\n","    first_feature_index = np.argmax(mi)\n","    selected_features.append(first_feature_index)\n","    selected_indices.append(first_feature_index)\n","    \n","    for _ in range(num_features - 1):\n","        max_relevance = -np.inf\n","        selected_feature_index = -1\n","        \n","        for i in range(X.shape[1]):\n","            if i in selected_indices:\n","                continue\n","            \n","            relevance = mi[i]\n","            redundancy = np.mean(distances[i, selected_indices])\n","            \n","            mrmr_score = relevance - redundancy\n","            \n","            if mrmr_score > max_relevance:\n","                max_relevance = mrmr_score\n","                selected_feature_index = i\n","        \n","        selected_features.append(selected_feature_index)\n","        selected_indices.append(selected_feature_index)\n","\n","    X_selected = X[:, selected_indices]\n","    return X_selected, selected_indices\n","\n","## FEATURE SELECTION RANDOM FOREST\n","def rf_feature_selection(X, y, num_features):\n","    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","    rf.fit(X, y)\n","    feature_importances = rf.feature_importances_\n","    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n","    X_selected = X[:, selected_features]\n","    return X_selected, selected_features\n","\n","\n","## FEATURE SELECTION P_VALUE\n","# Seleziona e ordina le feature basate sui p-value con un test t di Student poi \n","# ordina le feature in base al p-value in ordine crescente e seleziona le prime `num_features` caratteristiche.\n","\n","def select_features_by_p_value(x_train_expanded, y_train_expanded, num_features):\n","    p_values = []\n","    num_features_total = x_train_expanded.shape[1]\n","\n","    # Calcolo dei p-value per ciascuna feature\n","    for i in range(num_features_total):\n","        feature = x_train_expanded[:, i]\n","        group_0 = feature[y_train_expanded == 0]\n","        group_1 = feature[y_train_expanded == 1]\n","        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n","        p_values.append(p_val)\n","\n","\n","    p_values = np.array(p_values)\n","\n","    # Ordinare tutte le caratteristiche in base ai p-value (dal più piccolo al più grande)\n","    sorted_indices = np.argsort(p_values)\n","    sorted_indices = sorted_indices[:num_features]\n","\n","    x_train_selected = x_train_expanded[:, sorted_indices]\n","\n","    return x_train_selected, sorted_indices\n","\n","\n","\n","## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n","def filter_patients_features(filtered_patients, selected_features):\n","    filtered_patients_selected = []\n","\n","    for patient_features in filtered_patients:\n","        # Select only the features specified in selected_features\n","        patient_features_selected = patient_features[:, selected_features]\n","        filtered_patients_selected.append(patient_features_selected)\n","\n","    return filtered_patients_selected\n","\n","\n","\n","## FUNZIONE DI CLASSIFICAZIONE\n","def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.4, 0.6, 0.01)):\n","    best_f1_score = 0\n","    best_case = None\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n","    if(isinstance(thresholds, np.ndarray)== False): ## se la threshold viene data fissa\n","        thresholds=[thresholds]\n","        \n","    \n","    for threshold in thresholds:\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_pred_custom_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_pred_custom_test)\n","            pr_auc = auc(recall, precision)\n","\n","            best_precision = precision[np.argmax(recall)]\n","            best_recall = recall[np.argmax(recall)]\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","\n","            # Se il nuovo risultato è migliore rispetto al migliore attuale (in base all'f1 e altrimenti pr_auc)\n","            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n","                best_f1_score = f1\n","                best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'best_precision': best_precision,\n","                    'best_recall': best_recall,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'best_threshold': threshold\n","                }\n","\n","    return best_case\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## split"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:29.977584Z","iopub.status.busy":"2024-09-12T14:41:29.977021Z","iopub.status.idle":"2024-09-12T14:41:29.982827Z","shell.execute_reply":"2024-09-12T14:41:29.981953Z","shell.execute_reply.started":"2024-09-12T14:41:29.977546Z"},"trusted":true},"outputs":[],"source":["#y_train1, y_test, x_train1, X_test= train_test_split(Y_train, x_train, test_size=0.2, shuffle=False, random_state=1)\n","#y_train, y_val, X_train, X_val= train_test_split(y_train1, x_train1, test_size=0.3, shuffle=True, stratify=y_train1, random_state=2)\n","#y_train, y_val, X_train, X_val= train_test_split(y_train1, x_train1, test_size=0.3, shuffle=False, random_state=7)\n","\n","Y_train, y_test, X_train, X_test= train_test_split(labels, features, test_size=0.3, shuffle=False, random_state=1)"]},{"cell_type":"markdown","metadata":{},"source":["## correlation e p_value"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.617818Z","iopub.status.busy":"2024-09-12T14:41:30.616974Z","iopub.status.idle":"2024-09-12T14:41:30.650271Z","shell.execute_reply":"2024-09-12T14:41:30.649099Z","shell.execute_reply.started":"2024-09-12T14:41:30.617778Z"},"trusted":true},"outputs":[],"source":["\n","## FEATURE CORRELATION\n","\n","X_train_reduced, dropped_features = remove_highly_correlated_features(X_train, 0.9)\n","#X_val_reduced = np.delete(X_val, dropped_features, axis=1)\n","X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","#print(X_val_reduced.shape)\n","\n","# RIMOZIONE FEATURES CON P_VALUE ELEVATO\n","\n","#X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, Y_train, alpha=0.05)\n","#X_val_reduced = X_val_reduced[:, features_to_keep]\n","#X_test_reduced = X_test_reduced[:, features_to_keep]\n","\n","\n","print(X_train_reduced.shape)\n","print(X_test_reduced.shape)\n","#print(X_val_reduced.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## parametri"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:30.820390Z","iopub.status.busy":"2024-09-12T14:41:30.820019Z","iopub.status.idle":"2024-09-12T14:41:30.825775Z","shell.execute_reply":"2024-09-12T14:41:30.824852Z","shell.execute_reply.started":"2024-09-12T14:41:30.820355Z"},"trusted":true},"outputs":[],"source":["alpha_values = np.linspace(0, 0.006, 30).tolist()\n","\n","thresholds=np.arange(0.4, 0.6, 0.001) \n","\n","\n","selectors=['p_value', 'mrmr','rf', 'logistic', 'lasso']\n","\n","classifiers=['XgBoost',  'SVM', 'ensemble','RandomForest', 'Logistic', 'MLP']\n"]},{"cell_type":"markdown","metadata":{},"source":["## loop cross val"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T14:41:31.611017Z","iopub.status.busy":"2024-09-12T14:41:31.610666Z"},"trusted":true},"outputs":[],"source":["n_folds=5\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","#scores = []\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'best_precision': None,\n","                'best_recall': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'best_threshold': None,\n","                'selected_features': []\n","            }\n","\n","## creazione di dizionari vuoti (range con numero elevato casuale)\n","results_val = [template_dict.copy() for _ in range(900000)]\n","results_val.append(template_dict.copy())\n","\n","\n","k=0\n","for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    for i, classifier in enumerate(classifiers):\n","        print(\"Starting with classifier:\", classifier)\n","        for j, selector in enumerate(selectors):\n","            print(\"Starting with selector:\", selector)\n","\n","            best_f1 = 0\n","            best_case = None\n","\n","            if(selector=='lasso'):\n","                for alpha in alpha_values:\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                    \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    best_case = classification_method(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, num_features=0, mode=\"Val\", selected_features=[0], thresholds=thresholds)\n","\n","                    if best_case:\n","                        results_val[k]['fold']=fold_idx\n","                        results_val[k]['classifier']=classifier\n","                        results_val[k]['selector']=selector\n","                        results_val[k]['alpha']=best_case['alpha']\n","                        results_val[k]['selected_features']=best_case['selected_features']\n","                        results_val[k]['pr_auc']=best_case['pr_auc']\n","                        results_val[k]['best_precision']=best_case['best_precision']\n","                        results_val[k]['best_recall']=best_case['best_recall']\n","                        results_val[k]['roc_auc']=best_case['roc_auc']\n","                        results_val[k]['f1']=best_case['f1']\n","                        results_val[k]['accuracy']=best_case['accuracy']\n","                        results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                        results_val[k]['best_threshold']=best_case['best_threshold']\n","\n","                        k=k+1\n","            \n","            else: \n","                #limit=len(x_train_reduced[0]) + 1\n","                limit=50\n","                for t in range(1, limit):\n","                    #print(\"Number of features \", t)\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                        \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    best_case = classification_method(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n","\n","\n","                    if best_case:\n","                        results_val[k]['num_features']=best_case['num_features']\n","                        results_val[k]['fold']=fold_idx\n","                        results_val[k]['classifier']=classifier\n","                        results_val[k]['selector']=selector\n","                        results_val[k]['selected_features']=best_case['selected_features']\n","                        results_val[k]['pr_auc']=best_case['pr_auc']\n","                        results_val[k]['best_precision']=best_case['best_precision']\n","                        results_val[k]['best_recall']=best_case['best_recall']\n","                        results_val[k]['roc_auc']=best_case['roc_auc']\n","                        results_val[k]['f1']=best_case['f1']\n","                        results_val[k]['accuracy']=best_case['accuracy']\n","                        results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                        results_val[k]['best_threshold']=best_case['best_threshold']\n","                        k=k+1\n"]},{"cell_type":"markdown","metadata":{},"source":["## trova configurazione migliore con gridsearch\n","fa una lista di tutte le combinazioni di configurazioni dalla migliore (considerando average f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import statistics\n","\n","# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","selectors = ['mrmr', 'rf', 'logistic', 'p_value', 'lasso']\n","#num_features_range = list(range(2, len(X_train_reduced[0]) + 1))\n","num_features_range=list(range(1,50))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features)\n","for classifier in classifiers:\n","    print(f\"sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        print(f\"sto iniziando selector {selector}\")\n","\n","        if (selector)=='lasso':\n","            for alpha in alpha_values:\n","                filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha]\n","\n","                if filtered_results:\n","                    pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                    f1_values = [res['f1'] for res in filtered_results]\n","                    accuracy_values = [res['accuracy'] for res in filtered_results]\n","                    \n","                    # Calcola le medie delle metriche\n","                    avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                    avg_f1 = sum(f1_values) / len(f1_values)\n","                    avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","                    \n","                    # Calcola la deviazione standard delle metriche\n","                    std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                    std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                    std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","                    \n","                    # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                    grid_results[(classifier, selector, alpha)] = {\n","                        'avg_pr_auc': avg_pr_auc,\n","                        'std_pr_auc': std_pr_auc,\n","                        'avg_f1': avg_f1,\n","                        'std_f1': std_f1,\n","                        'avg_accuracy': avg_accuracy,\n","                        'std_accuracy': std_accuracy\n","                    }\n","        \n","        else:\n","            for num_features in num_features_range:\n","                # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features]\n","                \n","                if filtered_results:\n","                    pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                    f1_values = [res['f1'] for res in filtered_results]\n","                    accuracy_values = [res['accuracy'] for res in filtered_results]\n","                    \n","                    # Calcola le medie delle metriche\n","                    avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                    avg_f1 = sum(f1_values) / len(f1_values)\n","                    avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","                    \n","                    # Calcola la deviazione standard delle metriche\n","                    std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                    std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                    std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","                    \n","                    # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                    grid_results[(classifier, selector, num_features)] = {\n","                        'avg_pr_auc': avg_pr_auc,\n","                        'std_pr_auc': std_pr_auc,\n","                        'avg_f1': avg_f1,\n","                        'std_f1': std_f1,\n","                        'avg_accuracy': avg_accuracy,\n","                        'std_accuracy': std_accuracy\n","                    }\n","\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']), reverse=True)"]},{"cell_type":"markdown","metadata":{},"source":["## salvataggio array"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Salva il dizionario in un file pickle\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_5foldVGG_max50_0.3', 'wb') as pickle_file:\n","    pickle.dump(sorted_results, pickle_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Carica il dizionario dal file pickle\n","\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_5foldVGG_max50_0.3', 'rb') as pickle_file:\n","    sorted_results = pickle.load(pickle_file)\n","\n","# Ora 'results_val' contiene i dati che hai salvato\n","print(\"Dati caricati correttamente:\", type(sorted_results))"]},{"cell_type":"markdown","metadata":{},"source":["## Stampa n risultati migliori per validation + performance su test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-12T14:28:28.238893Z","iopub.status.idle":"2024-09-12T14:28:28.239275Z","shell.execute_reply":"2024-09-12T14:28:28.239084Z","shell.execute_reply.started":"2024-09-12T14:28:28.239066Z"},"trusted":true},"outputs":[],"source":["n=10\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    #thresholds=np.arange(0.4, 0.6, 0.01)\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=0.5)\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=0.5)\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n","    print(f\"Best Threshold: {best_case['best_threshold']}\")"]},{"cell_type":"markdown","metadata":{},"source":["## codice che prende solo le configurazioni migliori per il test con una soglia di f1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["threshold_f1 = 0.6 # soglia minima dell'F1 Score\n","best_combination_found = False  # Flag per indicare se è stata trovata una buona combinazione\n","i = 0\n","\n","while not best_combination_found and i < len(sorted_results):\n","    params, metrics = sorted_results[i]\n","\n","    if params[0] == 'RandomForest':\n","        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","        classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","        classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","        logistic_model = LogisticRegression(random_state=42)\n","        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","        classi = VotingClassifier(\n","            estimators=[\n","                ('random_forest', rf_model),\n","                ('logistic', logistic_model),\n","                ('svc', svc_model)\n","            ],\n","            voting='soft'\n","        )\n","\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.3, 0.6, 0.01))\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=np.arange(0.3, 0.6, 0.01))\n","\n","\n","    # Controlla se l'F1 Score supera la soglia\n","    if best_case['f1'] >= threshold_f1:\n","        print(f\"\\n#Analizzando combinazione {i + 1}:\")\n","        print(f\"Classifier: {params[0]}\")\n","        print(f\"Selector: {params[1]}\")\n","        if(params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","        else: \n","            print(f\"Num_features: {params[2]}\")\n","\n","        print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","        #print(f\"\\nTrovata una combinazione con F1 Score >= {threshold_f1}\")\n","        \n","        #best_combination_found = True\n","        print(\"Metrics from best_case ON THE TEST SET:\")\n","        if(params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","        print(f\"Number of Features: {best_case['num_features']}\")\n","        print(f\"Selected Features: {best_case['selected_features']}\")\n","        print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","        #print(f\"Best Precision: {best_case['best_precision']}\")\n","        #print(f\"Best Recall: {best_case['best_recall']}\")\n","        print(f\"ROC AUC: {best_case['roc_auc']}\")\n","        print(f\"F1 Score: {best_case['f1']}\")\n","        print(f\"Accuracy: {best_case['accuracy']}\")\n","        print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n","        print(f\"Best Threshold: {best_case['best_threshold']}\")\n","        i += 1\n","    else:\n","        i += 1  # Passa alla prossima combinazione\n","\n","if not best_combination_found:\n","    print(f\"\\nNessuna combinazione con F1 Score >= {threshold_f1} è stata trovata.\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## PLOT"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Crea un pivot per visualizzare i dati nella heatmap\n","results_df = pd.DataFrame(results_val)\n","heatmap_data = results_df.pivot_table(index='classifier', columns='selector', values='f1', aggfunc='mean')\n","\n","# Crea la heatmap\n","plt.figure(figsize=(10, 6))\n","sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".3f\")\n","plt.title('F1-score medio per combinazione di Classifier e Selector')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Converto i risultati in un DataFrame per visualizzare meglio\n","results_df = pd.DataFrame(results_val)\n","\n","# Crea un boxplot per l'F1-score\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='classifier', y='f1', data=results_df)\n","plt.title('Distribuzione degli F1-score per ogni classificatore')\n","plt.show()\n","\n","# Crea un boxplot per PR AUC\n","plt.figure(figsize=(10, 6))\n","sns.boxplot(x='classifier', y='pr_auc', data=results_df)\n","plt.title('Distribuzione di PR AUC per ogni classificatore')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["# codice tuning threshold"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni diverse"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["\n","def classification_method_withoutThreshold(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0]):\n","\n","    if mode == \"Val\":\n","        selected_features = None \n","\n","        if num_features != len(x_train_expanded[0]) or alpha != 0:\n","            if selector == \"lasso\":\n","                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n","            elif selector == \"logistic\":\n","                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"mrmr\":\n","                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"rf\":\n","                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n","            elif selector == \"p_value\":\n","                X_selected, selected_features = select_features_by_p_value(x_train_expanded,y_train_expanded, num_features=num_features)\n","            else:\n","                print(\"Wrong selector. Choose between: mrmr, rf, logistic, p_value, lasso\")\n","                return\n","\n","            x_test = x_test[:, selected_features]  # selezione delle feature anche su x_test\n","        else:\n","            X_selected = x_train_expanded\n","            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n","\n","        number_features = len(selected_features)  # Numero di feature selezionate\n","\n","        # Training del classificatore\n","        classifier.fit(X_selected, y_train_expanded)\n","\n","\n","    if (mode == \"Test\"): ## non addestra il classificatore e non fa feature selection\n","        x_test = x_test[:, selected_features]\n","        number_features = len(selected_features)\n","    \n","\n","    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n","\n"," \n","    return y_proba_test, number_features, selected_features\n","\n","\n","\n","def classification_threshold(y_proba_test,y_test, threshold, alpha, number_features, selected_features):\n","        \n","            best_case = None\n","\n","            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n","            accuracy = accuracy_score(y_test, y_pred_custom_test)\n","            f1 = f1_score(y_test, y_pred_custom_test)\n","            roc_auc = roc_auc_score(y_test, y_pred_custom_test)\n","\n","            precision, recall, _ = precision_recall_curve(y_test, y_pred_custom_test)\n","            pr_auc = auc(recall, precision)\n","\n","            best_precision = precision[np.argmax(recall)]\n","            best_recall = recall[np.argmax(recall)]\n","\n","            conf = confusion_matrix(y_test, y_pred_custom_test)\n","            best_case = {\n","                    'alpha': alpha,\n","                    'num_features': number_features,\n","                    'selected_features': selected_features,\n","                    'pr_auc': pr_auc,\n","                    'best_precision': best_precision,\n","                    'best_recall': best_recall,\n","                    'roc_auc': roc_auc,\n","                    'f1': f1,\n","                    'accuracy': accuracy,\n","                    'confusion_matrix': conf,\n","                    'threshold': threshold\n","                }\n","            print(\"number features \", number_features)\n","                \n","            return best_case\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_folds=5\n","skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n","\n","thresholds=np.arange(0.42, 0.6, 0.01) \n","\n","#scores = []\n","template_dict = {\n","                'fold': None,\n","                'classifier': None,\n","                'selector': None,\n","                'alpha': None,\n","                'num_features': None,\n","                'pr_auc': None,\n","                'best_precision': None,\n","                'best_recall': None,\n","                'roc_auc': None,\n","                'f1': None,\n","                'accuracy': None,\n","                'confusion_matrix': [],\n","                'threshold': None,\n","                'selected_features': []\n","            }\n","\n","## creazione di dizionari vuoti (range con numero elevato casuale)\n","results_val = [template_dict.copy() for _ in range(900000)]\n","results_val.append(template_dict.copy())\n","\n","\n","k=0\n","for fold_idx, (train_index, val_index) in enumerate(skf.split(X_train_reduced, Y_train)):\n","    print(\"Starting with fold:\", fold_idx)\n","\n","    x_train_reduced, X_val_reduced = X_train_reduced[train_index], X_train_reduced[val_index]\n","    y_train, y_val = Y_train[train_index], Y_train[val_index]\n","\n","    for i, classifier in enumerate(classifiers):\n","        print(\"Starting with classifier:\", classifier)\n","        for j, selector in enumerate(selectors):\n","            print(\"Starting with selector:\", selector)\n","            if(selector=='lasso'):\n","                for alpha in alpha_values:\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                    \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, alpha, x_train_reduced, y_train, X_val_reduced, y_val, num_features=0, mode=\"Val\", selected_features=[0])\n","\n","                    for threshold in thresholds:\n","                        best_f1 = 0\n","                        best_case = None\n","\n","                        best_case=classification_threshold(y_proba_test,y_val, threshold, alpha, 0, selected_features)\n","\n","                        if best_case:\n","                            results_val[k]['fold']=fold_idx\n","                            results_val[k]['classifier']=classifier\n","                            results_val[k]['selector']=selector\n","                            results_val[k]['alpha']=best_case['alpha']\n","                            results_val[k]['num_features']=best_case['alpha']\n","                            results_val[k]['selected_features']=best_case['selected_features']\n","                            results_val[k]['pr_auc']=best_case['pr_auc']\n","                            results_val[k]['best_precision']=best_case['best_precision']\n","                            results_val[k]['best_recall']=best_case['best_recall']\n","                            results_val[k]['roc_auc']=best_case['roc_auc']\n","                            results_val[k]['f1']=best_case['f1']\n","                            results_val[k]['accuracy']=best_case['accuracy']\n","                            results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                            results_val[k]['threshold']=best_case['threshold']\n","\n","                            k=k+1\n","            \n","            else: \n","                #limit=len(x_train_reduced[0]) + 1\n","                limit=50\n","                for t in range(1, limit):\n","                    #print(\"Number of features \", t)\n","\n","                    if classifier == 'RandomForest':\n","                        classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        #selector_rf = SelectFromModel(classi, threshold='mean')\n","                        #X_train_rf = selector_rf.fit_transform(x_train_reduced, y_train)\n","                        #X_test_rf = selector_rf.transform(X_test_reduced)\n","                        #X_val_rf = selector_rf.transform(X_val_reduced)\n","                        #if(t>len(X_train_rf[0])):\n","                        #   continue\n","\n","                    elif classifier == 'Logistic':\n","                        classi = LogisticRegression()\n","                        #selector_lr = SelectFromModel(classi, threshold='mean')\n","                        #X_train_lr = selector_lr.fit_transform(x_train_reduced, y_train)\n","                        #X_test_lr = selector_lr.transform(X_test_reduced)\n","                        #X_val_lr = selector_lr.transform(X_val_reduced)\n","                        #if(t>len(X_train_lr[0])):\n","                        #    continue\n","                        \n","                    elif classifier == 'SVM':\n","                        classi = SVC(kernel='rbf', probability=True, random_state=42)\n","                    elif classifier == 'XgBoost':\n","                        classi = XGBClassifier()\n","                    elif classifier == 'MLP':\n","                        classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","                    elif classifier == 'ensemble':\n","                        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                        logistic_model = LogisticRegression(random_state=42)\n","                        svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","                        classi = VotingClassifier(\n","                            estimators=[\n","                                ('random_forest', rf_model),\n","                                ('logistic', logistic_model),\n","                                ('svc', svc_model)\n","                            ],\n","                            voting='soft'\n","                            )\n","\n","                    y_proba_test, number_features, selected_features = classification_method_withoutThreshold(selector, classi, 0, x_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n","\n","                    for threshold in thresholds:\n","                        best_f1 = 0\n","                        best_case = None\n","\n","                        best_case=classification_threshold(y_proba_test,y_val, threshold, 0, t, selected_features)\n","\n","                        if best_case:\n","                            results_val[k]['fold']=fold_idx\n","                            results_val[k]['classifier']=classifier\n","                            results_val[k]['selector']=selector\n","                            results_val[k]['alpha']=0\n","                            results_val[k]['num_features']=t\n","                            results_val[k]['selected_features']=best_case['selected_features']\n","                            results_val[k]['pr_auc']=best_case['pr_auc']\n","                            results_val[k]['best_precision']=best_case['best_precision']\n","                            results_val[k]['best_recall']=best_case['best_recall']\n","                            results_val[k]['roc_auc']=best_case['roc_auc']\n","                            results_val[k]['f1']=best_case['f1']\n","                            results_val[k]['accuracy']=best_case['accuracy']\n","                            results_val[k]['confusion_matrix']=best_case['confusion_matrix']\n","                            results_val[k]['threshold']=best_case['threshold']\n","\n","                            k=k+1\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(results_val)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Definizione delle possibili configurazioni di classificatori, selettori e numero di feature\n","classifiers = ['SVM']\n","#classifiers = ['SVM', 'RandomForest', 'ensemble', 'XgBoost', 'Logistic', 'MLP']\n","#selectors = ['mrmr', 'rf', 'logistic', 'p_value', 'lasso']\n","selectors = ['mrmr', 'rf']\n","thresholds = np.arange(0.42, 0.6, 0.01) \n","num_features_range = list(range(1, 50))\n","\n","grid_results = {}\n","\n","# Itera su tutte le combinazioni di parametri (classifier, selector, num_features, threshold)\n","for classifier in classifiers:\n","    print(f\"Sto iniziando classifier {classifier}\")\n","    for selector in selectors:\n","        print(f\"Sto iniziando selector {selector}\")\n","\n","        if selector == 'lasso':\n","            for alpha in alpha_values:\n","                for threshold in thresholds:\n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results = [res for res in results_val if res['classifier'] == classifier and res['selector'] == selector and res['alpha'] == alpha and res['threshold'] == threshold]\n","\n","                    if filtered_results:\n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results[(classifier, selector, alpha, threshold)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy\n","                        }\n","        \n","        else:\n","            for num_features in num_features_range:\n","                for threshold in thresholds:\n","                    # Filtra i risultati che corrispondono a questa combinazione di parametri\n","                    filtered_results=[]\n","                    for res in results_val:\n","                        print(res)\n","                        if (res['classifier'] == classifier and res['selector'] == selector and res['num_features'] == num_features and res['threshold'] == threshold):\n","                            filtered_results.append(res)\n","                    print(len(filtered_results))\n","                    if filtered_results:\n","                        pr_auc_values = [res['pr_auc'] for res in filtered_results]\n","                        f1_values = [res['f1'] for res in filtered_results]\n","                        accuracy_values = [res['accuracy'] for res in filtered_results]\n","\n","                        # Calcola le medie delle metriche\n","                        avg_pr_auc = sum(pr_auc_values) / len(pr_auc_values)\n","                        avg_f1 = sum(f1_values) / len(f1_values)\n","                        avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n","\n","                        # Calcola la deviazione standard delle metriche\n","                        std_pr_auc = statistics.stdev(pr_auc_values) if len(pr_auc_values) > 1 else 0\n","                        std_f1 = statistics.stdev(f1_values) if len(f1_values) > 1 else 0\n","                        std_accuracy = statistics.stdev(accuracy_values) if len(accuracy_values) > 1 else 0\n","\n","                        # Memorizza i risultati medi e la deviazione standard di questa combinazione\n","                        grid_results[(classifier, selector, num_features, threshold)] = {\n","                            'avg_pr_auc': avg_pr_auc,\n","                            'std_pr_auc': std_pr_auc,\n","                            'avg_f1': avg_f1,\n","                            'std_f1': std_f1,\n","                            'avg_accuracy': avg_accuracy,\n","                            'std_accuracy': std_accuracy\n","                        }\n","\n","# Ordina le combinazioni per 'avg_f1', e in caso di parità, per 'avg_pr_auc'\n","sorted_results = sorted(grid_results.items(), key=lambda x: (x[1]['avg_f1'], x[1]['avg_pr_auc']), reverse=True)\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# Salva il dizionario in un file pickle\n","with open('/Users/alessiamenozzi/Desktop/sorted_results_VGG_max50_0.3_threshold', 'wb') as pickle_file:\n","    pickle.dump(sorted_results, pickle_file)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n=10\n","best_3_combinations = sorted_results[:n] ## mostrando le n migliori configurazioni\n","print(best_3_combinations)\n","print(f\"Migliori {n} combinazioni di parametri:\")\n","for i, (params, metrics) in enumerate(best_3_combinations, start=1):\n","    print(f\"\\n#{i}:\")\n","    print(f\"Classifier: {params[0]}\")\n","    print(f\"Selector: {params[1]}\")\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {params[2]}\")\n","    print(f\"Num_features: {params[2]}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Performance medie: F1 = {metrics['avg_f1']} (std = {metrics['std_f1']}), \"\n","          f\"PR AUC = {metrics['avg_pr_auc']} (std = {metrics['std_pr_auc']}), \"\n","          f\"Accuracy = {metrics['avg_accuracy']} (std = {metrics['std_accuracy']})\")\n","\n","\n","    if params[0] == 'RandomForest':\n","                            classi = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif params[0] == 'Logistic':\n","                            classi = LogisticRegression()\n","    elif params[0] == 'SVM':\n","                            classi = SVC(kernel='rbf', probability=True, random_state=42)\n","    elif params[0] == 'XgBoost':\n","                            classi = XGBClassifier()\n","    elif params[0] == 'MLP':\n","                            classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n","    elif params[0] == 'ensemble':\n","                            rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","                            logistic_model = LogisticRegression(random_state=42)\n","                            svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n","\n","                            # Crea l'ensemble con VotingClassifier\n","                            classi = VotingClassifier(\n","                                estimators=[\n","                                    ('random_forest', rf_model),\n","                                    ('logistic', logistic_model),\n","                                    ('svc', svc_model)\n","                                ],\n","                                voting='soft'  # 'soft' usa le probabilità di classe, 'hard' usa le predizioni di classe\n","                                )\n","\n","    #thresholds=np.arange(0.4, 0.6, 0.01)\n","    if(params[1]=='lasso'):     \n","        best_case=classification_method(params[1], classi, params[2], X_train_reduced, Y_train, X_test_reduced, y_test, 0, mode=\"Val\", selected_features=[0], thresholds=params[3])\n","    else: \n","        best_case=classification_method(params[1], classi, 0, X_train_reduced, Y_train, X_test_reduced, y_test, params[2], mode=\"Val\", selected_features=[0], thresholds=params[3])\n","\n","\n","    print(\"Metrics from best_case ON THE TEST SET:\")\n","\n","    if (params[1]=='lasso'):\n","            print(f\"Alpha: {best_case['alpha']}\")\n","    print(f\"Number of Features: {best_case['num_features']}\")\n","    print(f\"Threshold: {params[3]}\")\n","    print(f\"Selected Features: {best_case['selected_features']}\")\n","    print(f\"Precision-Recall AUC: {best_case['pr_auc']}\")\n","    print(f\"Best Precision: {best_case['best_precision']}\")\n","    print(f\"Best Recall: {best_case['best_recall']}\")\n","    print(f\"ROC AUC: {best_case['roc_auc']}\")\n","    print(f\"F1 Score: {best_case['f1']}\")\n","    print(f\"Accuracy: {best_case['accuracy']}\")\n","    print(f\"Confusion Matrix: \\n{np.array(best_case['confusion_matrix'])}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filtro i risultati dove la soglia è 0.5\n","filtered_results = [res for res in sorted_results if res[0][3] == 0.5 and res[0][0]== 'ensemble' and res[0][1]=='logistic']\n","\n","# Stampa i risultati filtrati\n","for result in filtered_results:\n","    classifier, selector, num_features, threshold = result[0]\n","    metrics = result[1]\n","    \n","    print(f\"Classifier: {classifier}, Selector: {selector}, Num Features: {num_features}, Threshold: {threshold}\")\n","    print(f\"Avg PR AUC: {metrics['avg_pr_auc']}, Std PR AUC: {metrics['std_pr_auc']}\")\n","    print(f\"Avg F1: {metrics['avg_f1']}, Std F1: {metrics['std_f1']}\")\n","\n","    print(\"-\" * 50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filtered_results = [res for res in sorted_results if res[0][3] == 0.5]\n","print(res)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sorted_results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Conta gli elementi in results_val dove 'fold' è diverso da None\n","count_non_none_fold = sum(1 for res in results_val if res.get('threshold') is not None)\n","\n","print(f\"Numero di elementi con 'fold' diverso da None: {count_non_none_fold}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5686764,"sourceId":9375373,"sourceType":"datasetVersion"},{"datasetId":5686788,"sourceId":9375404,"sourceType":"datasetVersion"},{"datasetId":5687116,"sourceId":9375826,"sourceType":"datasetVersion"}],"dockerImageVersionId":30762,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
