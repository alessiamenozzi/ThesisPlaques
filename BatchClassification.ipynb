{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivi visibili a TensorFlow:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.initializers import he_normal, glorot_uniform, glorot_normal\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "devices = tf.config.experimental.list_physical_devices()\n",
    "print(\"Dispositivi visibili a TensorFlow:\")\n",
    "for device in devices:\n",
    "    print(device)\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Reshape, Flatten, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.initializers import HeNormal, GlorotUniform, Zeros\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#import pymrmr\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "import os\n",
    "rd=0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = np.linspace(0, 0.006, 30).tolist()\n",
    "alpha=0.003\n",
    "\n",
    "thresholds=np.arange(0.001, 0.501, 0.001) \n",
    "\n",
    "#selectors=['p_value', 'mrmr','rf', 'logistic', 'lasso']\n",
    "selectors=['p_value', 'mrmr','rf', 'logistic']\n",
    "classifiers=['XgBoost', 'MLP', 'SVM']\n",
    "#classifiers=['RandomForest', 'XgBoost', 'MLP', 'SVM']\n",
    "#classifiers=['RandomForest', 'Logistic', 'XgBoost', 'MLP', 'SVM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dati normali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
      "       ...\n",
      "       '1526', '1527', '1528', '1529', '1530', '1531', '1532', '1533', '1534',\n",
      "       '1535'],\n",
      "      dtype='object', length=1537)\n",
      "(124, 1536)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carica il file CSV\n",
    "file_path = \"/Users/alessiamenozzi/Desktop/ThesisPlaques/data_rad_clin_DEF.csv\"\n",
    "#file_path = \"C:\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ThesisPlaques\\\\data_rad_clin_DEF.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Lista degli ID da escludere\n",
    "ids_to_exclude = [\"patient_TC_19\", \"patient_TC_40\", \"patient_TC_88\", \"patient_TC_150\", \"patient_TC_193\"]\n",
    "\n",
    "# Filtra il DataFrame per escludere le righe con gli ID specificati\n",
    "filtered_data = data[~data['IDs_new'].isin(ids_to_exclude)]\n",
    "\n",
    "# Estrae i valori dalla colonna 'label' del DataFrame filtrato\n",
    "labels_column = filtered_data['label']\n",
    "\n",
    "# Converte i valori della colonna 'label' in numeri interi\n",
    "labels = labels_column.astype(int).tolist()\n",
    "\n",
    "Y_train=np.array(labels)\n",
    "\n",
    "df = pd.read_csv('/Users/alessiamenozzi/Desktop/tabella_risultati.csv')\n",
    "print(df.columns)\n",
    "# Supponiamo che i numeri dei pazienti siano nella prima colonna\n",
    "df.columns = ['numero_paziente'] + [f'feature_{i}' for i in range(1, 1537)]\n",
    "\n",
    "# Ordina i dati in base ai numeri dei pazienti\n",
    "df_sorted = df.sort_values(by='numero_paziente')\n",
    "\n",
    "# Estrai le feature in un array\n",
    "features_array = df_sorted.iloc[:, 1:].values\n",
    "X_train = np.array(features_array)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dati radiomica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        patient_TC_5\n",
      "1       patient_TC_12\n",
      "2       patient_TC_15\n",
      "3       patient_TC_16\n",
      "4       patient_TC_17\n",
      "            ...      \n",
      "124    patient_TC_193\n",
      "125    patient_TC_197\n",
      "126    patient_TC_199\n",
      "127    patient_TC_200\n",
      "128    patient_TC_205\n",
      "Name: IDs_new, Length: 129, dtype: object\n",
      "Labels: [0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0\n",
      " 1 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 1 1 0 1 1]\n",
      "Number of labels: 120\n",
      "['Paziente', 'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum', 'diagnostics_Mask-original_VoxelNum', 'diagnostics_Mask-original_VolumeNum', 'original_shape_Elongation', 'original_shape_Flatness', 'original_shape_LeastAxisLength', 'original_shape_MajorAxisLength', 'original_shape_Maximum2DDiameterColumn', 'original_shape_Maximum2DDiameterRow', 'original_shape_Maximum2DDiameterSlice', 'original_shape_Maximum3DDiameter', 'original_shape_MeshVolume', 'original_shape_MinorAxisLength', 'original_shape_Sphericity', 'original_shape_SurfaceArea', 'original_shape_SurfaceVolumeRatio', 'original_shape_VoxelVolume', 'original_firstorder_10Percentile', 'original_firstorder_90Percentile', 'original_firstorder_Energy', 'original_firstorder_Entropy', 'original_firstorder_InterquartileRange', 'original_firstorder_Kurtosis', 'original_firstorder_Maximum', 'original_firstorder_MeanAbsoluteDeviation', 'original_firstorder_Mean', 'original_firstorder_Median', 'original_firstorder_Minimum', 'original_firstorder_Range', 'original_firstorder_RobustMeanAbsoluteDeviation', 'original_firstorder_RootMeanSquared', 'original_firstorder_Skewness', 'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity', 'original_firstorder_Variance', 'original_glcm_Autocorrelation', 'original_glcm_ClusterProminence', 'original_glcm_ClusterShade', 'original_glcm_ClusterTendency', 'original_glcm_Contrast', 'original_glcm_Correlation', 'original_glcm_DifferenceAverage', 'original_glcm_DifferenceEntropy', 'original_glcm_DifferenceVariance', 'original_glcm_Id', 'original_glcm_Idm', 'original_glcm_Idmn', 'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2', 'original_glcm_InverseVariance', 'original_glcm_JointAverage', 'original_glcm_JointEnergy', 'original_glcm_JointEntropy', 'original_glcm_MCC', 'original_glcm_MaximumProbability', 'original_glcm_SumAverage', 'original_glcm_SumEntropy', 'original_glcm_SumSquares', 'original_gldm_DependenceEntropy', 'original_gldm_DependenceNonUniformity', 'original_gldm_DependenceNonUniformityNormalized', 'original_gldm_DependenceVariance', 'original_gldm_GrayLevelNonUniformity', 'original_gldm_GrayLevelVariance', 'original_gldm_HighGrayLevelEmphasis', 'original_gldm_LargeDependenceEmphasis', 'original_gldm_LargeDependenceHighGrayLevelEmphasis', 'original_gldm_LargeDependenceLowGrayLevelEmphasis', 'original_gldm_LowGrayLevelEmphasis', 'original_gldm_SmallDependenceEmphasis', 'original_gldm_SmallDependenceHighGrayLevelEmphasis', 'original_gldm_SmallDependenceLowGrayLevelEmphasis', 'original_glrlm_GrayLevelNonUniformity', 'original_glrlm_GrayLevelNonUniformityNormalized', 'original_glrlm_GrayLevelVariance', 'original_glrlm_HighGrayLevelRunEmphasis', 'original_glrlm_LongRunEmphasis', 'original_glrlm_LongRunHighGrayLevelEmphasis', 'original_glrlm_LongRunLowGrayLevelEmphasis', 'original_glrlm_LowGrayLevelRunEmphasis', 'original_glrlm_RunEntropy', 'original_glrlm_RunLengthNonUniformity', 'original_glrlm_RunLengthNonUniformityNormalized', 'original_glrlm_RunPercentage', 'original_glrlm_RunVariance', 'original_glrlm_ShortRunEmphasis', 'original_glrlm_ShortRunHighGrayLevelEmphasis', 'original_glrlm_ShortRunLowGrayLevelEmphasis', 'original_glszm_GrayLevelNonUniformity', 'original_glszm_GrayLevelNonUniformityNormalized', 'original_glszm_GrayLevelVariance', 'original_glszm_HighGrayLevelZoneEmphasis', 'original_glszm_LargeAreaEmphasis', 'original_glszm_LargeAreaHighGrayLevelEmphasis', 'original_glszm_LargeAreaLowGrayLevelEmphasis', 'original_glszm_LowGrayLevelZoneEmphasis', 'original_glszm_SizeZoneNonUniformity', 'original_glszm_SizeZoneNonUniformityNormalized', 'original_glszm_SmallAreaEmphasis', 'original_glszm_SmallAreaHighGrayLevelEmphasis', 'original_glszm_SmallAreaLowGrayLevelEmphasis', 'original_glszm_ZoneEntropy', 'original_glszm_ZonePercentage', 'original_glszm_ZoneVariance', 'original_ngtdm_Busyness', 'original_ngtdm_Coarseness', 'original_ngtdm_Complexity', 'original_ngtdm_Contrast', 'original_ngtdm_Strength']\n",
      "0        5\n",
      "1       12\n",
      "2       15\n",
      "3       16\n",
      "4       22\n",
      "      ... \n",
      "115    189\n",
      "116    190\n",
      "117    197\n",
      "118    199\n",
      "119    205\n",
      "Name: Paziente, Length: 120, dtype: int64\n",
      "[[-7.82822844e+02 -1.02400000e+03  3.07100000e+03 ...  2.69972505e+03\n",
      "   2.80963106e-02  1.00514866e+01]\n",
      " [-9.66090232e+02 -3.02400000e+03  3.07100000e+03 ...  5.06730171e+03\n",
      "   4.13964322e-02  9.21642811e+00]\n",
      " [-8.96630635e+02 -3.02400000e+03  3.07100000e+03 ...  3.95715175e+03\n",
      "   1.13273940e-02  2.75076797e+01]\n",
      " ...\n",
      " [-9.39521199e+02 -3.02400000e+03  3.07100000e+03 ...  2.38010395e+03\n",
      "   3.21141803e-02  3.22969245e+00]\n",
      " [-6.02441998e+02 -1.02400000e+03  3.07100000e+03 ...  1.36263582e+02\n",
      "   6.99679621e-02  4.97074683e-01]\n",
      " [-5.15162265e+02 -1.02400000e+03  3.07100000e+03 ...  4.02397749e+03\n",
      "   7.17804108e-02  4.97083572e+00]]\n",
      "(120, 112)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"/Users/alessiamenozzi/Desktop/ThesisPlaques/data_rad_clin_DEF.csv\"\n",
    "#file_path = \"C:\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ThesisPlaques\\\\data_rad_clin_DEF.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(data['IDs_new'])\n",
    "# Lista degli ID da escludere\n",
    "ids_to_exclude = [\"patient_TC_19\", \"patient_TC_40\", \"patient_TC_88\", \"patient_TC_150\", \"patient_TC_193\", \"patient_TC_200\", \"patient_TC_17\", \"patient_TC_107\", \"patient_TC_127\", ]\n",
    "\n",
    "\n",
    "# Filtra il DataFrame per escludere le righe con gli ID specificati\n",
    "filtered_data = data[~data['IDs_new'].isin(ids_to_exclude)]\n",
    "\n",
    "# Estrae i valori dalla colonna 'label' del DataFrame filtrato\n",
    "labels_column = filtered_data['label']\n",
    "\n",
    "# Converte i valori della colonna 'label' in numeri interi\n",
    "labels = labels_column.astype(int).tolist()\n",
    "\n",
    "Y_train=np.array(labels)\n",
    "print(\"Labels:\", Y_train)\n",
    "print(\"Number of labels:\", len(Y_train))\n",
    "\n",
    "file_path = \"/Users/alessiamenozzi/Desktop/ThesisPlaques/features_radiomiche.csv\" # Sostituisci con il percorso corretto\n",
    "df = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Verifica i nomi delle colonne\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Estrai i valori dalla colonna 'Paziente'\n",
    "labels = df['Paziente'].astype(int)\n",
    "print(labels)\n",
    "\n",
    "# Rimuovi la colonna 'Paziente' per ottenere solo le feature\n",
    "df_features = df.drop(columns=['Paziente'])\n",
    "\n",
    "# Converti le features in un array numpy\n",
    "X_train = df_features.to_numpy()\n",
    "\n",
    "print(X_train)\n",
    "print(X_train.shape)  # (120, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1, y_test, x_train1, X_test= train_test_split(Y_train, X_train, test_size=0.2, shuffle=False, random_state=1)\n",
    "y_train, y_val, x_train, X_val= train_test_split(y_train1, x_train1, test_size=0.3, shuffle=True, stratify=y_train1, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 42)\n",
      "(24, 42)\n",
      "(29, 42)\n",
      "[ 0  1  4  5  6  8 10 14 15 16 17 18 19 21 22 24 25 28 31 32 34 35 37 39\n",
      " 40]\n",
      "(67, 25)\n",
      "(24, 25)\n",
      "(29, 25)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_reduced, dropped_features = remove_highly_correlated_features(x_train, 0.9)\n",
    "\n",
    "# Riduci X_val e X_test usando le feature rimosse\n",
    "X_val_reduced = np.delete(X_val, dropped_features, axis=1)\n",
    "X_test_reduced = np.delete(X_test, dropped_features, axis=1)\n",
    "\n",
    "print(X_train_reduced.shape)\n",
    "\n",
    "print(X_test_reduced.shape)\n",
    "print(X_val_reduced.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Rimozione delle feature con p-value elevato\n",
    "X_train_reduced, features_to_keep = remove_high_pvalue_features(X_train_reduced, y_train, alpha=0.5)\n",
    "print(features_to_keep)\n",
    "X_val_reduced = X_val_reduced[:, features_to_keep]\n",
    "X_test_reduced = X_test_reduced[:, features_to_keep]\n",
    "\n",
    "\n",
    "print(X_train_reduced.shape)\n",
    "\n",
    "print(X_test_reduced.shape)\n",
    "print(X_val_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_correlation(X, threshold=0.85):\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    upper_triangle = np.triu(corr_matrix, k=1)\n",
    "    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n",
    "    return to_drop\n",
    "\n",
    "\n",
    "def remove_highly_correlated_features(X, threshold=0.85):\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    upper_triangle = np.triu(corr_matrix, k=1)\n",
    "    to_drop = [column for column in range(upper_triangle.shape[0]) if any(abs(upper_triangle[column, :]) > threshold)]\n",
    "    X_reduced = np.delete(X, to_drop, axis=1)\n",
    "    return X_reduced, to_drop\n",
    "\n",
    "\n",
    "def remove_high_pvalue_features(X, y, alpha=0.05):\n",
    "    selector = SelectKBest(score_func=f_classif, k='all')\n",
    "    selector.fit(X, y)\n",
    "    p_values = selector.pvalues_\n",
    "    features_to_keep = np.where(p_values < alpha)[0]\n",
    "    X_reduced = X[:, features_to_keep]\n",
    "    return X_reduced, features_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE SELECTION LASSO\n",
    "def select_features_with_lasso(X, y, alpha=0.001):\n",
    "    \n",
    "    # Fit Lasso regression model\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "\n",
    "    # Get coefficients\n",
    "    coefficients = lasso.coef_\n",
    "\n",
    "    # Select features with non-zero coefficients\n",
    "    selected_features = np.where(coefficients != 0)[0]\n",
    "\n",
    "    # Create new feature matrix with only selected features\n",
    "    X_selected = X[:, selected_features]\n",
    "\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FEATURE SELECTION LOGISTIC\n",
    "def logistic_regression_feature_selection(X, y, num_features):\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr.fit(X, y)\n",
    "    coef_abs = np.abs(lr.coef_)\n",
    "    feature_importances = np.mean(coef_abs, axis=0)\n",
    "    selected_features = feature_importances.argsort()[-num_features:][::-1]\n",
    "    # Create new feature matrix with only selected features\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "\n",
    "def mrmr_feature_selection(X, y, num_features):\n",
    "    # Calcolare l'informazione mutua tra ogni caratteristica e il target\n",
    "    mi = mutual_info_classif(X, y)\n",
    "    \n",
    "    # Standardizzare le caratteristiche\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Calcolare la distanza euclidea tra le caratteristiche\n",
    "    distances = squareform(pdist(X_scaled.T, 'euclidean'))\n",
    "    \n",
    "    selected_features = []\n",
    "    selected_indices = []\n",
    "    \n",
    "    # Selezionare la prima caratteristica con la massima informazione mutua\n",
    "    first_feature_index = np.argmax(mi)\n",
    "    selected_features.append(first_feature_index)\n",
    "    selected_indices.append(first_feature_index)\n",
    "    \n",
    "    # Iterare per selezionare le caratteristiche rimanenti\n",
    "    for _ in range(num_features - 1):\n",
    "        max_relevance = -np.inf\n",
    "        selected_feature_index = -1\n",
    "        \n",
    "        for i in range(X.shape[1]):\n",
    "            if i in selected_indices:\n",
    "                continue\n",
    "            \n",
    "            relevance = mi[i]\n",
    "            redundancy = np.mean(distances[i, selected_indices])\n",
    "            \n",
    "            mrmr_score = relevance - redundancy\n",
    "            \n",
    "            if mrmr_score > max_relevance:\n",
    "                max_relevance = mrmr_score\n",
    "                selected_feature_index = i\n",
    "        \n",
    "        selected_features.append(selected_feature_index)\n",
    "        selected_indices.append(selected_feature_index)\n",
    "\n",
    "    X_selected = X[:, selected_indices]\n",
    "    return X_selected, selected_indices\n",
    "\n",
    "\n",
    "\n",
    "## FEATURE SELECTION RANDOM FOREST\n",
    "def rf_feature_selection(X, y, num_features):\n",
    "    # Inizializza il classificatore Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    # Addestra il modello\n",
    "    rf.fit(X, y)\n",
    "    # Ottieni l'importanza delle caratteristiche\n",
    "    feature_importances = rf.feature_importances_\n",
    "    # Seleziona gli indici delle caratteristiche più importanti\n",
    "    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n",
    "    # Crea una nuova matrice di caratteristiche con solo le caratteristiche selezionate\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "\n",
    "def p_value_feature_selection(X, num_features):\n",
    "    \"\"\"\n",
    "    Seleziona le prime `num_features` caratteristiche dal vettore di caratteristiche.\n",
    "\n",
    "    Args:\n",
    "    X (np.ndarray): Matrice delle caratteristiche (numero di campioni, numero di caratteristiche).\n",
    "    num_features (int): Numero di caratteristiche da selezionare.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Nuova matrice delle caratteristiche con solo le caratteristiche selezionate.\n",
    "    np.ndarray: Indici delle caratteristiche selezionate.\n",
    "    \"\"\"\n",
    "    # Controlla se num_features è maggiore del numero totale di caratteristiche\n",
    "    if num_features > X.shape[1]:\n",
    "        raise ValueError(f\"num_features ({num_features}) è maggiore del numero totale di caratteristiche ({X.shape[1]})\")\n",
    "\n",
    "    # Seleziona i primi num_features indici\n",
    "    selected_features = np.arange(num_features)\n",
    "    \n",
    "    # Crea una nuova matrice di caratteristiche con solo le caratteristiche selezionate\n",
    "    X_selected = X[:, selected_features]\n",
    "    \n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n",
    "def filter_patients_features(filtered_patients, selected_features):\n",
    "    \"\"\"\n",
    "    Removes the non-selected features from the filtered_patients array.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_patients (list of numpy.ndarray): The list containing patients' images' features.\n",
    "    selected_features (numpy.ndarray): The indices of the selected features.\n",
    "\n",
    "    Returns:\n",
    "    list of numpy.ndarray: The new filtered_patients array with only the selected features.\n",
    "    \"\"\"\n",
    "    filtered_patients_selected = []\n",
    "\n",
    "    for patient_features in filtered_patients:\n",
    "        # Select only the features specified in selected_features\n",
    "        patient_features_selected = patient_features[:, selected_features]\n",
    "        filtered_patients_selected.append(patient_features_selected)\n",
    "\n",
    "    return filtered_patients_selected\n",
    "\n",
    "\n",
    "def select_features_by_p_value(x_train_expanded, y_train_expanded, p_value_threshold=0.01):\n",
    "\n",
    "    p_values = []\n",
    "    num_features = x_train_expanded.shape[1]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        feature = x_train_expanded[:, i]\n",
    "        group_0 = feature[y_train_expanded == 0]\n",
    "        group_1 = feature[y_train_expanded == 1]\n",
    "        t_stat, p_val = ttest_ind(group_0, group_1, equal_var=False)\n",
    "        p_values.append(p_val)\n",
    "\n",
    "    # Convertire i p-value in un array numpy per ordinare più facilmente\n",
    "    p_values = np.array(p_values)\n",
    "\n",
    "    # Selezionare le caratteristiche con p-value < soglia\n",
    "    selected_features_indices = np.where(p_values < p_value_threshold)[0]\n",
    "\n",
    "    # Ordinare le caratteristiche selezionate in base ai p-value\n",
    "    sorted_indices = selected_features_indices[np.argsort(p_values[selected_features_indices])]\n",
    "\n",
    "    x_train_expanded = x_train_expanded[:, sorted_indices]\n",
    "\n",
    "    return x_train_expanded, sorted_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funzione classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def classification_method(selector, classifier, alpha, x_train_expanded, y_train_expanded, x_test, y_test, num_features, mode=\"Val\", selected_features=[0], thresholds=np.arange(0.3, 0.6, 0.01)):\n",
    "    best_f1_score = 0\n",
    "    best_case = None\n",
    "\n",
    "    if mode == \"Val\":\n",
    "        selected_features = None  # Inizializziamo selected_features per prevenire l'errore UnboundLocalError\n",
    "\n",
    "        if num_features != len(x_train_expanded[0]) or alpha != 0:\n",
    "            if selector == \"lasso\":\n",
    "                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n",
    "            elif selector == \"logistic\":\n",
    "                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"mrmr\":\n",
    "                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"rf\":\n",
    "                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"p_value\":\n",
    "                X_selected, selected_features = p_value_feature_selection(x_train_expanded, num_features)\n",
    "            else:\n",
    "                print(\"Wrong selector. Choose between: mrmr, rf, logistic, lasso\")\n",
    "                return\n",
    "\n",
    "            x_test = x_test[:, selected_features]  # Applichiamo la selezione delle feature anche su x_test\n",
    "        else:\n",
    "            X_selected = x_train_expanded\n",
    "            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n",
    "\n",
    "        number_features = len(selected_features)  # Numero di feature selezionate\n",
    "\n",
    "        # Addestriamo il classificatore\n",
    "        classifier.fit(X_selected, y_train_expanded)\n",
    "\n",
    "\n",
    "    if (mode == \"Test\"):\n",
    "        print(len(selected_features))\n",
    "        x_test = x_test[:, selected_features]\n",
    "        number_features = len(selected_features)\n",
    "    \n",
    "        # Prevediamo le probabilità sul set di test\n",
    "    y_proba_test = classifier.predict_proba(x_test)[:, 1]\n",
    "\n",
    "\n",
    "    if(isinstance(thresholds, np.ndarray)== False):\n",
    "        thresholds=[thresholds]\n",
    "        print(thresholds)\n",
    "        \n",
    "    \n",
    "    for threshold in thresholds:\n",
    "            # Previsioni usando la soglia custom\n",
    "            y_pred_custom_test = (y_proba_test >= threshold).astype(int)\n",
    "\n",
    "            # Calcolo metriche\n",
    "            accuracy = accuracy_score(y_test, y_pred_custom_test)\n",
    "            f1 = f1_score(y_test, y_pred_custom_test)\n",
    "            roc_auc = roc_auc_score(y_test, y_proba_test)\n",
    "\n",
    "            # Precision-recall curve e AUC\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_proba_test)\n",
    "            pr_auc = auc(recall, precision)\n",
    "\n",
    "            # Miglior precisione e richiamo (basato su soglia personalizzata)\n",
    "            best_precision = precision[np.argmax(recall)]\n",
    "            best_recall = recall[np.argmax(recall)]\n",
    "\n",
    "            # Matrice di confusione\n",
    "            conf = confusion_matrix(y_test, y_pred_custom_test)\n",
    "\n",
    "            # Se il nuovo risultato è migliore rispetto al migliore attuale, aggiorniamo\n",
    "            if f1 > best_f1_score or (f1 == best_f1_score and pr_auc > (best_case['pr_auc'] if best_case else 0)):\n",
    "                best_f1_score = f1\n",
    "                best_case = {\n",
    "                    'alpha': alpha,\n",
    "                    'num_features': number_features,\n",
    "                    'selected_features': selected_features,\n",
    "                    'pr_auc': pr_auc,\n",
    "                    'best_precision': best_precision,\n",
    "                    'best_recall': best_recall,\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'f1': f1,\n",
    "                    'accuracy': accuracy,\n",
    "                    'confusion_matrix': conf,\n",
    "                    'best_threshold': threshold\n",
    "                }\n",
    "\n",
    "    return best_case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with classifier: XgBoost\n",
      "Starting with selector: p_value\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.32]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.4000000000000001]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.37000000000000005]\n",
      "Number of features  11\n",
      "11\n",
      "[0.32]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.4100000000000001]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.35000000000000003]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.31]\n",
      "Number of features  20\n",
      "20\n",
      "[0.33]\n",
      "Number of features  21\n",
      "21\n",
      "[0.4000000000000001]\n",
      "Number of features  22\n",
      "22\n",
      "[0.47000000000000014]\n",
      "Number of features  23\n",
      "23\n",
      "[0.5800000000000003]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n",
      "Starting with selector: mrmr\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.3]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.3]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.49000000000000016]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.38000000000000006]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.3]\n",
      "Number of features  22\n",
      "22\n",
      "[0.3]\n",
      "Number of features  23\n",
      "23\n",
      "[0.38000000000000006]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4300000000000001]\n",
      "Starting with selector: rf\n",
      "Number of features  2\n",
      "2\n",
      "[0.4300000000000001]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.4300000000000001]\n",
      "Number of features  5\n",
      "5\n",
      "[0.5500000000000003]\n",
      "Number of features  6\n",
      "6\n",
      "[0.49000000000000016]\n",
      "Number of features  7\n",
      "7\n",
      "[0.31]\n",
      "Number of features  8\n",
      "8\n",
      "[0.4000000000000001]\n",
      "Number of features  9\n",
      "9\n",
      "[0.35000000000000003]\n",
      "Number of features  10\n",
      "10\n",
      "[0.4200000000000001]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.36000000000000004]\n",
      "Number of features  13\n",
      "13\n",
      "[0.37000000000000005]\n",
      "Number of features  14\n",
      "14\n",
      "[0.36000000000000004]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.32]\n",
      "Number of features  17\n",
      "17\n",
      "[0.47000000000000014]\n",
      "Number of features  18\n",
      "18\n",
      "[0.38000000000000006]\n",
      "Number of features  19\n",
      "19\n",
      "[0.5500000000000003]\n",
      "Number of features  20\n",
      "20\n",
      "[0.31]\n",
      "Number of features  21\n",
      "21\n",
      "[0.5900000000000003]\n",
      "Number of features  22\n",
      "22\n",
      "[0.4300000000000001]\n",
      "Number of features  23\n",
      "23\n",
      "[0.35000000000000003]\n",
      "Number of features  24\n",
      "24\n",
      "[0.35000000000000003]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n",
      "Starting with selector: logistic\n",
      "Number of features  2\n",
      "2\n",
      "[0.38000000000000006]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.47000000000000014]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.3]\n",
      "Number of features  8\n",
      "8\n",
      "[0.31]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.5200000000000002]\n",
      "Number of features  11\n",
      "11\n",
      "[0.4500000000000001]\n",
      "Number of features  12\n",
      "12\n",
      "[0.5500000000000003]\n",
      "Number of features  13\n",
      "13\n",
      "[0.5400000000000003]\n",
      "Number of features  14\n",
      "14\n",
      "[0.34]\n",
      "Number of features  15\n",
      "15\n",
      "[0.4300000000000001]\n",
      "Number of features  16\n",
      "16\n",
      "[0.5500000000000003]\n",
      "Number of features  17\n",
      "17\n",
      "[0.5700000000000003]\n",
      "Number of features  18\n",
      "18\n",
      "[0.5100000000000002]\n",
      "Number of features  19\n",
      "19\n",
      "[0.5800000000000003]\n",
      "Number of features  20\n",
      "20\n",
      "[0.5200000000000002]\n",
      "Number of features  21\n",
      "21\n",
      "[0.5200000000000002]\n",
      "Number of features  22\n",
      "22\n",
      "[0.37000000000000005]\n",
      "Number of features  23\n",
      "23\n",
      "[0.34]\n",
      "Number of features  24\n",
      "24\n",
      "[0.4400000000000001]\n",
      "Number of features  25\n",
      "25\n",
      "[0.3]\n",
      "Starting with classifier: MLP\n",
      "Starting with selector: p_value\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.3]\n",
      "Number of features  5\n",
      "5\n",
      "[0.32]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.3]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.34]\n",
      "Number of features  22\n",
      "22\n",
      "[0.3]\n",
      "Number of features  23\n",
      "23\n",
      "[0.3]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.3]\n",
      "Starting with selector: mrmr\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.3]\n",
      "Number of features  5\n",
      "5\n",
      "[0.39000000000000007]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.3]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.3]\n",
      "Number of features  22\n",
      "22\n",
      "[0.3]\n",
      "Number of features  23\n",
      "23\n",
      "[0.3]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.47000000000000014]\n",
      "Starting with selector: rf\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.3]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.3]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.3]\n",
      "Number of features  22\n",
      "22\n",
      "[0.3]\n",
      "Number of features  23\n",
      "23\n",
      "[0.3]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.3]\n",
      "Starting with selector: logistic\n",
      "Number of features  2\n",
      "2\n",
      "[0.4200000000000001]\n",
      "Number of features  3\n",
      "3\n",
      "[0.3]\n",
      "Number of features  4\n",
      "4\n",
      "[0.3]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.4100000000000001]\n",
      "Number of features  8\n",
      "8\n",
      "[0.3]\n",
      "Number of features  9\n",
      "9\n",
      "[0.3]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.33]\n",
      "Number of features  15\n",
      "15\n",
      "[0.3]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.39000000000000007]\n",
      "Number of features  22\n",
      "22\n",
      "[0.3]\n",
      "Number of features  23\n",
      "23\n",
      "[0.3]\n",
      "Number of features  24\n",
      "24\n",
      "[0.3]\n",
      "Number of features  25\n",
      "25\n",
      "[0.3]\n",
      "Starting with classifier: SVM\n",
      "Starting with selector: p_value\n",
      "Number of features  2\n",
      "2\n",
      "[0.3]\n",
      "Number of features  3\n",
      "3\n",
      "[0.39000000000000007]\n",
      "Number of features  4\n",
      "4\n",
      "[0.39000000000000007]\n",
      "Number of features  5\n",
      "5\n",
      "[0.39000000000000007]\n",
      "Number of features  6\n",
      "6\n",
      "[0.39000000000000007]\n",
      "Number of features  7\n",
      "7\n",
      "[0.39000000000000007]\n",
      "Number of features  8\n",
      "8\n",
      "[0.39000000000000007]\n",
      "Number of features  9\n",
      "9\n",
      "[0.39000000000000007]\n",
      "Number of features  10\n",
      "10\n",
      "[0.3]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.36000000000000004]\n",
      "Number of features  16\n",
      "16\n",
      "[0.36000000000000004]\n",
      "Number of features  17\n",
      "17\n",
      "[0.36000000000000004]\n",
      "Number of features  18\n",
      "18\n",
      "[0.36000000000000004]\n",
      "Number of features  19\n",
      "19\n",
      "[0.35000000000000003]\n",
      "Number of features  20\n",
      "20\n",
      "[0.35000000000000003]\n",
      "Number of features  21\n",
      "21\n",
      "[0.35000000000000003]\n",
      "Number of features  22\n",
      "22\n",
      "[0.35000000000000003]\n",
      "Number of features  23\n",
      "23\n",
      "[0.35000000000000003]\n",
      "Number of features  24\n",
      "24\n",
      "[0.4200000000000001]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n",
      "Starting with selector: mrmr\n",
      "Number of features  2\n",
      "2\n",
      "[0.4500000000000001]\n",
      "Number of features  3\n",
      "3\n",
      "[0.39000000000000007]\n",
      "Number of features  4\n",
      "4\n",
      "[0.4400000000000001]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.4400000000000001]\n",
      "Number of features  7\n",
      "7\n",
      "[0.4400000000000001]\n",
      "Number of features  8\n",
      "8\n",
      "[0.4400000000000001]\n",
      "Number of features  9\n",
      "9\n",
      "[0.4400000000000001]\n",
      "Number of features  10\n",
      "10\n",
      "[0.4400000000000001]\n",
      "Number of features  11\n",
      "11\n",
      "[0.3]\n",
      "Number of features  12\n",
      "12\n",
      "[0.3]\n",
      "Number of features  13\n",
      "13\n",
      "[0.3]\n",
      "Number of features  14\n",
      "14\n",
      "[0.3]\n",
      "Number of features  15\n",
      "15\n",
      "[0.4200000000000001]\n",
      "Number of features  16\n",
      "16\n",
      "[0.3]\n",
      "Number of features  17\n",
      "17\n",
      "[0.3]\n",
      "Number of features  18\n",
      "18\n",
      "[0.3]\n",
      "Number of features  19\n",
      "19\n",
      "[0.3]\n",
      "Number of features  20\n",
      "20\n",
      "[0.3]\n",
      "Number of features  21\n",
      "21\n",
      "[0.4200000000000001]\n",
      "Number of features  22\n",
      "22\n",
      "[0.4200000000000001]\n",
      "Number of features  23\n",
      "23\n",
      "[0.4200000000000001]\n",
      "Number of features  24\n",
      "24\n",
      "[0.4200000000000001]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n",
      "Starting with selector: rf\n",
      "Number of features  2\n",
      "2\n",
      "[0.34]\n",
      "Number of features  3\n",
      "3\n",
      "[0.34]\n",
      "Number of features  4\n",
      "4\n",
      "[0.35000000000000003]\n",
      "Number of features  5\n",
      "5\n",
      "[0.39000000000000007]\n",
      "Number of features  6\n",
      "6\n",
      "[0.39000000000000007]\n",
      "Number of features  7\n",
      "7\n",
      "[0.39000000000000007]\n",
      "Number of features  8\n",
      "8\n",
      "[0.39000000000000007]\n",
      "Number of features  9\n",
      "9\n",
      "[0.39000000000000007]\n",
      "Number of features  10\n",
      "10\n",
      "[0.39000000000000007]\n",
      "Number of features  11\n",
      "11\n",
      "[0.39000000000000007]\n",
      "Number of features  12\n",
      "12\n",
      "[0.38000000000000006]\n",
      "Number of features  13\n",
      "13\n",
      "[0.38000000000000006]\n",
      "Number of features  14\n",
      "14\n",
      "[0.38000000000000006]\n",
      "Number of features  15\n",
      "15\n",
      "[0.38000000000000006]\n",
      "Number of features  16\n",
      "16\n",
      "[0.38000000000000006]\n",
      "Number of features  17\n",
      "17\n",
      "[0.38000000000000006]\n",
      "Number of features  18\n",
      "18\n",
      "[0.4000000000000001]\n",
      "Number of features  19\n",
      "19\n",
      "[0.4000000000000001]\n",
      "Number of features  20\n",
      "20\n",
      "[0.46000000000000013]\n",
      "Number of features  21\n",
      "21\n",
      "[0.46000000000000013]\n",
      "Number of features  22\n",
      "22\n",
      "[0.46000000000000013]\n",
      "Number of features  23\n",
      "23\n",
      "[0.46000000000000013]\n",
      "Number of features  24\n",
      "24\n",
      "[0.4200000000000001]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n",
      "Starting with selector: logistic\n",
      "Number of features  2\n",
      "2\n",
      "[0.4200000000000001]\n",
      "Number of features  3\n",
      "3\n",
      "[0.4200000000000001]\n",
      "Number of features  4\n",
      "4\n",
      "[0.46000000000000013]\n",
      "Number of features  5\n",
      "5\n",
      "[0.3]\n",
      "Number of features  6\n",
      "6\n",
      "[0.3]\n",
      "Number of features  7\n",
      "7\n",
      "[0.46000000000000013]\n",
      "Number of features  8\n",
      "8\n",
      "[0.46000000000000013]\n",
      "Number of features  9\n",
      "9\n",
      "[0.46000000000000013]\n",
      "Number of features  10\n",
      "10\n",
      "[0.46000000000000013]\n",
      "Number of features  11\n",
      "11\n",
      "[0.4500000000000001]\n",
      "Number of features  12\n",
      "12\n",
      "[0.35000000000000003]\n",
      "Number of features  13\n",
      "13\n",
      "[0.35000000000000003]\n",
      "Number of features  14\n",
      "14\n",
      "[0.35000000000000003]\n",
      "Number of features  15\n",
      "15\n",
      "[0.35000000000000003]\n",
      "Number of features  16\n",
      "16\n",
      "[0.35000000000000003]\n",
      "Number of features  17\n",
      "17\n",
      "[0.35000000000000003]\n",
      "Number of features  18\n",
      "18\n",
      "[0.33]\n",
      "Number of features  19\n",
      "19\n",
      "[0.33]\n",
      "Number of features  20\n",
      "20\n",
      "[0.35000000000000003]\n",
      "Number of features  21\n",
      "21\n",
      "[0.38000000000000006]\n",
      "Number of features  22\n",
      "22\n",
      "[0.34]\n",
      "Number of features  23\n",
      "23\n",
      "[0.34]\n",
      "Number of features  24\n",
      "24\n",
      "[0.35000000000000003]\n",
      "Number of features  25\n",
      "25\n",
      "[0.4200000000000001]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_recall_curve, auc, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Lista per salvare i risultati\n",
    "results_test = [{} for _ in range(len(classifiers))]\n",
    "results_val = [{} for _ in range(len(classifiers))]\n",
    "\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    print(\"Starting with classifier:\", classifier)\n",
    "    for selector in selectors:\n",
    "        print(\"Starting with selector:\", selector)\n",
    "        results_test[i][selector] = {\n",
    "            'classifier': classifier,\n",
    "            'alpha': [],\n",
    "            'num_features': [],\n",
    "            'pr_auc': [],\n",
    "            'best_precision': [],\n",
    "            'best_recall': [],\n",
    "            'roc_auc': [],\n",
    "            'f1': [],\n",
    "            'accuracy': [],\n",
    "            'confusion_matrix': [],\n",
    "            'best_threshold': [],\n",
    "            'selected_features': []\n",
    "        }\n",
    "        results_val[i][selector] = {\n",
    "            'classifier': classifier,\n",
    "            'alpha': [],\n",
    "            'num_features': [],\n",
    "            'pr_auc': [],\n",
    "            'best_precision': [],\n",
    "            'best_recall': [],\n",
    "            'roc_auc': [],\n",
    "            'f1': [],\n",
    "            'accuracy': [],\n",
    "            'confusion_matrix': [],\n",
    "            'best_threshold': [],\n",
    "            'selected_features': []\n",
    "        }\n",
    "\n",
    "        best_f1 = 0\n",
    "        best_case = None\n",
    "\n",
    "        for t in range(2, len(X_train_reduced[0]) + 1):\n",
    "            # Seleziona le feature ridotte\n",
    "            print(\"Number of features \", t)\n",
    "\n",
    "            # Selezione del classificatore\n",
    "            if classifier == 'RandomForest':\n",
    "                classi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            elif classifier == 'Logistic':\n",
    "                classi = LogisticRegression()\n",
    "            elif classifier == 'SVM':\n",
    "                classi = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "            elif classifier == 'XgBoost':\n",
    "                classi = XGBClassifier()\n",
    "            elif classifier == 'MLP':\n",
    "                classi = MLPClassifier(hidden_layer_sizes=(128, 64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n",
    "\n",
    "\n",
    "            best_case = classification_method(selector, classi, alpha, X_train_reduced, y_train, X_val_reduced, y_val, num_features=t, mode=\"Val\", selected_features=[0])\n",
    "\n",
    "\n",
    "            if best_case:\n",
    "                results_val[i][selector]['alpha'].append(best_case['alpha'])\n",
    "                results_val[i][selector]['selected_features'].append(best_case['selected_features'])\n",
    "                results_val[i][selector]['num_features'].append(best_case['num_features'])\n",
    "                results_val[i][selector]['pr_auc'].append(best_case['pr_auc'])\n",
    "                results_val[i][selector]['best_precision'].append(best_case['best_precision'])\n",
    "                results_val[i][selector]['best_recall'].append(best_case['best_recall'])\n",
    "                results_val[i][selector]['roc_auc'].append(best_case['roc_auc'])\n",
    "                results_val[i][selector]['f1'].append(best_case['f1'])\n",
    "                results_val[i][selector]['accuracy'].append(best_case['accuracy'])\n",
    "                results_val[i][selector]['confusion_matrix'].append(best_case['confusion_matrix'])\n",
    "                results_val[i][selector]['best_threshold'].append(best_case['best_threshold'])\n",
    "            \n",
    "            best_case = classification_method(selector, classi, alpha, X_train_reduced, y_train, X_test_reduced, y_test, num_features=t, mode=\"Test\", selected_features=best_case['selected_features'], thresholds=best_case['best_threshold'])\n",
    "            if best_case:\n",
    "                results_test[i][selector]['alpha'].append(best_case['alpha'])\n",
    "                results_test[i][selector]['selected_features'].append(best_case['selected_features'])\n",
    "                results_test[i][selector]['num_features'].append(best_case['num_features'])\n",
    "                results_test[i][selector]['pr_auc'].append(best_case['pr_auc'])\n",
    "                results_test[i][selector]['best_precision'].append(best_case['best_precision'])\n",
    "                results_test[i][selector]['best_recall'].append(best_case['best_recall'])\n",
    "                results_test[i][selector]['roc_auc'].append(best_case['roc_auc'])\n",
    "                results_test[i][selector]['f1'].append(best_case['f1'])\n",
    "                results_test[i][selector]['accuracy'].append(best_case['accuracy'])\n",
    "                results_test[i][selector]['confusion_matrix'].append(best_case['confusion_matrix'])\n",
    "                results_test[i][selector]['best_threshold'].append(best_case['best_threshold'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top 1 Validation Result ---\n",
      "Classifier: SVM, Selector: p_value\n",
      "Alpha: 0.003\n",
      "Num Features: 3\n",
      "PR AUC: 0.5800343212874701\n",
      "Best Precision: 0.4827586206896552\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.6095238095238095\n",
      "F1 Score: 0.7567567567567568\n",
      "Accuracy: 0.6896551724137931\n",
      "Confusion Matrix:\n",
      "[[ 6  9]\n",
      " [ 0 14]]\n",
      "Best Threshold: 0.39000000000000007\n",
      "\n",
      "--- Corresponding Test Result ---\n",
      "Classifier: SVM, Selector: p_value\n",
      "Alpha: 0.003\n",
      "Num Features: 3\n",
      "PR AUC: 0.7901350482377959\n",
      "Best Precision: 0.3333333333333333\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.796875\n",
      "F1 Score: 0.5454545454545454\n",
      "Accuracy: 0.5833333333333334\n",
      "Confusion Matrix:\n",
      "[[8 8]\n",
      " [2 6]]\n",
      "Best Threshold: 0.39000000000000007\n",
      "\n",
      "--- Top 2 Validation Result ---\n",
      "Classifier: SVM, Selector: mrmr\n",
      "Alpha: 0.003\n",
      "Num Features: 3\n",
      "PR AUC: 0.5800343212874701\n",
      "Best Precision: 0.4827586206896552\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.6095238095238095\n",
      "F1 Score: 0.7567567567567568\n",
      "Accuracy: 0.6896551724137931\n",
      "Confusion Matrix:\n",
      "[[ 6  9]\n",
      " [ 0 14]]\n",
      "Best Threshold: 0.39000000000000007\n",
      "\n",
      "--- Corresponding Test Result ---\n",
      "Classifier: SVM, Selector: mrmr\n",
      "Alpha: 0.003\n",
      "Num Features: 3\n",
      "PR AUC: 0.7901350482377959\n",
      "Best Precision: 0.3333333333333333\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.796875\n",
      "F1 Score: 0.5454545454545454\n",
      "Accuracy: 0.5833333333333334\n",
      "Confusion Matrix:\n",
      "[[8 8]\n",
      " [2 6]]\n",
      "Best Threshold: 0.39000000000000007\n",
      "\n",
      "--- Top 3 Validation Result ---\n",
      "Classifier: SVM, Selector: rf\n",
      "Alpha: 0.003\n",
      "Num Features: 2\n",
      "PR AUC: 0.5800343212874701\n",
      "Best Precision: 0.4827586206896552\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.6095238095238095\n",
      "F1 Score: 0.7567567567567568\n",
      "Accuracy: 0.6896551724137931\n",
      "Confusion Matrix:\n",
      "[[ 6  9]\n",
      " [ 0 14]]\n",
      "Best Threshold: 0.34\n",
      "\n",
      "--- Corresponding Test Result ---\n",
      "Classifier: SVM, Selector: rf\n",
      "Alpha: 0.003\n",
      "Num Features: 2\n",
      "PR AUC: 0.7901350482377959\n",
      "Best Precision: 0.3333333333333333\n",
      "Best Recall: 1.0\n",
      "ROC AUC: 0.796875\n",
      "F1 Score: 0.5\n",
      "Accuracy: 0.5\n",
      "Confusion Matrix:\n",
      "[[ 6 10]\n",
      " [ 2  6]]\n",
      "Best Threshold: 0.34\n"
     ]
    }
   ],
   "source": [
    "def get_top_n_overall_results(results, n=3, metric='f1'):\n",
    "    \"\"\"\n",
    "    Ordina i risultati complessivi di tutti i classificatori e selettori in base alla metrica specificata\n",
    "    e restituisce i migliori N risultati.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        for selector in selectors:\n",
    "            for j in range(len(results[i][selector][metric])):\n",
    "                all_results.append({\n",
    "                    'classifier': classifier,\n",
    "                    'selector': selector,\n",
    "                    'alpha': results[i][selector]['alpha'][j],\n",
    "                    'selected_features': results[i][selector]['selected_features'][j],\n",
    "                    'num_features': results[i][selector]['num_features'][j],\n",
    "                    'pr_auc': results[i][selector]['pr_auc'][j],\n",
    "                    'best_precision': results[i][selector]['best_precision'][j],\n",
    "                    'best_recall': results[i][selector]['best_recall'][j],\n",
    "                    'roc_auc': results[i][selector]['roc_auc'][j],\n",
    "                    'f1': results[i][selector]['f1'][j],\n",
    "                    'accuracy': results[i][selector]['accuracy'][j],\n",
    "                    'confusion_matrix': results[i][selector]['confusion_matrix'][j],\n",
    "                    'best_threshold': results[i][selector]['best_threshold'][j],\n",
    "                    'index': (i, selector, j)  # Memorizza l'indice per corrispondere con il test set\n",
    "                })\n",
    "    \n",
    "    # Ordina tutti i risultati in base alla metrica specificata\n",
    "    sorted_results = sorted(all_results, key=lambda x: x[metric], reverse=True)\n",
    "    \n",
    "    return sorted_results[:n]  # Restituisce i migliori N risultati\n",
    "\n",
    "\n",
    "# Trova i migliori 3 risultati complessivi per il validation set\n",
    "top_val_results = get_top_n_overall_results(results_val, n=3, metric='f1')\n",
    "\n",
    "# Stampa i 3 migliori risultati di validazione e i loro rispettivi valori di test\n",
    "for idx, val_case in enumerate(top_val_results):\n",
    "    i, selector, j = val_case['index']  # Recupera l'indice originale del risultato\n",
    "    \n",
    "    print(f\"\\n--- Top {idx+1} Validation Result ---\")\n",
    "    print(f\"Classifier: {val_case['classifier']}, Selector: {val_case['selector']}\")\n",
    "    print(f\"Alpha: {val_case['alpha']}\")\n",
    "    print(f\"Num Features: {val_case['num_features']}\")\n",
    "    print(f\"PR AUC: {val_case['pr_auc']}\")\n",
    "    print(f\"Best Precision: {val_case['best_precision']}\")\n",
    "    print(f\"Best Recall: {val_case['best_recall']}\")\n",
    "    print(f\"ROC AUC: {val_case['roc_auc']}\")\n",
    "    print(f\"F1 Score: {val_case['f1']}\")\n",
    "    print(f\"Accuracy: {val_case['accuracy']}\")\n",
    "    print(f\"Confusion Matrix:\\n{val_case['confusion_matrix']}\")\n",
    "    print(f\"Best Threshold: {val_case['best_threshold']}\")\n",
    "\n",
    "    # Ora stampa i corrispondenti risultati del test set\n",
    "    print(f\"\\n--- Corresponding Test Result ---\")\n",
    "    print(f\"Classifier: {val_case['classifier']}, Selector: {val_case['selector']}\")\n",
    "    print(f\"Alpha: {results_test[i][selector]['alpha'][j]}\")\n",
    "    print(f\"Num Features: {results_test[i][selector]['num_features'][j]}\")\n",
    "    print(f\"PR AUC: {results_test[i][selector]['pr_auc'][j]}\")\n",
    "    print(f\"Best Precision: {results_test[i][selector]['best_precision'][j]}\")\n",
    "    print(f\"Best Recall: {results_test[i][selector]['best_recall'][j]}\")\n",
    "    print(f\"ROC AUC: {results_test[i][selector]['roc_auc'][j]}\")\n",
    "    print(f\"F1 Score: {results_test[i][selector]['f1'][j]}\")\n",
    "    print(f\"Accuracy: {results_test[i][selector]['accuracy'][j]}\")\n",
    "    print(f\"Confusion Matrix:\\n{results_test[i][selector]['confusion_matrix'][j]}\")\n",
    "    print(f\"Best Threshold: {results_test[i][selector]['best_threshold'][j]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
