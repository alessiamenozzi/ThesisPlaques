{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8469228,"sourceType":"datasetVersion","datasetId":5049797},{"sourceId":8477799,"sourceType":"datasetVersion","datasetId":5056158},{"sourceId":8479504,"sourceType":"datasetVersion","datasetId":5057405}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T14:06:44.274582Z","iopub.execute_input":"2024-05-22T14:06:44.274943Z","iopub.status.idle":"2024-05-22T14:06:44.295929Z","shell.execute_reply.started":"2024-05-22T14:06:44.274916Z","shell.execute_reply":"2024-05-22T14:06:44.295017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pymrmr","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:06:44.955164Z","iopub.execute_input":"2024-05-22T14:06:44.955530Z","iopub.status.idle":"2024-05-22T14:07:06.486176Z","shell.execute_reply.started":"2024-05-22T14:06:44.955503Z","shell.execute_reply":"2024-05-22T14:07:06.485132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\n\n# Import libraries\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications import ResNet50\nfrom sklearn.model_selection import train_test_split\n\nimport random\nrandom.seed(seed)\n\nimport matplotlib.pyplot as plt\nimport cv2\n#from google.colab.patches import cv2_imshow\nimport numpy as np\nimport os\nimport glob\nfrom PIL import Image\nfrom imgaug import augmenters as iaa\nfrom skimage.transform import resize\n\nimport numpy as np\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:07:06.488432Z","iopub.execute_input":"2024-05-22T14:07:06.489277Z","iopub.status.idle":"2024-05-22T14:07:06.984327Z","shell.execute_reply.started":"2024-05-22T14:07:06.489237Z","shell.execute_reply":"2024-05-22T14:07:06.983564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Ste","metadata":{}},{"cell_type":"code","source":"X_train=np.load(\"/kaggle/input/immagini-nuove/images_array.npy\")\nY_train=np.load(\"/kaggle/input/immagini-nuove/labels_array.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:07:06.985539Z","iopub.execute_input":"2024-05-22T14:07:06.986892Z","iopub.status.idle":"2024-05-22T14:07:09.164304Z","shell.execute_reply.started":"2024-05-22T14:07:06.986857Z","shell.execute_reply":"2024-05-22T14:07:09.163502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(Y_train, return_counts = True))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:07:09.166152Z","iopub.execute_input":"2024-05-22T14:07:09.166529Z","iopub.status.idle":"2024-05-22T14:07:09.175923Z","shell.execute_reply.started":"2024-05-22T14:07:09.166497Z","shell.execute_reply":"2024-05-22T14:07:09.174831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Ale","metadata":{}},{"cell_type":"code","source":"X_train=np.load(\"/kaggle/input/dataset/archive-2/images_array.npy\")\nY_train=np.load(\"/kaggle/input/dataset/archive-2/labels_array.npy\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:07:09.177042Z","iopub.execute_input":"2024-05-22T14:07:09.177341Z","iopub.status.idle":"2024-05-22T14:07:09.419300Z","shell.execute_reply.started":"2024-05-22T14:07:09.177318Z","shell.execute_reply":"2024-05-22T14:07:09.418182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dividi i dati in set di addestramento, validazione e test\nx_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=32)\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.1, random_state=32) \n\n# Assicurati che le dimensioni siano corrette\nprint(\"Dimensioni set di addestramento:\", x_train.shape, y_train.shape)\nprint(\"Dimensioni set di validazione:\", x_val.shape, y_val.shape)\nprint(\"Dimensioni set di test:\", x_test.shape, y_test.shape)\n\n\nx_train=x_train.astype('float32')/255.\nx_val=x_val.astype('float32')/255.\nx_test=x_test.astype('float32')/255.\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:29:49.941352Z","iopub.execute_input":"2024-05-22T15:29:49.942210Z","iopub.status.idle":"2024-05-22T15:29:50.533644Z","shell.execute_reply.started":"2024-05-22T15:29:49.942174Z","shell.execute_reply":"2024-05-22T15:29:50.532602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(np.unique(y_train, return_counts = True))\nprint(np.unique(y_val, return_counts = True))\nprint(np.unique(y_test, return_counts = True))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:29:52.193205Z","iopub.execute_input":"2024-05-22T15:29:52.194031Z","iopub.status.idle":"2024-05-22T15:29:52.201518Z","shell.execute_reply.started":"2024-05-22T15:29:52.194000Z","shell.execute_reply":"2024-05-22T15:29:52.200512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import AdamW\n\nclass PrintLearningRate(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        lr = float(self.model.optimizer.learning_rate.numpy())  # Ottenere il valore numerico del tasso di apprendimento\n        print(f'Epoch {epoch+1}: Learning Rate = {lr}')\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  # Monitora la perdita sulla tua valutazione\n    patience=20,          # Numero di epoche senza miglioramenti prima di fermare l'addestramento\n    restore_best_weights=True  # Ripristina i pesi del modello alla migliore iterazione\n)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',  # Monitora la perdita sulla tua valutazione\n    factor=0.1,          # Fattore di riduzione del tasso di apprendimento (riduce il tasso di apprendimento di un fattore di 0.2)\n    patience=10,          # Numero di epoche senza miglioramenti prima di ridurre il tasso di apprendimento\n    min_lr=1e-10         # Limite inferiore del tasso di apprendimento\n)\n\nlearning_rate = 1e-3\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:25:26.599568Z","iopub.execute_input":"2024-05-22T16:25:26.600202Z","iopub.status.idle":"2024-05-22T16:25:26.608040Z","shell.execute_reply.started":"2024-05-22T16:25:26.600165Z","shell.execute_reply":"2024-05-22T16:25:26.606906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import GlobalAveragePooling2D,BatchNormalization\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Reshape, Flatten, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l1\n\n\n### Modello ALE\ndef encoder(input_shape):\n    inputs = Input(shape=input_shape)\n    x = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = GlobalAveragePooling2D()(x)  # Global Average Pooling\n    x = Flatten()(x)\n    encoded = Dense(64, activation='relu', kernel_regularizer=l1(10e-8))(x)\n    encoder_model = Model(inputs, encoded, name='encoder')\n    encoder_model.summary()\n    return encoder_model\n\ndef decoder(output_shape):\n    inputs = Input(shape=output_shape)\n    x = Dense(2*2*256, activation='relu')(inputs)\n    x = Reshape((2, 2, 256))(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n    #x = UpSampling2D((2, 2))(x)\n    #x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    #x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n    #x = UpSampling2D((2, 2))(x)\n    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n    decoder_model = Model(inputs, decoded, name='decoder')\n    decoder_model.summary()\n    return decoder_model\n\n\n\ninput_shape = (64, 64, 1)\nencoder_model = encoder(input_shape)\ndecoder_model = decoder(encoder_model.output_shape[1:])\n\ninputs = Input(shape=input_shape)\nencoded = encoder_model(inputs)\ndecoded = decoder_model(encoded)\nautoencoder_model = Model(inputs, decoded, name='autoencoder')\n\n\n# Compilazione dell'autoencoder\nautoencoder_model.compile(optimizer=AdamW(learning_rate=learning_rate), loss='binary_crossentropy')\n\n# Visualizzazione dell'architettura dell'autoencoder\nautoencoder_model.summary()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:25:29.409543Z","iopub.execute_input":"2024-05-22T16:25:29.409884Z","iopub.status.idle":"2024-05-22T16:25:29.617584Z","shell.execute_reply.started":"2024-05-22T16:25:29.409860Z","shell.execute_reply":"2024-05-22T16:25:29.616685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Addestramento dell'autoencoder\nautoencoder_model.fit(x_train, x_train,\n                      epochs=1000,\n                      batch_size=256,\n                      shuffle=True,\n                      validation_data=(x_val, x_val),\n                      callbacks=[early_stopping, reduce_lr])\n\n#encoder_model.save('encoder_model16.h5')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T16:25:34.888446Z","iopub.execute_input":"2024-05-22T16:25:34.888947Z","iopub.status.idle":"2024-05-22T16:45:32.733813Z","shell.execute_reply.started":"2024-05-22T16:25:34.888912Z","shell.execute_reply":"2024-05-22T16:45:32.732862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Numero di immagini da visualizzare\nnum_images = 10\n\nreconstructed_images = autoencoder_model.predict(x_test)\n\n\n# Visualizzazione delle immagini originali e ricostruite\nplt.figure(figsize=(15, 6))\nfor i in range(num_images):\n    # Immagine originale\n    plt.subplot(2, num_images, i + 1)\n    plt.imshow(x_test[i], cmap='gray')\n    plt.title('Originale')\n    plt.axis('off')\n\n    # Immagine ricostruita\n    plt.subplot(2, num_images, i + num_images + 1)\n    plt.imshow(reconstructed_images[i], cmap='gray')\n    plt.title('Ricostruita')\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-22T16:48:49.285506Z","iopub.execute_input":"2024-05-22T16:48:49.285902Z","iopub.status.idle":"2024-05-22T16:48:53.706361Z","shell.execute_reply.started":"2024-05-22T16:48:49.285873Z","shell.execute_reply":"2024-05-22T16:48:53.705343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# classificatori","metadata":{}},{"cell_type":"markdown","source":"## Ottenimento features\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom keras.models import load_model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n\n#encoder_model = load_model('encoder_model16.h5')\n#encoder_model = load_model('encoder_model32.h5')\n#encoder_model = load_model('encoder_model64.h5')\n\n#encoder_model = load_model('/kaggle/input/modelli/encoder_model16.h5')\nencoder_model = load_model('/kaggle/input/modelli/encoder_model32.h5')\n#encoder_model = load_model('/kaggle/input/modelli/encoder_model64.h5')\n\n# Usa l'encoder per ottenere le feature da ciascun set\nX_train_encoded = encoder_model.predict(x_train)\nX_val_encoded = encoder_model.predict(x_val)\nX_test_encoded = encoder_model.predict(x_test)\n\n# Verifica la forma delle feature estratte\nprint(f\"Shape of encoded train features: {X_train_encoded.shape}\")\nprint(f\"Shape of encoded val features: {X_val_encoded.shape}\")\nprint(f\"Shape of encoded test features: {X_test_encoded.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:07:28.965208Z","iopub.execute_input":"2024-05-22T14:07:28.965601Z","iopub.status.idle":"2024-05-22T14:07:42.196738Z","shell.execute_reply.started":"2024-05-22T14:07:28.965571Z","shell.execute_reply":"2024-05-22T14:07:42.195852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Selector","metadata":{}},{"cell_type":"code","source":"import pymrmr\nimport numpy as np\nfrom sklearn.linear_model import Lasso\nfrom sklearn.decomposition import PCA\n\ndef feature_selection(X_train, X_val, X_test, y_train, num_features_mrmr=None, alpha_lasso=None, num_features_rf=None, method=None):\n    if method == \"MRMR\":\n        # Feature selection using MRMR\n        df_train = pd.DataFrame(X_train)\n        df_train.columns = df_train.columns.astype(str)\n        selected_features_mrmr = pymrmr.mRMR(df_train, 'MIQ', num_features_mrmr)\n        selected_features_mrmr_int = [int(feature) for feature in selected_features_mrmr]\n        \n        X_train_selected = X_train[:, selected_features_mrmr_int]\n        X_val_selected = X_val[:, selected_features_mrmr_int]\n        X_test_selected = X_test[:, selected_features_mrmr_int]\n        \n        print(\"Le caratteristiche selezionate tramite MRMR sono:\", selected_features_mrmr)\n        \n    elif method == \"LASSO\":\n        # Feature selection using LASSO\n        lasso = Lasso(alpha=alpha_lasso)\n        lasso.fit(X_train, y_train)\n        coefficients = lasso.coef_\n        selected_features_lasso = np.where(coefficients != 0)[0]\n        \n        X_train_selected = X_train[:, selected_features_lasso]\n        X_val_selected = X_val[:, selected_features_lasso]\n        X_test_selected = X_test[:, selected_features_lasso]\n        \n        print(\"Le caratteristiche selezionate tramite LASSO sono:\", selected_features_lasso)\n        \n    elif method == \"RF\":\n        # Feature selection using Random Forest\n        rf = RandomForestClassifier(n_estimators=100, random_state=42)\n        rf.fit(X_train, y_train)\n        \n        importances = rf.feature_importances_\n        indices = np.argsort(importances)[::-1]\n        selected_features_rf = indices[:num_features_rf]\n        \n        X_train_selected = X_train[:, selected_features_rf]\n        X_val_selected = X_val[:, selected_features_rf]\n        X_test_selected = X_test[:, selected_features_rf]\n        \n        print(\"Le caratteristiche selezionate tramite Random Forest sono:\", selected_features_rf)\n        \n    else:\n        raise ValueError(\"Invalid method specified. Choose from 'MRMR', 'LASSO', or 'RF'.\")\n    \n    return X_train_selected, X_val_selected, X_test_selected\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:59:39.850007Z","iopub.execute_input":"2024-05-22T14:59:39.850818Z","iopub.status.idle":"2024-05-22T14:59:39.862293Z","shell.execute_reply.started":"2024-05-22T14:59:39.850782Z","shell.execute_reply":"2024-05-22T14:59:39.861202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate_mlp(X_train, y_train, X_val, y_val, X_test, y_test, hidden_layers=(128, 64, 32), max_iter=500, random_state=42, batch_size=64):\n    # Inizializza il classificatore MLP\n    mlp = MLPClassifier(hidden_layer_sizes=hidden_layers, max_iter=max_iter, random_state=random_state, \n                        verbose=True, batch_size=batch_size, early_stopping=True, learning_rate=\"adaptive\")\n\n    # Addestra il classificatore sulle feature selezionate dal set di addestramento\n    mlp.fit(X_train, y_train)\n\n    # Fai predizioni sui dati di validazione e test\n    y_val_pred = mlp.predict(X_val)\n    y_test_pred = mlp.predict(X_test)\n\n    # Calcola l'accuratezza sui set di validazione e test\n    val_accuracy = accuracy_score(y_val, y_val_pred)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n\n    # Calcola precisione e richiamo sul set di validation\n    precision_val = precision_score(y_val, y_val_pred)\n    recall_val = recall_score(y_val, y_val_pred)\n    \n    # Calcola precisione e richiamo sul set di test\n    precision = precision_score(y_test, y_test_pred)\n    recall = recall_score(y_test, y_test_pred)\n\n    # Calcola la matrice di confusione sul set di validation\n    conf_matrix_val = confusion_matrix(y_val, y_val_pred)\n    \n    # Calcola la matrice di confusione sul set di test\n    conf_matrix = confusion_matrix(y_test, y_test_pred)\n\n    # Stampa i risultati\n    print()\n    print(f\"Validation Accuracy: {val_accuracy}\")\n    print(f\"Test Accuracy: {test_accuracy}\")\n    print()\n    print(\"Precision VALIDATION:\", precision_val)\n    print(\"Recall VALIDATION:\", recall_val)\n    print()\n    print(\"Precision TEST:\", precision)\n    print(\"Recall TEST:\", recall)\n    print()\n    print('Confusion Matrix VALIDATION:')\n    print(conf_matrix_val)\n    print()\n    print('Confusion Matrix TEST:')\n    print(conf_matrix)\n\n    return {\n        \"val_accuracy\": val_accuracy,\n        \"test_accuracy\": test_accuracy,\n        \"precision_val\": precision_val,\n        \"recall_val\": recall_val,\n        \"precision_test\": precision,\n        \"recall_test\": recall,\n        \"confusion_matrix_val\": conf_matrix_val,\n        \"confusion_matrix_test\": conf_matrix\n    }","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:59:40.908833Z","iopub.execute_input":"2024-05-22T14:59:40.909184Z","iopub.status.idle":"2024-05-22T14:59:40.920231Z","shell.execute_reply.started":"2024-05-22T14:59:40.909158Z","shell.execute_reply":"2024-05-22T14:59:40.919309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Vanilla","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\nfrom tensorflow.keras.optimizers import AdamW, Adam\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n\ndef build_and_train_nn(X_train, y_train, X_val, y_val, X_test, y_test, input_dim, learning_rate=1e-3, batch_size=64, epochs=1000):\n    # Definisci il modello\n    model = Sequential()\n\n    model.add(Input(shape=(input_dim,)))\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(64, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    model.add(Dense(32, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.3))\n\n    # Livello di output\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Compila il modello\n    model.compile(optimizer=AdamW(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n\n    # Mostra il sommario del modello\n    model.summary()\n\n    # Callbacks\n    early_stopping_class = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n    reduce_lr_class = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10)\n\n    \n    # Addestra il modello utilizzando i dati di training e di validazione\n    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping_class, reduce_lr_class])\n\n    # Fai predizioni sui dati di test e val\n    y_val_pred_proba = model.predict(X_val)\n    y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n    \n    y_test_pred_proba = model.predict(X_test)\n    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n\n    val_accuracy = accuracy_score(y_val, y_val_pred)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    print()\n    print(f\"Validation Accuracy: {val_accuracy}\")\n    print(f\"Test Accuracy: {test_accuracy}\")\n    \n    precision = precision_score(y_val, y_val_pred)\n    recall = recall_score(y_val, y_val_pred)\n    print()\n    print(f\"Precision Validation: {precision:.4f}\")\n    print(f\"Recall Validation: {recall:.4f}\")\n    print()    \n    precision = precision_score(y_test, y_test_pred)\n    recall = recall_score(y_test, y_test_pred)\n    print()\n    print(f\"Precision Test: {precision:.4f}\")\n    print(f\"Recall Test: {recall:.4f}\")\n    print()\n    print('Confusion Matrix VALIDATION:')\n    print(confusion_matrix(y_val, y_val_pred))\n    print()\n    print('Confusion Matrix TEST:')\n    print(confusion_matrix(y_test, y_test_pred))\n\n    return model, history\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:59:41.540302Z","iopub.execute_input":"2024-05-22T14:59:41.540900Z","iopub.status.idle":"2024-05-22T14:59:41.555909Z","shell.execute_reply.started":"2024-05-22T14:59:41.540868Z","shell.execute_reply":"2024-05-22T14:59:41.554966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TESTS","metadata":{}},{"cell_type":"markdown","source":"### Creazione Variabili","metadata":{}},{"cell_type":"code","source":"X_train_selected_mrmr_32, X_val_selected_mrmr_32, X_test_selected_mrmr_32 = feature_selection(X_train_encoded, X_val_encoded, X_test_encoded, y_train, num_features_mrmr=24, alpha_lasso=0.001, num_features_rf=24, method=\"MRMR\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T14:59:46.356917Z","iopub.execute_input":"2024-05-22T14:59:46.357649Z","iopub.status.idle":"2024-05-22T15:00:18.669624Z","shell.execute_reply.started":"2024-05-22T14:59:46.357619Z","shell.execute_reply":"2024-05-22T15:00:18.668589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_selected_mrmr_48, X_val_selected_mrmr_48, X_test_selected_mrmr_48 = feature_selection(X_train_encoded, X_val_encoded, X_test_encoded, y_train, num_features_mrmr=12, alpha_lasso=0.001, num_features_rf=24, method=\"MRMR\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:20:18.118900Z","iopub.execute_input":"2024-05-22T11:20:18.119283Z","iopub.status.idle":"2024-05-22T11:20:22.162455Z","shell.execute_reply.started":"2024-05-22T11:20:18.119250Z","shell.execute_reply":"2024-05-22T11:20:22.161478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_selected_rf_32, X_val_selected_rf_32, X_test_selected_rf_32 = feature_selection(X_train_encoded, X_val_encoded, X_test_encoded, y_train, num_features_mrmr=12, alpha_lasso=0.001, num_features_rf=24, method=\"RF\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:00:18.671079Z","iopub.execute_input":"2024-05-22T15:00:18.671346Z","iopub.status.idle":"2024-05-22T15:00:44.048597Z","shell.execute_reply.started":"2024-05-22T15:00:18.671323Z","shell.execute_reply":"2024-05-22T15:00:44.047611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_selected_rf_48, X_val_selected_rf_48, X_test_selected_rf_48 = feature_selection(X_train_encoded, X_val_encoded, X_test_encoded, y_train, num_features_mrmr=12, alpha_lasso=0.001, num_features_rf=12, method=\"RF\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:20:46.287273Z","iopub.execute_input":"2024-05-22T11:20:46.287964Z","iopub.status.idle":"2024-05-22T11:21:09.965130Z","shell.execute_reply.started":"2024-05-22T11:20:46.287925Z","shell.execute_reply":"2024-05-22T11:21:09.964166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_selected_lasso_34, X_val_selected_lasso_34, X_test_selected_lasso_34 = feature_selection(X_train_encoded, X_val_encoded, X_test_encoded, y_train, num_features_mrmr=12, alpha_lasso=0.0001, num_features_rf=24, method=\"LASSO\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T11:21:09.966222Z","iopub.execute_input":"2024-05-22T11:21:09.966498Z","iopub.status.idle":"2024-05-22T11:21:09.990125Z","shell.execute_reply.started":"2024-05-22T11:21:09.966475Z","shell.execute_reply":"2024-05-22T11:21:09.987344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Risultati Modelli","metadata":{}},{"cell_type":"markdown","source":"### Vanilla","metadata":{}},{"cell_type":"code","source":"## RANDOM FOREST 32\nmodel, history = build_and_train_nn(X_train_selected_rf_32, y_train, X_val_selected_rf_32, y_val, X_test_selected_rf_32, y_test, X_train_selected_rf_32.shape[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:01:14.670503Z","iopub.execute_input":"2024-05-22T15:01:14.671320Z","iopub.status.idle":"2024-05-22T15:08:33.591038Z","shell.execute_reply.started":"2024-05-22T15:01:14.671289Z","shell.execute_reply":"2024-05-22T15:08:33.589913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = build_and_train_nn(X_train_selected_rf_48, y_train, X_val_selected_rf_48, y_val, X_test_selected_rf_48, y_test, X_train_selected_rf_48.shape[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## MRMR 16\nmodel, history = build_and_train_nn(X_train_selected_mrmr_32, y_train, X_val_selected_mrmr_32, y_val, X_test_selected_mrmr_32, y_test, X_train_selected_mrmr_32.shape[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:08:33.592782Z","iopub.execute_input":"2024-05-22T15:08:33.593074Z","iopub.status.idle":"2024-05-22T15:14:56.413399Z","shell.execute_reply.started":"2024-05-22T15:08:33.593050Z","shell.execute_reply":"2024-05-22T15:14:56.412507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## MRMR 16\nmodel, history = build_and_train_nn(X_train_selected_mrmr_48, y_train, X_val_selected_mrmr_48, y_val, X_test_selected_mrmr_48, y_test, X_train_selected_mrmr_48.shape[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = build_and_train_nn(X_train_selected_lasso_34, y_train, X_val_selected_lasso_34, y_val, X_test_selected_lasso_34, y_test, X_train_selected_lasso_34.shape[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### MLP","metadata":{}},{"cell_type":"code","source":"## RANDOM FOREST 24\nresult = train_and_evaluate_mlp(X_train_selected_rf_32, y_train, X_val_selected_rf_32, y_val, X_test_selected_rf_32, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:14:56.414703Z","iopub.execute_input":"2024-05-22T15:14:56.415054Z","iopub.status.idle":"2024-05-22T15:17:08.179164Z","shell.execute_reply.started":"2024-05-22T15:14:56.415021Z","shell.execute_reply":"2024-05-22T15:17:08.177973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = train_and_evaluate_mlp(X_train_selected_rf_48, y_train, X_val_selected_rf_48, y_val, X_test_selected_rf_48, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## MRMR 24\nresult = train_and_evaluate_mlp(X_train_selected_mrmr_32, y_train, X_val_selected_mrmr_32, y_val, X_test_selected_mrmr_32, y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T15:17:08.181937Z","iopub.execute_input":"2024-05-22T15:17:08.182649Z","iopub.status.idle":"2024-05-22T15:23:17.796289Z","shell.execute_reply.started":"2024-05-22T15:17:08.182605Z","shell.execute_reply":"2024-05-22T15:23:17.795219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = train_and_evaluate_mlp(X_train_selected_mrmr_48, y_train, X_val_selected_mrmr_48, y_val, X_test_selected_mrmr_48, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = train_and_evaluate_mlp(X_train_selected_lasso_34, y_train, X_val_selected_lasso_34, y_val, X_test_selected_lasso_34, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Without Selection","metadata":{}},{"cell_type":"code","source":"model, history = build_and_train_nn(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test, X_train_encoded.shape[1])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = train_and_evaluate_mlp(X_train_encoded, y_train, X_val_encoded, y_val, X_test_encoded, y_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DA FARE:\n\n- Finire mrmr 24 per vanilla e mlp\n- Testare MID per MRMR\n- Testare batch 64\n\n- Eseguire codice su DENSE 64\n- Eseguire codice su DENSE 16","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}