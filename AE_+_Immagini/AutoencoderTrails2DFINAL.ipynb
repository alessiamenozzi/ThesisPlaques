{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-04T17:02:14.309530Z","iopub.status.busy":"2024-09-04T17:02:14.308713Z","iopub.status.idle":"2024-09-04T17:02:14.320761Z","shell.execute_reply":"2024-09-04T17:02:14.319857Z","shell.execute_reply.started":"2024-09-04T17:02:14.309495Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:16.193244Z","iopub.status.busy":"2024-09-04T17:02:16.192887Z","iopub.status.idle":"2024-09-04T17:02:16.206433Z","shell.execute_reply":"2024-09-04T17:02:16.205503Z","shell.execute_reply.started":"2024-09-04T17:02:16.193214Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","import tensorflow as tf\n","from tensorflow import keras as tfk\n","from tensorflow.keras import layers as tfkl\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50\n","from sklearn.model_selection import train_test_split\n","\n","import random\n","random.seed(seed)\n","from sklearn.utils import shuffle\n","\n","import matplotlib.pyplot as plt\n","import cv2\n","import numpy as np\n","import os\n","import glob\n","from PIL import Image\n","from imgaug import augmenters as iaa\n","from skimage.transform import resize\n","from skimage.metrics import structural_similarity as ssim\n","from tensorflow.keras.initializers import he_normal, glorot_uniform, glorot_normal\n","from tensorflow.keras.optimizers import Adam, SGD, AdamW\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping\n","from tensorflow.keras.layers import GlobalAveragePooling2D, BatchNormalization, Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Reshape, Flatten, Dropout, Conv2DTranspose, LeakyReLU, LayerNormalization, MultiHeadAttention, Add, Activation\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l1, l2\n","from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy, mean_squared_error\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Impostazioni GPU\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","devices = tf.config.experimental.list_physical_devices()\n","print(\"Dispositivi visibili a TensorFlow:\")\n","for device in devices:\n","    print(device)\n","\n","import seaborn as sns\n","import matplotlib.patches as patches\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import Ste"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:18.072849Z","iopub.status.busy":"2024-09-04T17:02:18.072472Z","iopub.status.idle":"2024-09-04T17:02:18.085368Z","shell.execute_reply":"2024-09-04T17:02:18.084314Z","shell.execute_reply.started":"2024-09-04T17:02:18.072819Z"},"trusted":true},"outputs":[],"source":["\n","Y_train=np.load(\"/kaggle/input/labels-finali/labels_array_03.npy\")\n","\n","X_train=np.load(\"/kaggle/input/immagini-corrette-bw/images_array_col_03_giuste_bw.npy\")"]},{"cell_type":"markdown","metadata":{},"source":["## Import Ale"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T08:09:07.246639Z","iopub.status.busy":"2024-09-04T08:09:07.245841Z","iopub.status.idle":"2024-09-04T08:09:07.385804Z","shell.execute_reply":"2024-09-04T08:09:07.384840Z","shell.execute_reply.started":"2024-09-04T08:09:07.246602Z"},"trusted":true},"outputs":[],"source":["X_train=np.load(\"/kaggle/input/datiandlabels/images_array_bw.npy\")\n","Y_train=np.load(\"/kaggle/input/datiandlabels/labels_array_03.npy\")\n","print(X_train.shape)\n","print(Y_train.shape)\n","\n","print(sum(Y_train==0)) \n","print(sum(Y_train==1))\n"]},{"cell_type":"markdown","metadata":{},"source":["# AUTOENCODER double loss"]},{"cell_type":"markdown","metadata":{},"source":["### augmentation con labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:22.555566Z","iopub.status.busy":"2024-09-04T17:02:22.554754Z","iopub.status.idle":"2024-09-04T17:02:22.567943Z","shell.execute_reply":"2024-09-04T17:02:22.567035Z","shell.execute_reply.started":"2024-09-04T17:02:22.555533Z"},"trusted":true},"outputs":[],"source":["\n","\n","def augment_images_with_labels_01(images_array, labels_array, num_augmented_copies_class_0, num_augmented_copies_class_1):\n","    if images_array.ndim == 3:\n","        images_array = np.expand_dims(images_array, axis=-1)\n","    \n","    # Crea un oggetto ImageDataGenerator con le trasformazioni desiderate\n","    datagen = ImageDataGenerator(\n","        horizontal_flip=True,  # Ribaltamento orizzontale\n","        vertical_flip=True,    # Ribaltamento verticale\n","        rotation_range=10,     # Rotazione casuale tra -10 e 10 gradi\n","        width_shift_range=0.1, # Traslazione casuale del 10% su asse x\n","        height_shift_range=0.1,# Traslazione casuale del 10% su asse y\n","        zoom_range=0.2,        # Zoom casuale tra l'80% e il 120%\n","        brightness_range=[0.5, 0.8]  # Modifica casuale della luminositÃ  tra l'80% e il 120%\n","    )\n","\n","    # Liste per memorizzare le immagini e le etichette aumentate\n","    augmented_images = []\n","    augmented_labels = []\n","\n","    # Indici per separare le immagini per classe\n","    indices_class_0 = np.where(labels_array == 0)[0]\n","    indices_class_1 = np.where(labels_array == 1)[0]\n","\n","    # Seleziona le immagini per ciascuna classe\n","    images_class_0 = images_array[indices_class_0]\n","    labels_class_0 = labels_array[indices_class_0]\n","    images_class_1 = images_array[indices_class_1]\n","    labels_class_1 = labels_array[indices_class_1]\n","\n","    # Funzione per aumentare le immagini di una classe specifica\n","    def augment_class_images(images, labels, num_augmented_copies):\n","        augmented_images = []\n","        augmented_labels = []\n","        for image, label in zip(images, labels):\n","            # Aggiungi l'immagine e l'etichetta originale\n","            augmented_images.append(image)\n","            augmented_labels.append(label)\n","\n","            # Applica l'aumentazione per il numero specificato di copie\n","            image = np.expand_dims(image, 0)  # Espandi la dimensione per farla diventare (1, h, w, c)\n","            i = 0\n","            for batch in datagen.flow(image, batch_size=1):\n","                augmented_images.append(batch[0])\n","                augmented_labels.append(label)  # Aggiungi la stessa etichetta per l'immagine aumentata\n","                i += 1\n","                if i >= num_augmented_copies:\n","                    break\n","        return np.array(augmented_images), np.array(augmented_labels)\n","\n","    # Aumenta le immagini della classe 0 e 1\n","    augmented_images_class_0, augmented_labels_class_0 = augment_class_images(images_class_0, labels_class_0, num_augmented_copies_class_0)\n","    augmented_images_class_1, augmented_labels_class_1 = augment_class_images(images_class_1, labels_class_1, num_augmented_copies_class_1)\n","\n","    # Combina le immagini e le etichette aumentate delle due classi\n","    augmented_images = np.concatenate([augmented_images_class_0, augmented_images_class_1])\n","    augmented_labels = np.concatenate([augmented_labels_class_0, augmented_labels_class_1])\n","\n","    # Stampa le dimensioni degli array\n","    print(\"Dimensione del vettore delle immagini aumentate:\", augmented_images.shape)\n","    print(\"Dimensione del vettore delle etichette aumentate:\", augmented_labels.shape)\n","\n","    return augmented_images, augmented_labels\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### split dati"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:24.381498Z","iopub.status.busy":"2024-09-04T17:02:24.380875Z","iopub.status.idle":"2024-09-04T17:02:24.407782Z","shell.execute_reply":"2024-09-04T17:02:24.406801Z","shell.execute_reply.started":"2024-09-04T17:02:24.381465Z"},"trusted":true},"outputs":[],"source":["# Dati di esempio\n","# Assumendo che X_train e Y_train siano i tuoi dati, con X_train di shape (3000, 64, 64)\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","\n","print(sum(Y_train==0)) \n","print(sum(Y_train==1))\n","\n","\n","X = X_train.reshape(-1, 64, 64, 1)\n","Y = Y_train\n","\n","# Split dei dati in training, validation e test set\n","X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42, shuffle=True, stratify=Y_train)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42, shuffle=True, stratify=Y_temp)\n","\n","print(sum(Y_train==0)) \n","print(sum(Y_train==1))\n","\n","print(sum(Y_val==0)) \n","print(sum(Y_val==1))\n","\n","print(sum(Y_test==0)) \n","print(sum(Y_test==1))"]},{"cell_type":"markdown","metadata":{},"source":["## preprocessing dati \n","Aumentiamo i dati di train, abbiamo provato ad aumentare maggiormente la sottoclasse (1) \n","Abbiamo tentato anche di aumentare leggermente il validation "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:25.178850Z","iopub.status.busy":"2024-09-04T17:02:25.178496Z","iopub.status.idle":"2024-09-04T17:02:38.185196Z","shell.execute_reply":"2024-09-04T17:02:38.184231Z","shell.execute_reply.started":"2024-09-04T17:02:25.178822Z"},"trusted":true},"outputs":[],"source":["X_train, Y_train = augment_images_with_labels_01(X_train, Y_train, 4, 8)\n","X_val, Y_val = augment_images_with_labels_01(X_val, Y_val, 2, 3)\n","\n","\n","X_train = shuffle(X_train, random_state = 58)\n","Y_train = shuffle(Y_train, random_state = 58)\n","X_val = shuffle(X_val, random_state = 99)\n","Y_val = shuffle(Y_val, random_state = 99)\n","\n","print(X_train.shape)\n","print(Y_train.shape)\n","print(sum(Y_train==0)) \n","print(sum(Y_train==1))\n","\n","print(X_val.shape)\n","print(Y_val.shape)\n","print(sum(Y_val==0)) \n","print(sum(Y_val==1))\n","\n","X_train = X_train / 255.0\n","X_val = X_val / 255.0\n","X_test = X_test / 255.0\n"]},{"cell_type":"markdown","metadata":{},"source":["## Primo modello 3 strati convoluzionali\n","pesi salvati qui:  /Users/alessiamenozzi/Desktop/encoder_doubleloss_easy128.weights.h5"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-4,\n","    decay_steps=35000,\n","    decay_rate=0.9\n",")\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=100,         \n","    restore_best_weights=True, \n","    min_delta=0.00001,\n","    verbose = True\n",")\n","\n","## dizionari creati per gestire la doppia loss in modo che le loss vengano ottimizzate insieme\n","stored_values = {\n","    'y_true_class': None,\n","    'y_pred_class': None,\n","    'y_true_recon': None,\n","    'y_pred_recon': None\n","}\n","\n","\n","# Funzione per la loss combinata\n","def create_combined_loss(lambdadec, lambdatot):\n","    def combined_loss_diz(y_true, y_pred):\n","        if len(y_true.shape) == 2:  # Output del classificatore\n","            stored_values['y_true_class'] = y_true\n","            stored_values['y_pred_class'] = y_pred\n","        elif len(y_true.shape) == 4:  # Output del decoder (immagini)\n","            stored_values['y_true_recon'] = y_true\n","            stored_values['y_pred_recon'] = y_pred\n","\n","        if stored_values['y_true_class'] is not None and stored_values['y_true_recon'] is not None:\n","            # perdita per il classificatore\n","            bce_loss = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_class'], stored_values['y_pred_class'])\n","            \n","            # perdita per il decoder\n","            mse_loss = tf.keras.losses.MeanSquaredError()(stored_values['y_true_recon'], stored_values['y_pred_recon'])\n","            bce_loss_re = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_recon'], stored_values['y_true_recon'])\n","\n","            #ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(stored_values['y_true_recon'], stored_values['y_pred_recon'], max_val=1.0))\n","            dec_loss= lambdadec * mse_loss + (1-lambdadec) * bce_loss_re\n","            \n","            ## loss combinata\n","            combined_loss_value = lambdatot * dec_loss + (1-lambdatot) * bce_loss\n","        \n","            stored_values['y_true_class'] = None\n","            stored_values['y_pred_class'] = None\n","            stored_values['y_true_recon'] = None\n","            stored_values['y_pred_recon'] = None\n","            \n","            return combined_loss_value\n","\n","        return 0.0\n","    return combined_loss_diz\n","\n","\n","\n","lossWeights={'classifier': 0.3, 'decoder': 0.7}\n","\n","\n","def create_encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Flatten()(x)\n","    encoded = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n","    return Model(inputs, encoded, name=\"encoder\")\n","\n","\n","def create_decoder(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    x = Dense(8 * 8 * 32, activation='relu', kernel_regularizer=l2(0.001))(inputs)\n","    x = Reshape((8, 8, 32))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_regularizer=l2(0.001))(x)\n","    return Model(inputs, decoded, name=\"decoder\")\n","\n","\n","def create_classifier(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    classification = Dense(1, activation='sigmoid')(inputs)\n","    return Model(inputs, classification, name=\"classifier\")\n","\n","def build_autoencoder_classifier(input_shape, encoded_shape):\n","    encoder = create_encoder(input_shape)\n","    decoder = create_decoder(encoded_shape)\n","    classifier = create_classifier(encoded_shape)\n","\n","\n","    inputs = Input(shape=input_shape)\n","\n","    # Encoding\n","    encoded = encoder(inputs)\n","\n","    # Decoding\n","    reconstructed = decoder(encoded)\n","\n","    # Classification\n","    classification = classifier(encoded)\n","\n","    # Modello finale\n","    autoencoder_classifier = Model(inputs, [classification, reconstructed], name='autoencoder_classifier')\n","\n","    autoencoder_classifier.compile(optimizer=Adam(learning_rate=1e-4),\n","                                   #loss_weights=lossWeights,\n","                                   #loss={'decoder': 'mse', 'classifier': 'bce'},\n","                                   loss=create_combined_loss(0.5, 0.4),\n","                                   metrics={'classifier': 'accuracy'})\n","\n","    return autoencoder_classifier\n","\n","\n","input_shape = (64, 64, 1)\n","encoded_shape = (128,)\n","\n","\n","autoencoder_classifier = build_autoencoder_classifier(input_shape, encoded_shape)\n","\n","\n","autoencoder_classifier.summary()\n","\n","# Addestramento del modello\n","history = autoencoder_classifier.fit(\n","    x=X_train,\n","    y=[Y_train, X_train],\n","    epochs=320,\n","    batch_size=128,\n","    validation_data=(X_val, [Y_val, X_val]),\n","    #callbacks=[early_stopping]\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Secondo Modello 7 strati convoluzionali\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:38.188201Z","iopub.status.busy":"2024-09-04T17:02:38.187516Z","iopub.status.idle":"2024-09-04T17:02:38.389831Z","shell.execute_reply":"2024-09-04T17:02:38.388983Z","shell.execute_reply.started":"2024-09-04T17:02:38.188166Z"},"trusted":true},"outputs":[],"source":["\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=100,          \n","    restore_best_weights=True, \n","    min_delta=0.0001,\n","    verbose = True\n",")\n","\n","stored_values = {\n","    'y_true_class': None,\n","    'y_pred_class': None,\n","    'y_true_recon': None,\n","    'y_pred_recon': None\n","}\n","\n","tf.config.run_functions_eagerly(False)\n","\n","\n","def create_combined_loss(lambdadec, lambdatot):\n","    def combined_loss_diz(y_true, y_pred):\n","        if len(y_true.shape) == 2:  # Output del classificatore\n","            stored_values['y_true_class'] = y_true\n","            stored_values['y_pred_class'] = y_pred\n","        elif len(y_true.shape) == 4:  # Output del decoder (immagini)\n","            stored_values['y_true_recon'] = y_true\n","            stored_values['y_pred_recon'] = y_pred\n","\n","        if stored_values['y_true_class'] is not None and stored_values['y_true_recon'] is not None:\n","            # perdita per il classificatore\n","            bce_loss = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_class'], stored_values['y_pred_class'])\n","            \n","            # perdita per il decoder\n","            mse_loss = tf.keras.losses.MeanSquaredError()(stored_values['y_true_recon'], stored_values['y_pred_recon'])\n","            bce_loss_re = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_recon'], stored_values['y_true_recon'])\n","            #ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(stored_values['y_true_recon'], stored_values['y_pred_recon'], max_val=1.0))\n","            \n","            dec_loss= lambdadec * mse_loss + (1-lambdadec) * bce_loss_re\n","            \n","            combined_loss_value = lambdatot * dec_loss + (1-lambdatot) * bce_loss\n","        \n","            stored_values['y_true_class'] = None\n","            stored_values['y_pred_class'] = None\n","            stored_values['y_true_recon'] = None\n","            stored_values['y_pred_recon'] = None\n","            \n","            return combined_loss_value\n","\n","        return 0.0\n","    return combined_loss_diz\n","\n","\n","lossWeights={'classifier': 0.3, 'decoder': 0.7}\n","\n","\n","def create_encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Flatten()(x)\n","    \n","    encoded = Dense(64, activation='relu', kernel_regularizer=l1(1e-5))(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    return encoder_model\n","\n","# Decoder\n","def create_decoder(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    x = Dense(1 * 1 * 512, activation='relu', kernel_regularizer=l1(1e-5))(inputs)\n","    x = Reshape((1, 1, 512))(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    return decoder_model\n","\n","# Funzione per creare il classificatore\n","def create_classifier(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    classification = Dense(1, activation='sigmoid')(inputs)\n","    return Model(inputs, classification, name=\"classifier\")\n","\n","# Funzione per costruire l'intero modello Autoencoder-Classifier\n","def build_autoencoder_classifier(input_shape, encoded_shape):\n","    encoder = create_encoder(input_shape)\n","    decoder = create_decoder(encoded_shape)\n","    classifier = create_classifier(encoded_shape)\n","\n","    # Input\n","    inputs = Input(shape=input_shape)\n","\n","    # Encoding\n","    encoded = encoder(inputs)\n","\n","    # Decoding\n","    reconstructed = decoder(encoded)\n","\n","    # Classification\n","    classification = classifier(encoded)\n","\n","    # Modello finale\n","    autoencoder_classifier = Model(inputs, [classification, reconstructed], name='autoencoder_classifier')\n","\n","    # Compilazione del modello\n","    autoencoder_classifier.compile(optimizer=Adam(learning_rate=1e-4),\n","                                   #loss_weights=lossWeights,\n","                                   #loss={'decoder': 'mse', 'classifier': 'bce'},\n","                                   loss=create_combined_loss(0.5, 0.9),\n","                                   metrics={'classifier': 'accuracy'})\n","\n","    return autoencoder_classifier\n","\n","# Parametri del modello\n","input_shape = (64, 64, 1)\n","encoded_shape = (64,)\n","\n","# Costruzione del modello\n","autoencoder_classifier = build_autoencoder_classifier(input_shape, encoded_shape)\n","\n","# Visualizzazione del modello\n","autoencoder_classifier.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:11:11.552674Z","iopub.status.busy":"2024-09-04T17:11:11.552270Z","iopub.status.idle":"2024-09-04T17:11:11.592615Z","shell.execute_reply":"2024-09-04T17:11:11.591700Z","shell.execute_reply.started":"2024-09-04T17:11:11.552643Z"},"trusted":true},"outputs":[],"source":["encoder = autoencoder_classifier.get_layer(\"encoder\")\n","encoder.save_weights('encoder_doubleloss_easy64.weights.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Secondo Modello + trasformer"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-09-04T14:57:25.367330Z","iopub.status.busy":"2024-09-04T14:57:25.366936Z","iopub.status.idle":"2024-09-04T14:57:25.660297Z","shell.execute_reply":"2024-09-04T14:57:25.659494Z","shell.execute_reply.started":"2024-09-04T14:57:25.367301Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-4,\n","    decay_steps=10000,\n","    decay_rate=0.9\n",")\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',  \n","    patience=50,          \n","    restore_best_weights=True, \n","    min_delta=0.0001,\n","    verbose = True\n",")\n","\n","#lossWeights={'classifier': 0.3, 'decoder': 0.7}\n","\n","\n","stored_values = {\n","    'y_true_class': None,\n","    'y_pred_class': None,\n","    'y_true_recon': None,\n","    'y_pred_recon': None\n","}\n","\n","#tf.config.run_functions_eagerly(False)\n","\n","\n","def create_combined_loss(lambdadec, lambdatot):\n","    def combined_loss_diz(y_true, y_pred):\n","        if len(y_true.shape) == 2:  \n","            stored_values['y_true_class'] = y_true\n","            stored_values['y_pred_class'] = y_pred\n","        elif len(y_true.shape) == 4:  \n","            stored_values['y_true_recon'] = y_true\n","            stored_values['y_pred_recon'] = y_pred\n","\n","        if stored_values['y_true_class'] is not None and stored_values['y_true_recon'] is not None:\n","            bce_loss = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_class'], stored_values['y_pred_class'])\n","            \n","            mse_loss = tf.keras.losses.MeanSquaredError()(stored_values['y_true_recon'], stored_values['y_pred_recon'])\n","            bce_loss_re = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_recon'], stored_values['y_true_recon'])\n","            #ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(stored_values['y_true_recon'], stored_values['y_pred_recon'], max_val=1.0))\n","            dec_loss= lambdadec * mse_loss + (1-lambdadec) * bce_loss_re\n","            \n","\n","            combined_loss_value = lambdatot * dec_loss + (1-lambdatot) * bce_loss\n","        \n","            stored_values['y_true_class'] = None\n","            stored_values['y_pred_class'] = None\n","            stored_values['y_true_recon'] = None\n","            stored_values['y_pred_recon'] = None\n","            \n","            return combined_loss_value\n","\n","        return 0.0\n","    return combined_loss_diz\n","\n","\n","\n","# Blocco Transformer\n","def transformer_block(x, num_heads, ff_dim, rate=0.3):\n","    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x, x)\n","    attn_output = Dropout(rate)(attn_output)\n","    out1 = Add()([x, attn_output])  \n","    out1 = LayerNormalization(epsilon=1e-6)(out1)\n","\n","    ff_output = Dense(ff_dim, activation='relu')(out1)  \n","    ff_output = Dense(x.shape[-1])(ff_output)  \n","    ff_output = Dropout(rate)(ff_output)\n","\n","    out2 = Add()([out1, ff_output])  \n","    return LayerNormalization(epsilon=1e-6)(out2)\n","\n","\n","def encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Flatten()(x)\n","    \n","    encoded = Dense(64, activation='relu', kernel_regularizer=l1(1e-5))(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    return encoder_model\n","\n","\n","def decoder(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    x = Dense(1 * 1 * 512, activation='relu', kernel_regularizer=l1(1e-5))(inputs)\n","    x = Reshape((1, 1, 512))(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    return decoder_model\n","\n","\n","def classifier(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    classification = Dense(1, activation='sigmoid')(inputs)\n","    return Model(inputs, classification, name=\"classifier\")\n","\n","\n","def build_autoencoder_classifier(input_shape, encoded_shape):\n","    encoder_model = encoder(input_shape)\n","    \n","    # Trasformo il bottleneck per simulare una sequenza (per il Transformer)\n","    x = Reshape((1, 64))(encoder_model.output)\n","    #x = transformer_block(x, num_heads=8, ff_dim=512)\n","    x = transformer_block(x, num_heads=6, ff_dim=256)\n","    #x = transformer_block(x, num_heads=8, ff_dim=512)\n","    x = Flatten()(x)\n","    \n","\n","    decoder_model = decoder((64,))\n","    reconstructed = decoder_model(x)\n","    \n","\n","    classifier_model = classifier((64,))\n","    classification = classifier_model(x)\n","\n","\n","    autoencoder_classifier = Model(encoder_model.input, [classification, reconstructed], name='autoencoder_classifier')\n","    \n","\n","    autoencoder_classifier.compile(optimizer=Adam(learning_rate=lr_schedule), \n","                                   loss={'decoder': 'bce'},\n","                                   #loss_weights=lossWeights,\n","                                   #loss=create_combined_loss(0.5, 0.4),\n","                                   metrics={'classifier': 'accuracy'})\n","\n","    return autoencoder_classifier\n","\n","\n","input_shape = (64, 64, 1)\n","encoded_shape = (64,)\n","\n","\n","autoencoder_classifier = build_autoencoder_classifier(input_shape, encoded_shape)\n","\n","autoencoder_classifier.summary()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T17:02:38.391072Z","iopub.status.busy":"2024-09-04T17:02:38.390814Z","iopub.status.idle":"2024-09-04T17:09:36.560789Z","shell.execute_reply":"2024-09-04T17:09:36.559972Z","shell.execute_reply.started":"2024-09-04T17:02:38.391048Z"},"trusted":true},"outputs":[],"source":["\n","history = autoencoder_classifier.fit(\n","    x=X_train, \n","    y=[Y_train, X_train],\n","    epochs=1000, \n","    batch_size=256, \n","    validation_data=(X_val, [Y_val, X_val]),\n","    callbacks=[early_stopping]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["encoder_input = autoencoder_classifier.input \n","encoder_output = autoencoder_classifier.get_layer('flatten_3').output\n","\n","\n","encoder_model = Model(inputs=encoder_input, outputs=encoder_output, name='encoder')\n","\n","encoder_model.save_weights('encoder_DoubleLoss_transformer.weights.h5')\n"]},{"cell_type":"markdown","metadata":{},"source":["## VALUTAZIONI ricostruzioni e classificazione"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T13:41:37.027143Z","iopub.status.busy":"2024-09-04T13:41:37.026779Z","iopub.status.idle":"2024-09-04T13:41:48.491086Z","shell.execute_reply":"2024-09-04T13:41:48.490132Z","shell.execute_reply.started":"2024-09-04T13:41:37.027114Z"},"trusted":true},"outputs":[],"source":["\n","\n","# Valutazione sul test set CLASSIFICAZIONE\n","results = autoencoder_classifier.evaluate(X_test, Y_test)\n","print(f'Test Loss: {results[0]}, Test Accuracy: {results[1]}')\n","\n","\n","Y_test_pred, _  = autoencoder_classifier.predict(X_test)\n","#_, Y_test_pred  = autoencoder_classifier.predict(X_test)\n","# Soglia per la classificazione\n","Y_test_pred_binary = (Y_test_pred > 0.5).astype(int)\n","\n","\n","conf_matrix = confusion_matrix(Y_test, Y_test_pred_binary)\n","class_report = classification_report(Y_test, Y_test_pred_binary, target_names=['Class 0', 'Class 1'])\n","\n","\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n","print(\"\\nClassification Report:\")\n","print(class_report)\n","\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","\n","val_loss = history.history['val_loss']\n","val_accuracy = history.history.get('val_classifier_accuracy', [])\n","\n","\n","print(f\"Validation Loss: {val_loss[-1]}\")\n","if val_accuracy:\n","    print(f\"Validation Accuracy: {val_accuracy[-1]}\")\n","else:\n","    print(\"Validation Accuracy not available in history.\")\n","\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","if val_accuracy:\n","    plt.figure(figsize=(12, 6))\n","    plt.plot(history.history['classifier_accuracy'], label='Training Accuracy')\n","    plt.plot(val_accuracy, label='Validation Accuracy')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T15:34:58.875500Z","iopub.status.busy":"2024-09-04T15:34:58.874776Z","iopub.status.idle":"2024-09-04T15:35:01.522673Z","shell.execute_reply":"2024-09-04T15:35:01.521760Z","shell.execute_reply.started":"2024-09-04T15:34:58.875470Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","\n","### VALUTAZIONE RICOSTRUZIONI\n","\n","# Funzione per calcolare il SSIM medio\n","def calculate_mean_ssim(X_true, X_pred):\n","    ssim_values = []\n","    for i in range(len(X_true)):\n","        # Calcolo del SSIM per ciascuna immagine\n","        ssim_value = ssim(X_true[i].reshape(64, 64), X_pred[i].reshape(64, 64), data_range=1.0)\n","        ssim_values.append(ssim_value)\n","        \n","    std_ssim = np.std(ssim_values)\n","    mean_ssim= np.mean(ssim_values)\n","    return std_ssim, mean_ssim\n","\n","\n","\n","_, X_test_reconstructed = autoencoder_classifier.predict(X_test)\n","#X_test_reconstructed, _ = autoencoder_classifier.predict(X_test)\n","\n","# Calcolo del SSIM medio\n","std_ssim, mean_ssim = calculate_mean_ssim(X_test, X_test_reconstructed)\n","print(f'Mean SSIM on Test Set: {mean_ssim}')\n","print(f'Std SSIM on Test Set: {std_ssim}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-04T15:34:44.577907Z","iopub.status.busy":"2024-09-04T15:34:44.577060Z","iopub.status.idle":"2024-09-04T15:34:44.965359Z","shell.execute_reply":"2024-09-04T15:34:44.964490Z","shell.execute_reply.started":"2024-09-04T15:34:44.577875Z"},"trusted":true},"outputs":[],"source":["## SSIM CON MASK\n","import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","def find_bounding_box(image):\n","    # Trova i bordi del rettangolo contenente la placca\n","    rows = np.any(image, axis=1)\n","    cols = np.any(image, axis=0)\n","    y_min, y_max = np.where(rows)[0][[0, -1]]\n","    x_min, x_max = np.where(cols)[0][[0, -1]]\n","    return y_min, y_max, x_min, x_max\n","\n","\n","if X_test_reconstructed.shape[-1] == 1:\n","    X_test_reconstructed = np.squeeze(X_test_reconstructed, axis=-1)\n","if X_test.shape[-1] == 1:\n","    X_test = np.squeeze(X_test, axis=-1)\n","\n","# Calcolo SSIM per ciascuna immagine\n","ssim_values = []\n","for i in range(len(X_test_reconstructed)):\n","    orig_img = X_test[i]\n","    recon_img = X_test_reconstructed[i]\n","\n","    y_min, y_max, x_min, x_max = find_bounding_box(orig_img)\n","\n","    orig_rect = orig_img[y_min:y_max+1, x_min:x_max+1]\n","    recon_rect = recon_img[y_min:y_max+1, x_min:x_max+1]\n","\n","    ssim_value = ssim(orig_rect, recon_rect, data_range=1.0)\n","    ssim_values.append(ssim_value)\n","    #print(f\"SSIM per immagine {i + 1}: {ssim_value}\")\n","\n","# Media e deviazione standard dei valori SSIM\n","mean_ssim = np.mean(ssim_values)\n","std_ssim = np.std(ssim_values)\n","\n","print(f\"Valore medio di SSIM con maschera: {mean_ssim}\")\n","print(f\"Deviazione standard di SSIM: {std_ssim}\")\n","\n","\n","# Visualizzazione della maschera per un esempio\n","example_index = 557\n","example_orig_img = X_test[example_index]\n","example_recon_img = X_test_reconstructed[example_index]\n","\n","y_min, y_max, x_min, x_max = find_bounding_box(example_orig_img)\n","\n","fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n","\n","ax[0].imshow(example_orig_img, cmap='gray')\n","rect = patches.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, linewidth=1, edgecolor='r', facecolor='none')\n","ax[0].add_patch(rect)\n","ax[0].set_title(\"Originale con Maschera\")\n","ax[0].axis('off')\n","\n","ax[1].imshow(example_recon_img, cmap='gray')\n","ax[1].set_title(\"Ricostruita\")\n","ax[1].axis('off')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-03T17:28:19.664136Z","iopub.status.busy":"2024-09-03T17:28:19.663750Z","iopub.status.idle":"2024-09-03T17:28:20.830550Z","shell.execute_reply":"2024-09-03T17:28:20.829660Z","shell.execute_reply.started":"2024-09-03T17:28:19.664106Z"},"trusted":true},"outputs":[],"source":["## Comparazione immagini originali e ricostruite\n","\n","\n","def plot_comparison(X_true, X_pred, num_images=10):\n","\n","    indices = np.random.choice(len(X_true), num_images, replace=False)\n","    \n","    plt.figure(figsize=(15, 10))\n","    \n","    for i, idx in enumerate(indices):\n","        plt.subplot(num_images, 2, 2*i + 1)\n","        plt.imshow(X_true[idx].reshape(64, 64), cmap='gray')\n","        plt.title(f\"Original {i+1}\")\n","        plt.axis('off')\n","        \n","        plt.subplot(num_images, 2, 2*i + 2)\n","        plt.imshow(X_pred[idx].reshape(64, 64), cmap='gray')\n","        plt.title(f\"Reconstructed {i+1}\")\n","        plt.axis('off')\n","    \n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","plot_comparison(X_test, X_test_reconstructed, num_images=10)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Modello 7 strati conv + 2 blocchi trasformer + classificatore con 3 strati densi"]},{"cell_type":"markdown","metadata":{},"source":["Valore medio di SSIM con maschera: 0.02195523895514344\n","Deviazione standard di SSIM: 0.030026406511328374\n","\n","Mean SSIM on Test Set: 0.5675735482555746\n","\n","\n","Test Loss: 0.025829948484897614, Test Accuracy: 0.0\n","\n","Confusion Matrix:\n","[[363  45]\n"," [ 69 114]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","     Class 0       0.84      0.89      0.86       408\n","     Class 1       0.72      0.62      0.67       183\n","\n","    accuracy                           0.81       591\n","   macro avg       0.78      0.76      0.77       591\n","weighted avg       0.80      0.81      0.80       591\n","\n","\n","Validation Loss: 1.6375044584274292\n","Validation Accuracy: 0.657274603843689\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-4,\n","    decay_steps=10000,\n","    decay_rate=0.95\n",")\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss',  \n","    patience=50,          \n","    restore_best_weights=True, \n","    min_delta=0.0001,\n","    verbose = True\n",")\n","\n","\n","# Definizione della loss combinata per decoder\n","def combined_loss_1(y_true, y_pred):\n","    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n","    mse_loss = mean_squared_error(y_true, y_pred)\n","    bce_loss = BinaryCrossentropy()(y_true, y_pred)\n","    return 0.5 * bce_loss + mse_loss + 0.5 * ssim_loss\n","\n","# Transformer block\n","def transformer_block(x, num_heads, ff_dim, rate=0.3):\n","    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x, x)\n","    attn_output = Dropout(rate)(attn_output)\n","    out1 = Add()([x, attn_output])  # Residual connection\n","    out1 = LayerNormalization(epsilon=1e-6)(out1)\n","\n","    ff_output = Dense(ff_dim, activation='relu')(out1)  # Feed-forward layer\n","    ff_output = Dense(x.shape[-1])(ff_output)  # Riduci di nuovo alla dimensione originale (64)\n","    ff_output = Dropout(rate)(ff_output)\n","\n","    out2 = Add()([out1, ff_output])  # Residual connection con le stesse dimensioni\n","    return LayerNormalization(epsilon=1e-6)(out2)\n","\n","\n","stored_values = {\n","    'y_true_class': None,\n","    'y_pred_class': None,\n","    'y_true_recon': None,\n","    'y_pred_recon': None\n","}\n","\n","#tf.config.run_functions_eagerly(False)\n","\n","\n","def create_combined_loss(lambdadec, lambdatot):\n","    def combined_loss_diz(y_true, y_pred):\n","        if len(y_true.shape) == 2:\n","            stored_values['y_true_class'] = y_true\n","            stored_values['y_pred_class'] = y_pred\n","        elif len(y_true.shape) == 4:\n","            stored_values['y_true_recon'] = y_true\n","            stored_values['y_pred_recon'] = y_pred\n","\n","        if stored_values['y_true_class'] is not None and stored_values['y_true_recon'] is not None:\n","\n","            bce_loss = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_class'], stored_values['y_pred_class'])\n","            \n","            mse_loss = tf.keras.losses.MeanSquaredError()(stored_values['y_true_recon'], stored_values['y_pred_recon'])\n","            bce_loss_re = tf.keras.losses.BinaryCrossentropy()(stored_values['y_true_recon'], stored_values['y_true_recon'])\n","            #ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(stored_values['y_true_recon'], stored_values['y_pred_recon'], max_val=1.0))\n","            dec_loss= lambdadec * mse_loss + (1-lambdadec) * bce_loss_re\n","            \n","            combined_loss_value = lambdatot * dec_loss + (1-lambdatot) * bce_loss\n","        \n","            stored_values['y_true_class'] = None\n","            stored_values['y_pred_class'] = None\n","            stored_values['y_true_recon'] = None\n","            stored_values['y_pred_recon'] = None\n","            \n","            return combined_loss_value\n","\n","        return 0.0\n","    return combined_loss_diz\n","\n","\n","def encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Flatten()(x)\n","    \n","    x = Dense(64, activation='relu', kernel_regularizer=l1(10e-6))(x)\n","    encoded = Dropout(0.4)(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    return encoder_model\n","\n","def decoder(output_shape):\n","    inputs = Input(shape=output_shape)\n","    x = Dense(1*1*512, activation='relu', kernel_regularizer=l1(10e-6))(inputs)\n","    x = Reshape((1, 1, 512))(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    return decoder_model\n","\n","\n","def build_classifier(encoded_shape):\n","    inputs = Input(shape=encoded_shape)\n","    x = Dense(128, activation='relu', kernel_regularizer=l1(0.001))(inputs)\n","    x = Dropout(0.5)(x)\n","    x = Dense(64, activation='relu', kernel_regularizer=l1(0.001))(inputs)\n","    x = Dropout(0.5)(x)\n","    x = Dense(32, activation='relu', kernel_regularizer=l1(0.001))(inputs)\n","    x = Dropout(0.5)(x)\n","    classification = Dense(1, activation='sigmoid')(x)\n","    return Model(inputs, classification, name=\"classifier\")\n","\n","\n","input_shape = (64, 64, 1)\n","encoder_model = encoder(input_shape)\n","\n","\n","encoded_input = encoder_model.output\n","x = Reshape((1, 64))(encoded_input)  # reshape per simulare una \"sequenza\"\n","x = transformer_block(x, num_heads=8, ff_dim=512)\n","#x = transformer_block(x, num_heads=8, ff_dim=512)\n","x = transformer_block(x, num_heads=8, ff_dim=512)\n","x = Flatten()(x)\n","\n","\n","decoder_model = decoder((64,))\n","decoded = decoder_model(x)\n","\n","\n","classifier_model = build_classifier((64,))\n","classification = classifier_model(encoded_input)\n","\n","autoencoder_classifier = Model(encoder_model.input, [decoded, classification], name=\"autoencoder_classifier\")\n","\n","optimizer = Adam(learning_rate=lr_schedule, clipvalue=1.0)\n","\n","\n","autoencoder_classifier.compile(\n","    optimizer=optimizer,\n","    #loss={\"decoder\": combined_loss, \"classifier\": \"binary_crossentropy\"},\n","    loss=create_combined_loss(0.5, 0.4),\n","    metrics={'classifier': 'accuracy'}\n",")\n","\n","\n","autoencoder_classifier.summary()\n","\n","history = autoencoder_classifier.fit(\n","    x=X_train, \n","    y={\"classifier\": Y_train, \"decoder\": X_train}, \n","    epochs=350, \n","    batch_size=64, \n","    validation_data=(X_val, {\"classifier\": Y_val, \"decoder\": X_val}),\n","    #callbacks=[early_stopping]\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Tentativi Loss singola"]},{"cell_type":"markdown","metadata":{},"source":["## funzioni"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def augment_images_with_labels(images_array, labels_array, num_augmented_copies):\n","    if images_array.ndim == 3:\n","        images_array = np.expand_dims(images_array, axis=-1)\n","    \n","\n","    datagen = ImageDataGenerator(\n","        horizontal_flip=True,  # Ribaltamento orizzontale\n","        vertical_flip=True,    # Ribaltamento verticale\n","        rotation_range=10,     # Rotazione casuale tra -10 e 10 gradi\n","        width_shift_range=0.1, # Traslazione casuale del 10% su asse x\n","        height_shift_range=0.1,# Traslazione casuale del 10% su asse y\n","        zoom_range=0.2,        # Zoom casuale tra l'80% e il 120%\n","        brightness_range=[0.5, 0.8]  # Modifica casuale della luminositÃ  tra l'80% e il 120%\n","    )\n","\n","\n","    augmented_images = []\n","    augmented_labels = []\n","\n","    for image, label in zip(images_array, labels_array):\n","\n","        augmented_images.append(image)\n","        augmented_labels.append(label)\n","\n","    \n","        image = np.expand_dims(image, 0)  \n","        i = 0\n","        for batch in datagen.flow(image, batch_size=1):\n","            augmented_images.append(batch[0])\n","            augmented_labels.append(label) \n","            i += 1\n","            if i >= num_augmented_copies:\n","                break\n","\n","\n","    augmented_images_array = np.array(augmented_images)\n","    augmented_labels_array = np.array(augmented_labels)\n","\n","  \n","    print(\"Dimensione del vettore delle immagini aumentate:\", augmented_images_array.shape)\n","    print(\"Dimensione del vettore delle etichette aumentate:\", augmented_labels_array.shape)\n","\n","    return augmented_images_array, augmented_labels_array\n","\n","\n","\n","\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","def augment_images(images_array, num_augmented_copies):\n","    if images_array.ndim == 3:\n","        images_array = np.expand_dims(images_array, axis=-1)\n","    \n","\n","    datagen = ImageDataGenerator(\n","        horizontal_flip=True,  # Ribaltamento orizzontale\n","        vertical_flip=True,    # Ribaltamento verticale\n","        rotation_range=10,     # Rotazione casuale tra -10 e 10 gradi\n","        width_shift_range=0.1, # Traslazione casuale del 10% su asse x\n","        height_shift_range=0.1,# Traslazione casuale del 10% su asse y\n","        zoom_range=0.2,        # Zoom casuale tra l'80% e il 120%\n","        brightness_range=[0.5, 0.8]  # Modifica casuale della luminositÃ  tra l'80% e il 120%\n","    )\n","\n","\n","    augmented_images = []\n","\n","\n","    for image in images_array:\n","        augmented_images.append(image)\n","        image = np.expand_dims(image, 0)\n","        i = 0\n","        for batch in datagen.flow(image, batch_size=1):\n","            augmented_images.append(batch[0])\n","            i += 1\n","            if i >= num_augmented_copies:\n","                break\n","\n","\n","    augmented_images_array = np.array(augmented_images)\n","\n","    print(\"Dimensione del vettore delle immagini aumentate:\", augmented_images_array.shape)\n","\n","    return augmented_images_array"]},{"cell_type":"markdown","metadata":{},"source":["## split e preprocessing dati"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dividi i dati in set di addestramento, validazione e test\n","x_train, x_val = train_test_split(X_train, test_size=0.2, random_state=32, shuffle = True)\n","x_train, x_test_start = train_test_split(x_train, test_size=0.2, random_state=32, shuffle = True) \n","\n","\n","print(\"Dimensioni set di addestramento:\", x_train.shape)\n","print(\"Dimensioni set di validazione:\", x_val.shape)\n","print(\"Dimensioni set di test:\", x_test_start.shape)\n","\n","\n","x_train_start = augment_images(x_train, 5)\n","x_val_start = augment_images(x_val, 3)\n","\n","x_train_start = shuffle(x_train_start, random_state = 58)\n","x_val_start = shuffle(x_val_start, random_state = 99)\n","\n","print(x_train.shape)\n","print(x_val.shape)\n","print(x_test_start.shape)\n","\n","x_train=x_train_start.astype('float32')/255.\n","x_val=x_val_start.astype('float32')/255.\n","x_test=x_test_start.astype('float32')/255.\n","\n","x_test = np.expand_dims(x_test, axis = -1)\n","\n","\n","print(x_train[0].shape)\n","print(x_val[0].shape)\n","print(x_test[0].shape)"]},{"cell_type":"markdown","metadata":{},"source":["### Preprocessing per resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_train = np.repeat(x_train, 3, axis=-1)\n","x_val = np.repeat(x_val, 3, axis=-1)\n","x_test = np.repeat(x_test, 3, axis=-1)\n","\n","print(x_train.shape)\n","print(x_val.shape)\n","print(x_test.shape)\n","\n","x_train_resized = tf.image.resize(x_train, (224, 224), method='bicubic')\n","x_val_resized = tf.image.resize(x_val, (224, 224), method='bicubic')\n","x_test_resized = tf.image.resize(x_test, (224, 224), method='bicubic')\n","\n","# Converti a numpy array\n","x_train = x_train_resized.numpy()\n","x_val = x_val_resized.numpy()\n","x_test = x_test_resized.numpy()"]},{"cell_type":"markdown","metadata":{},"source":["## MODELLO 1 con 6 strati conv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","def encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Flatten()(x)\n","    encoded = Dense(32, activation='relu', kernel_regularizer=l1(10e-6))(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    encoder_model.summary()\n","    return encoder_model\n","\n","def decoder(output_shape):\n","    inputs = Input(shape=output_shape)\n","    x = Dense(2*2*256, activation='relu', kernel_regularizer=l1(10e-6))(inputs)\n","    x = Reshape((2, 2, 256))(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    decoder_model.summary()\n","    return decoder_model\n","\n","\n","input_shape = (64, 64, 1)\n","encoder_model = encoder(input_shape)\n","decoder_model = decoder(encoder_model.output_shape[1:])\n","\n","inputs = Input(shape=input_shape)\n","encoded = encoder_model(inputs)\n","decoded = decoder_model(encoded)\n","\n","autoencoder_model = Model(inputs, decoded, name='autoencoder')\n","\n","\n","autoencoder_model.compile(optimizer=Adam(learning_rate=1e-3),\n","                          loss='binary_crossentropy')\n","\n","\n","autoencoder_model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Modello 2 con 7 strati conv, trasformer e  custom loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=1e-4,\n","    decay_steps=35000,\n","    decay_rate=0.9)\n","\n","def combined_loss(y_true, y_pred):\n","    print(y_true.shape)\n","    print(y_pred.shape)\n","    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n","    mse_loss = mean_squared_error(y_true, y_pred)\n","    bce_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n","    return (1/2) * bce_loss + (1) * mse_loss + (1/2) * ssim_loss\n","\n","def transformer_block(x, num_heads, ff_dim, rate=0.3):\n","    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(x, x)\n","    attn_output = Dropout(rate)(attn_output)\n","    out1 = Add()([x, attn_output])  \n","    out1 = LayerNormalization(epsilon=1e-6)(out1)\n","\n","    ff_output = Dense(ff_dim, activation='relu')(out1)  \n","    ff_output = Dense(x.shape[-1])(ff_output)\n","    ff_output = Dropout(rate)(ff_output)\n","\n","    out2 = Add()([out1, ff_output])  \n","    return LayerNormalization(epsilon=1e-6)(out2)\n","\n","def encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(inputs)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Flatten()(x)\n","    \n","    x = Dense(64, activation='relu', kernel_regularizer=l1(10e-6))(x)\n","    encoded = Dropout(0.4)(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    return encoder_model\n","\n","def decoder(output_shape):\n","    inputs = Input(shape=output_shape)\n","    x = Dense(1*1*512, activation='relu', kernel_regularizer=l1(10e-6))(inputs)\n","    x = Reshape((1, 1, 512))(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","    x = UpSampling2D((2, 2))(x)\n","    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    return decoder_model\n","\n","\n","input_shape = (64, 64, 1)\n","encoder_model = encoder(input_shape)\n","\n","encoded_input = encoder_model.output\n","\n","# Transformer Block\n","x = Reshape((1, 64))(encoded_input)  # reshape per simulare una \"sequenza\"\n","x = transformer_block(x, num_heads=8, ff_dim=512)\n","x = transformer_block(x, num_heads=8, ff_dim=512)\n","x = transformer_block(x, num_heads=8, ff_dim=512)\n","x = Flatten()(x)\n","\n","\n","decoder_model = decoder((64,))\n","decoded = decoder_model(x)\n","\n","\n","autoencoder_model = Model(encoder_model.input, decoded, name='autoencoder_transformer')\n","\n","autoencoder_model.compile(optimizer=Adam(learning_rate=lr_schedule),\n","                          loss=combined_loss)\n","\n","autoencoder_model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Modello con perdita focale, 5 strati conv con leaky relu. Per immagini non annerite (senza ritaglio roi)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","## Loss che calcola una perdita personalizzata che penalizza maggiormente gli errori sui valori centrali (0.5) \n","# e favorisce la precisione per i valori estremi (0 e 1)\n","def focal_loss(y_true, y_pred):\n","    epsilon = tf.keras.backend.epsilon()\n","    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n","    \n","    mse_loss = tf.square(y_true - y_pred)\n","    \n","    central_weight = tf.square(0.4 - y_true)\n","    \n","    weighted_loss = mse_loss * (1 + (2 * central_weight))\n","    \n","    return tf.reduce_mean(weighted_loss)\n","\n","\n","# Parametri\n","alpha = 0.5\n","fm = (5,5)\n","kernel_initializer = he_normal()\n","dim = 16\n","\n","def encoder(input_shape):\n","    inputs = Input(shape=input_shape)\n","    \n","    x = Conv2D(dim, fm, padding='same', kernel_initializer=kernel_initializer)(inputs)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Conv2D(2 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Conv2D(4 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Conv2D(8* dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Conv2D(16 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Conv2D(32 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    #x = GlobalAveragePooling2D()(x)\n","    \n","    x = Flatten()(x)\n","    x = Dense(32, kernel_initializer=kernel_initializer, activity_regularizer=l2(0.001))(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","\n","    encoded = Dropout(0.5)(x)\n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    encoder_model.summary()\n","    return encoder_model\n","\n","def decoder(output_shape):\n","    inputs = Input(shape=output_shape)\n","    \n","    x = Dense(2 * 2 * 32* dim, kernel_initializer=kernel_initializer, activity_regularizer=l2(0.001))(inputs)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    \n","    x = Dropout(0.5)(x)\n","    x = Reshape((2, 2, 32 * dim))(x)\n","    x = UpSampling2D((2, 2))(x)\n","    \n","    x = Conv2D(32 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = UpSampling2D((2, 2))(x)\n","    \n","    x = Conv2D(16 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = UpSampling2D((2, 2))(x)\n","    \n","    x = Conv2D(8 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = UpSampling2D((2, 2))(x)\n","    \n","    x = Conv2D(4 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    x = UpSampling2D((2, 2))(x)\n","    \n","    x = Conv2D(2 * dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    \n","    x = Conv2D(dim, fm, padding='same', kernel_initializer=kernel_initializer)(x)\n","    x = LeakyReLU(alpha=alpha)(x)\n","    \n","    \n","    decoded = Conv2D(1, fm, activation='sigmoid', padding='same', kernel_initializer=kernel_initializer)(x)\n","    \n","    decoder_model = Model(inputs, decoded, name='decoder')\n","    decoder_model.summary()\n","    return decoder_model\n","\n","input_shape = (64, 64, 1)\n","encoder_model = encoder(input_shape)\n","decoder_model = decoder(encoder_model.output_shape[1:])\n","\n","inputs = Input(shape=input_shape)\n","encoded = encoder_model(inputs)\n","decoded = decoder_model(encoded)\n","autoencoder_model = Model(inputs, decoded, name='autoencoder')\n","\n","autoencoder_model.compile(optimizer=AdamW(learning_rate=1e-4), loss=focal_loss)\n","\n","autoencoder_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Modello con rete pretrainata Resnet 50 per immagini non annerite"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_encoder(input_shape, trainable_layers=10):\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    # Congelo tutti i layers\n","    for layer in base_model.layers:\n","        layer.trainable = False\n","    \n","    # Sblocco gli ultimi  layers per il fine-tuning\n","    for layer in base_model.layers[-trainable_layers:]:\n","        layer.trainable = True\n","    \n","    inputs = Input(shape=input_shape)\n","    x = base_model(inputs, training=True)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, kernel_initializer='he_normal', activity_regularizer=tf.keras.regularizers.l2(0.001))(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    encoded = Dropout(0.5)(x)\n","    \n","    encoder_model = Model(inputs, encoded, name='encoder')\n","    encoder_model.summary()\n","    return encoder_model\n","\n","def build_decoder(encoded_shape, original_shape):\n","    latent_inputs = Input(shape=encoded_shape)\n","    x = Dense(7 * 7 * 512, kernel_initializer='he_normal')(latent_inputs)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    x = Reshape((7, 7, 512))(x)\n","    \n","    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    \n","    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    \n","    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    \n","    x = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    \n","    x = Conv2DTranspose(16, (3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal')(x)\n","    x = LeakyReLU(alpha=0.1)(x)\n","    \n","    x = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same', kernel_initializer='he_normal')(x)\n","    \n","    decoded = Reshape(original_shape)(x)\n","    \n","    decoder_model = Model(latent_inputs, decoded, name='decoder')\n","    decoder_model.summary()\n","    return decoder_model\n","\n","\n","input_shape = (224, 224, 3)\n","encoded_shape = (128,)\n","\n","\n","encoder = build_encoder(input_shape)\n","decoder = build_decoder(encoded_shape, input_shape)\n","\n","\n","autoencoder_input = Input(shape=input_shape)\n","encoded_output = encoder(autoencoder_input)\n","decoded_output = decoder(encoded_output)\n","\n","autoencoder_model = Model(autoencoder_input, decoded_output, name='autoencoder')\n","    \n","\n","autoencoder_model.compile(optimizer=AdamW(learning_rate=1e-4), loss='mean_squared_error')\n","\n","autoencoder_model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Modello Resnet per immagini annerite"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def build_encoder():\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n","    encoder = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n","    return encoder\n","\n","\n","def build_decoder():\n","    decoder_input = Input(shape=(2, 2, 2048))  # Output del ResNet bottleneck\n","    x = Conv2DTranspose(512, kernel_size=3, strides=2, padding='same', activation='relu')(decoder_input)\n","    x = Conv2DTranspose(256, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n","    x = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n","    x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n","    x = Conv2DTranspose(1, kernel_size=3, strides=2, padding='same', activation='sigmoid')(x)\n","    decoder = Model(inputs=decoder_input, outputs=x)\n","    return decoder\n","\n","def build_autoencoder():\n","    encoder = build_encoder()\n","    \n","    # congelamento dei layer dell'encoder\n","    for layer in encoder.layers:\n","        layer.trainable = False \n","\n","    \n","    decoder = build_decoder()\n","\n","    input_img = Input(shape=(64, 64, 1))\n","    encoded = encoder(input_img)\n","    decoded = decoder(encoded)\n","\n","    autoencoder = Model(inputs=input_img, outputs=decoded)\n","    return autoencoder\n","\n","autoencoder_model = build_autoencoder()\n","autoencoder_model.compile(optimizer=AdamW(learning_rate=1e-4), loss='mse')\n","autoencoder_model.summary()\n"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-27T15:48:35.858491Z","iopub.status.busy":"2024-07-27T15:48:35.858140Z","iopub.status.idle":"2024-07-27T15:48:35.862619Z","shell.execute_reply":"2024-07-27T15:48:35.861565Z","shell.execute_reply.started":"2024-07-27T15:48:35.858462Z"}},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","## definizione callbacks \n","early_stopping = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_loss', \n","    patience=30,         \n","    restore_best_weights=True,\n","    min_delta=0.0002,\n","    verbose = True\n",")\n","\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss', \n","    factor=0.1,          \n","    patience=20,         \n","    min_delta=0.0001\n",")\n","\n","\n","\n","## istogramma andamento dei valori predetti durante l'allenamento (ogni 20 epoche)\n","def plot_predictions_histogram(epoch, model, val_data):\n","    if epoch % 20 == 0:\n","        x_val = val_data\n","        x_reconstructed = model.predict(x_val)\n","        x_val_flat = x_val.flatten()\n","        x_reconstructed_flat = x_reconstructed.flatten()\n","        \n","        plt.figure(figsize=(10, 5))\n","        plt.hist(x_reconstructed_flat, bins=20,  alpha=0.7, color='blue', label='Ricostruzioni',range=(0.01, 1))\n","        plt.hist(x_val_flat, bins=20, alpha=0.5, color='red', label='Input Originali',range=(0.01, 1))\n","        plt.xlabel('Valore')\n","        plt.ylabel('Frequenza')\n","        plt.title(f'Istogramma delle Ricostruzioni e degli Input Originali - Epoch {epoch}')\n","        plt.legend()\n","        plt.show()\n","        \n","\n","plot_callback = LambdaCallback(\n","    on_epoch_end=lambda epoch, logs: plot_predictions_histogram(epoch, autoencoder_model, x_val)\n",")\n","\n","\n","history=autoencoder_model.fit(x_train, x_train,\n","                      epochs=1000,\n","                      batch_size=512,\n","                      shuffle=True,\n","                      validation_data=(x_val, x_val),\n","                      callbacks=[early_stopping, plot_callback])\n","\n","# callbacks=[early_stopping, reduce_lr, plot_callback]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# salvataggio pesi modello\n","encoder_transformer_model = Model(encoder_model.input, x, name='encoder_transformer')\n","\n","encoder_transformer_model.save_weights('encoder_transformer_decay.weights.h5')\n","\n","encoder_transformer_model.save('encoder_transformer_model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Grafici loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_loss = history.history['loss'][3:]\n","validation_loss = history.history['val_loss'][3:]\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(range(1, len(training_loss) + 1), training_loss, label='Training Loss')\n","plt.plot(range(1, len(validation_loss) + 1), validation_loss, label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## visualizzazione immagini"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["num_images = 10\n","\n","reconstructed_images = autoencoder_model.predict(x_test)\n","\n","\n","print(reconstructed_images.shape)\n","print(x_test.shape)\n","\n","\n","plt.figure(figsize=(15, 6))\n","for i in range(num_images):\n","    # Immagine originale\n","    plt.subplot(2, num_images, i + 1)\n","    plt.imshow(x_test[i], cmap='gray')\n","    plt.title('Originale')\n","    plt.axis('off')\n","\n","    # Immagine ricostruita\n","    plt.subplot(2, num_images, i + num_images + 1)\n","    plt.imshow(reconstructed_images[i], cmap='gray')\n","    plt.title('Ricostruita')\n","    plt.axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## indici di similarita immagini 1 canale"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## predizioni\n","reconstructed_images = autoencoder_model.predict(x_test)\n","\n","\n","if reconstructed_images.shape[-1] == 1:\n","    reconstructed_images = np.squeeze(reconstructed_images, axis=-1)\n","if x_test.shape[-1] == 1:\n","    x_test = np.squeeze(x_test, axis=-1)\n","\n","ssim_values = []\n","for i in range(len(reconstructed_images)):\n","    orig_img = x_test[i]\n","    recon_img = reconstructed_images[i]\n","    ssim_value = ssim(orig_img, recon_img, data_range=1.0, multichannel=False)\n","    ssim_values.append(ssim_value)\n","\n","\n","mean_ssim = np.mean(ssim_values)\n","std_ssim = np.std(ssim_values)\n","\n","\n","print(f\"Valore medio di SSIM: {mean_ssim}\")\n","print(f\"Deviazione standard di SSIM: {std_ssim}\")\n","\n","index = 7\n","\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(x_test[index], cmap='gray')\n","plt.title(\"Originale\")\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(reconstructed_images[index], cmap='gray')\n","plt.title(\"Ricostruita\")\n","plt.axis('off')\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["## ssim con maschera"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def find_bounding_box(image):\n","    # Trova i bordi del rettangolo contenente la placca\n","    rows = np.any(image, axis=1)\n","    cols = np.any(image, axis=0)\n","    y_min, y_max = np.where(rows)[0][[0, -1]]\n","    x_min, x_max = np.where(cols)[0][[0, -1]]\n","    return y_min, y_max, x_min, x_max\n","\n","if reconstructed_images.shape[-1] == 1:\n","    reconstructed_images = np.squeeze(reconstructed_images, axis=-1)\n","if x_test.shape[-1] == 1:\n","    x_test = np.squeeze(x_test, axis=-1)\n","\n","ssim_values = []\n","for i in range(len(reconstructed_images)):\n","    orig_img = x_test[i]\n","    recon_img = reconstructed_images[i]\n","    y_min, y_max, x_min, x_max = find_bounding_box(orig_img)\n","\n","    orig_rect = orig_img[y_min:y_max+1, x_min:x_max+1]\n","    recon_rect = recon_img[y_min:y_max+1, x_min:x_max+1]\n","\n","    ssim_value = ssim(orig_rect, recon_rect, data_range=1.0)\n","    ssim_values.append(ssim_value)\n","    #print(f\"SSIM per immagine {i + 1}: {ssim_value}\")\n","\n","\n","mean_ssim = np.mean(ssim_values)\n","std_ssim = np.std(ssim_values)\n","\n","\n","print(f\"Valore medio di SSIM: {mean_ssim}\")\n","print(f\"Deviazione standard di SSIM: {std_ssim}\")\n","\n","# Visualizzazione della maschera per un esempio \n","example_index = 557\n","example_orig_img = x_test[example_index]\n","example_recon_img = reconstructed_images[example_index]\n","\n","y_min, y_max, x_min, x_max = find_bounding_box(example_orig_img)\n","\n","fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n","\n","# Immagine originale con rettangolo\n","ax[0].imshow(example_orig_img, cmap='gray')\n","rect = patches.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, linewidth=1, edgecolor='r', facecolor='none')\n","ax[0].add_patch(rect)\n","ax[0].set_title(\"Originale con Maschera\")\n","ax[0].axis('off')\n","\n","# Immagine ricostruita\n","ax[1].imshow(example_recon_img, cmap='gray')\n","ax[1].set_title(\"Ricostruita\")\n","ax[1].axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## indici di similaritÃ  3 canali"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","from skimage.metrics import structural_similarity as ssim\n","from sklearn.metrics import mean_squared_error\n","from skimage.metrics import peak_signal_noise_ratio\n","from scipy.spatial.distance import cosine\n","\n","if reconstructed_images.shape[-1] == 1:\n","    reconstructed_images = np.squeeze(reconstructed_images, axis=-1)\n","\n","def calculate_ssim(original, reconstructed):\n","    ssim_values = []\n","    ssim_values_mask = []\n","    for i in range(len(original)):\n","        mask = original[i] > 0\n","        ssim_value_mask = ssim(original[i], reconstructed[i], data_range=1.0, channel_axis=-1, win_size=3)\n","        ssim_values_mask.append(ssim_value_mask)\n","        ssim_value = ssim(original[i], reconstructed[i], data_range=1.0, channel_axis=-1, win_size=3)\n","        ssim_values.append(ssim_value)\n","    return np.mean(ssim_values_mask), np.mean(ssim_values)\n","\n","def calculate_cosine_similarity(original, reconstructed):\n","    cosine_values = []\n","    cosine_values_mask = []\n","    for i in range(len(original)):\n","        original_flat = original[i].flatten()\n","        reconstructed_flat = reconstructed[i].flatten()\n","        cosine_value = 1 - cosine(original_flat, reconstructed_flat)\n","        cosine_values.append(cosine_value)\n","\n","    for i in range(len(original)):\n","        mask = original[i] > 0\n","        original_flat = original[i][mask].flatten()\n","        reconstructed_flat = reconstructed[i][mask].flatten()\n","        cosine_value = 1 - cosine(original_flat, reconstructed_flat)\n","        cosine_values_mask.append(cosine_value)\n","    return np.mean(cosine_values), np.mean(cosine_values_mask)\n","\n","\n","\n","ssim_value, ssim_value_mask = calculate_ssim(x_test, reconstructed_images)\n","cosine_similarity_value, cosine_similarity_value_mask = calculate_cosine_similarity(x_test, reconstructed_images)\n","\n","\n","print(f'Mean SSIM: {ssim_value} and Mean SSIM with mask: {ssim_value_mask}')\n","print(f'Mean Cosine Similarity: {cosine_similarity_value} and Mean Cosine Similarity with mask: {cosine_similarity_value_mask}')\n","\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5049797,"sourceId":8469228,"sourceType":"datasetVersion"},{"datasetId":5056158,"sourceId":8477799,"sourceType":"datasetVersion"},{"datasetId":5322302,"sourceId":8843034,"sourceType":"datasetVersion"},{"datasetId":5378382,"sourceId":8938911,"sourceType":"datasetVersion"},{"datasetId":5392363,"sourceId":8959210,"sourceType":"datasetVersion"},{"datasetId":5392435,"sourceId":8959312,"sourceType":"datasetVersion"},{"datasetId":5585329,"sourceId":9234046,"sourceType":"datasetVersion"},{"datasetId":5592896,"sourceId":9245398,"sourceType":"datasetVersion"},{"datasetId":5714717,"sourceId":9410905,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
