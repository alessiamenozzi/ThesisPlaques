{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## esegui all'inizio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati caricati da C:\\Users\\bsbar\\Desktop\\Tesi\\ThesisPlaques\\classificator_data.h5\n",
      "Numero di pazienti: 124\n",
      "Esempio di immagini per paziente: (28, 64, 64)\n",
      "Labels: [0 1 1 0 0 0 0 1 0 0 1 1 0 0 1 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0\n",
      " 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 0 0 1 0\n",
      " 1 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 1 0 1 0 1]\n",
      "Number of labels: 124\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pymrmr\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "import os\n",
    "\n",
    "# Imposta la variabile di ambiente\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '14'\n",
    "\n",
    "\n",
    "# Percorso del file HDF5 da cui caricare i dati\n",
    "#load_path = \"/Users/alessiamenozzi/Desktop/ThesisPlaques/classificator_data.h5\"\n",
    "load_path = \"C:\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ThesisPlaques\\\\classificator_data.h5\"\n",
    "\n",
    "# Inizializza le liste per contenere i dati\n",
    "loaded_class_images = []\n",
    "loaded_class_labels = None\n",
    "loaded_patients = None\n",
    "\n",
    "# Apre il file HDF5 in modalità lettura\n",
    "with h5py.File(load_path, 'r') as hf:\n",
    "    # Itera su tutti i gruppi nel file HDF5\n",
    "    for group_name in hf.keys():\n",
    "        # Controlla se il nome del gruppo inizia con \"patient_\"\n",
    "        if group_name.startswith(\"patient_\"):\n",
    "            group = hf[group_name]\n",
    "            # Carica le immagini dal dataset 'images' all'interno del gruppo\n",
    "            loaded_class_images.append(np.array(group['images']))\n",
    "        elif group_name == \"labels\":\n",
    "            # Carica le etichette dal dataset 'labels'\n",
    "            loaded_class_labels = hf['labels'][:]\n",
    "        elif group_name == \"patients\":\n",
    "            # Carica i numeri dei pazienti dal dataset 'patients'\n",
    "            loaded_patients = hf['patients'][:]\n",
    "\n",
    "print(f\"Dati caricati da {load_path}\")\n",
    "print(f\"Numero di pazienti: {len(loaded_class_images)}\")\n",
    "print(f\"Esempio di immagini per paziente: {loaded_class_images[0].shape}\")\n",
    "\n",
    "\n",
    "# Carica il file CSV\n",
    "#file_path = \"/Users/alessiamenozzi/Desktop/ThesisPlaques/data_rad_clin_DEF.csv\"\n",
    "file_path = \"C:\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ThesisPlaques\\\\data_rad_clin_DEF.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Lista degli ID da escludere\n",
    "ids_to_exclude = [\"patient_TC_19\", \"patient_TC_40\", \"patient_TC_88\", \"patient_TC_150\", \"patient_TC_193\"]\n",
    "\n",
    "# Filtra il DataFrame per escludere le righe con gli ID specificati\n",
    "filtered_data = data[~data['IDs_new'].isin(ids_to_exclude)]\n",
    "\n",
    "# Estrae i valori dalla colonna 'label' del DataFrame filtrato\n",
    "labels_column = filtered_data['label']\n",
    "\n",
    "# Converte i valori della colonna 'label' in numeri interi\n",
    "labels = labels_column.astype(int).tolist()\n",
    "\n",
    "labels=np.array(labels)\n",
    "print(\"Labels:\", labels)\n",
    "print(\"Number of labels:\", len(labels))\n",
    "\n",
    "\n",
    "# Carica il modello encoder\n",
    "#encoder = load_model(\"/Users/alessiamenozzi/Desktop/ThesisPlaques/encoder_models/encoder_model32.h5\", compile=False)\n",
    "#encoder = load_model(\"/Users/alessiamenozzi/Desktop/encoder64_senzaDense.h5\", compile=False)\n",
    "encoder = load_model(\"C:\\\\Users\\\\bsbar\\\\Desktop\\\\Tesi\\\\ThesisPlaques\\\\encoder_models\\\\encoder_model64.h5\", compile=False)\n",
    "\n",
    "# Funzione per ottenere le feature da una singola immagine\n",
    "def get_features_from_image(image):\n",
    "    image = image.astype('float32')\n",
    "    image = image / 255.0\n",
    "    # Ottieni le feature dall'encoder\n",
    "    if len(image.shape) == 2:  # Se l'immagine è 64x64\n",
    "        image = np.expand_dims(image, axis=-1)  # Aggiungi canale se necessario (per immagini in bianco e nero)\n",
    "    image = np.expand_dims(image, axis=0)  # Aggiungi dimensione batch\n",
    "    features = encoder.predict(image, verbose=False)\n",
    "    features = np.squeeze(features)\n",
    "    #print(features.shape)\n",
    "    return np.array(features)\n",
    "\n",
    "# Lista per salvare le feature delle immagini\n",
    "patients = []\n",
    "\n",
    "# Ottieni le feature per ogni immagine nella lista\n",
    "for i in range(len(loaded_class_images)):\n",
    "    features_list = []\n",
    "    for img in loaded_class_images[i]:\n",
    "        features = get_features_from_image(img)\n",
    "        features_list.append(features)\n",
    "    fetures_list = np.array(features_list)\n",
    "    patients.append(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funzioni 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILE DI FUNZIONI\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve, auc, average_precision_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#import pymrmr\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "\n",
    "\n",
    "def continue_array(filtered_patients, labels):\n",
    "    all_features = []\n",
    "    for patient in filtered_patients:\n",
    "        for image_features in patient:\n",
    "            all_features.append(image_features)\n",
    "\n",
    "    all_features_array = np.array(all_features)\n",
    "\n",
    "    # Print the shape of the combined features array\n",
    "    #print(f\"Shape of combined features array: {all_features_array.shape}\")\n",
    "\n",
    "    # Initialize the new expanded labels and patient IDs vectors\n",
    "    expanded_labels = []\n",
    "    expanded_patient_ids = []\n",
    "\n",
    "    # Assuming labels and loaded_patients are already defined\n",
    "    # labels: A list of length 124 with labels for each patient\n",
    "    # loaded_patients: A list of length 124 with IDs for each patient\n",
    "\n",
    "    # Iterate over the filtered patients and expand the labels and patient IDs\n",
    "    for i in range(len(filtered_patients)):\n",
    "        num_images = len(filtered_patients[i])  # Number of images for the current patient\n",
    "        expanded_labels.extend([labels[i]] * num_images)  # Assign the same label to all images of the patient\n",
    "        expanded_patient_ids.extend([loaded_patients[i]] * num_images)  # Assign the same patient ID to all images of the patient\n",
    "\n",
    "    # Convert the lists to NumPy arrays\n",
    "    expanded_labels_array = np.array(expanded_labels)\n",
    "    expanded_patient_ids_array = np.array(expanded_patient_ids)\n",
    "\n",
    "    # Print the shapes of the new arrays to verify\n",
    "    #print(f\"Shape of expanded labels array: {expanded_labels_array.shape}\")\n",
    "    #print(f\"Shape of expanded patient IDs array: {expanded_patient_ids_array.shape}\")\n",
    "    return all_features_array, expanded_labels_array, expanded_patient_ids_array\n",
    "\n",
    "\n",
    "def filter_highly_correlated_features(df, corr, threshold=0.85):\n",
    "    columns = np.full((corr.shape[0],), True, dtype=bool)\n",
    "    removed_features = []\n",
    "\n",
    "    for i in range(corr.shape[0]):\n",
    "        for j in range(i + 1, corr.shape[0]):\n",
    "            if corr.iloc[i, j] >= threshold:\n",
    "                if columns[j]:\n",
    "                    columns[j] = False\n",
    "                    removed_features.append(df.columns[j])\n",
    "\n",
    "    #selected_columns = df.columns[columns]\n",
    "    return removed_features\n",
    "\n",
    "\n",
    "\n",
    "def remove_features_from_patients(patients, features_to_remove):\n",
    "    # Estrai gli indici delle caratteristiche da rimuovere\n",
    "    feature_indices_to_remove = [int(feature.split('_')[1]) for feature in features_to_remove]\n",
    "    \n",
    "    # Rimuovi le caratteristiche corrispondenti dagli array dei pazienti\n",
    "    final_patients = []\n",
    "    for patient in patients:\n",
    "        new_patients = []\n",
    "        for image_features in patient:\n",
    "            new_patient = np.delete(image_features, feature_indices_to_remove, axis=0)\n",
    "            new_patients.append(new_patient)\n",
    "        final_patients.append(np.array(new_patients))    \n",
    "\n",
    "    return final_patients\n",
    "\n",
    "\n",
    "def perform_correlation(z_train, y_train, numero = 32, threshold = 0.85):\n",
    "    # Supponiamo che loaded_patients contenga le etichette dei pazienti\n",
    "\n",
    "    all_images, _, _= continue_array(z_train, y_train)\n",
    "\n",
    "    # Creazione del DataFrame con le immagini come righe e le features come colonne\n",
    "    df = pd.DataFrame(all_images, columns=[f'feature_{i}' for i in range(numero)])\n",
    "\n",
    "    # Visualizzazione del DataFrame\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    # Se vuoi anche visualizzare la matrice di correlazione con Seaborn\n",
    "    #plt.figure(figsize=(12, 10))\n",
    "    #sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "    #plt.title(\"Feature Correlation Matrix\")\n",
    "    #plt.show()  \n",
    "    \n",
    "    features_selected = filter_highly_correlated_features(df, corr_matrix, threshold)\n",
    "    \n",
    "    return features_selected\n",
    "\n",
    "\n",
    "\n",
    "## FEATURE SELECTION LASSO\n",
    "def select_features_with_lasso(X, y, alpha=0.001):\n",
    "    \n",
    "    # Fit Lasso regression model\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X, y)\n",
    "\n",
    "    # Get coefficients\n",
    "    coefficients = lasso.coef_\n",
    "\n",
    "    # Select features with non-zero coefficients\n",
    "    selected_features = np.where(coefficients != 0)[0]\n",
    "\n",
    "    # Create new feature matrix with only selected features\n",
    "    X_selected = X[:, selected_features]\n",
    "\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FEATURE SELECTION LOGISTIC\n",
    "def logistic_regression_feature_selection(X, y, num_features):\n",
    "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    lr.fit(X, y)\n",
    "    coef_abs = np.abs(lr.coef_)\n",
    "    feature_importances = np.mean(coef_abs, axis=0)\n",
    "    selected_features = feature_importances.argsort()[-num_features:][::-1]\n",
    "    # Create new feature matrix with only selected features\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FEATURE SELECTION MRMR\n",
    "def mrmr_feature_selection(X, y, num_features):\n",
    "    feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "    data = pd.DataFrame(X, columns=feature_names)\n",
    "    data['target'] = y\n",
    "    data.columns = data.columns.astype(str)\n",
    "    selected_features = pymrmr.mRMR(data, 'MIQ', num_features)\n",
    "    selected_indices = [data.columns.get_loc(feature) for feature in selected_features]\n",
    "    # Crea una nuova matrice delle caratteristiche con solo le caratteristiche selezionate\n",
    "    X_selected = X[:, selected_indices]\n",
    "\n",
    "    return X_selected, selected_indices\n",
    "\n",
    "## FEATURE SELECTION RANDOM FOREST\n",
    "def rf_feature_selection(X, y, num_features):\n",
    "    # Inizializza il classificatore Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    # Addestra il modello\n",
    "    rf.fit(X, y)\n",
    "    # Ottieni l'importanza delle caratteristiche\n",
    "    feature_importances = rf.feature_importances_\n",
    "    # Seleziona gli indici delle caratteristiche più importanti\n",
    "    selected_features = np.argsort(feature_importances)[-num_features:][::-1]\n",
    "    # Crea una nuova matrice di caratteristiche con solo le caratteristiche selezionate\n",
    "    X_selected = X[:, selected_features]\n",
    "    return X_selected, selected_features\n",
    "\n",
    "## FUNZIONE PER RIMUOVERE FEATURES SELEZIONATE\n",
    "def filter_patients_features(filtered_patients, selected_features):\n",
    "    \"\"\"\n",
    "    Removes the non-selected features from the filtered_patients array.\n",
    "\n",
    "    Parameters:\n",
    "    filtered_patients (list of numpy.ndarray): The list containing patients' images' features.\n",
    "    selected_features (numpy.ndarray): The indices of the selected features.\n",
    "\n",
    "    Returns:\n",
    "    list of numpy.ndarray: The new filtered_patients array with only the selected features.\n",
    "    \"\"\"\n",
    "    filtered_patients_selected = []\n",
    "\n",
    "    for patient_features in filtered_patients:\n",
    "        # Select only the features specified in selected_features\n",
    "        patient_features_selected = patient_features[:, selected_features]\n",
    "        filtered_patients_selected.append(patient_features_selected)\n",
    "\n",
    "    return filtered_patients_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funzioni 2 per la classificazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classificazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "def prob_to_binary(predictions_proba, threshold):\n",
    "        final_predictionarray=[]          \n",
    "        ## majority voting\n",
    "        for p in predictions_proba:\n",
    "            test_patient_predictions=[]\n",
    "            for proba in p:               \n",
    "                predictions_binary = 1 if proba[0][1] > threshold else 0\n",
    "                test_patient_predictions.append(predictions_binary)\n",
    "            count_0 = np.sum(np.array(test_patient_predictions)==0) \n",
    "            count_1 = np.sum(np.array(test_patient_predictions)==1)                                   \n",
    "            final_prediction = 0 if count_0 > count_1 else 1\n",
    "            final_predictionarray.append(final_prediction)\n",
    "         \n",
    "        return final_predictionarray\n",
    "\n",
    "\n",
    "def classification_method1(selector, alpha, classifier, x_train_expanded, y_train_expanded, patients_test, y_test, features_test, num_features, thresholds=np.arange(0.001, 0.501, 0.001), mode = \"Val\", selected_features= [0]):\n",
    "\n",
    "    if(mode == \"Val\"):\n",
    "        selected_features = None  # Inizializziamo selected_features per prevenire l'errore UnboundLocalError\n",
    "        \n",
    "        if num_features != len(x_train_expanded[0]) or alpha != 0:\n",
    "            if selector == \"lasso\":\n",
    "                X_selected, selected_features = select_features_with_lasso(x_train_expanded, y_train_expanded, alpha)\n",
    "            elif selector == \"logistic\": \n",
    "                X_selected, selected_features = logistic_regression_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"mrmr\":\n",
    "                X_selected, selected_features = mrmr_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            elif selector == \"rf\":\n",
    "                X_selected, selected_features = rf_feature_selection(x_train_expanded, y_train_expanded, num_features)\n",
    "            else:\n",
    "                print(\"Wrong selector. Choose between: mrmr, rf, logistic, lasso\")\n",
    "                return\n",
    "            \n",
    "            features_test = filter_patients_features(features_test, selected_features)\n",
    "        else:\n",
    "            X_selected = x_train_expanded\n",
    "            selected_features = list(range(len(x_train_expanded[0])))  # Selezioniamo tutte le feature se non si fa feature selection\n",
    "\n",
    "        number_features = len(selected_features)  # Ora number_features è sempre definito correttamente\n",
    "        \n",
    "        if len(X_selected[0]) == 0:\n",
    "            return 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "        \n",
    "        #smote = SMOTE(random_state=42)\n",
    "        adasyn = ADASYN(random_state=42)\n",
    "\n",
    "        # Applicare SMOTE al set di dati di addestramento espanso\n",
    "        #X_resampled, y_resampled = smote.fit_resample(X_selected, y_train_expanded)\n",
    "        X_resampled, y_resampled = adasyn.fit_resample(X_selected, y_train_expanded)\n",
    "\n",
    "        #print(X_selected, \" vs Resampled \", X_resampled)\n",
    "        #print(y_test, \"vs resempled \" , y_resampled)\n",
    "        #classifier.fit(X_selected, y_train_expanded)\n",
    "        classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "   \n",
    "    if (mode == \"Test\"):\n",
    "        features_test = filter_patients_features(features_test, selected_features)\n",
    "        number_features = len(selected_features)\n",
    "\n",
    "    ### questo trova le probabilità e fa la media\n",
    "    temp_array = []\n",
    "    patient_scores = []\n",
    "\n",
    "    for x in range(len(patients_test)):\n",
    "        patient_predictions = []\n",
    "        patient_predictions1 = []\n",
    "        for i in range(len(features_test[x])):\n",
    "            dato = features_test[x][i].reshape(1, -1)\n",
    "            prediction = classifier.predict_proba(dato)\n",
    "            prediction1 = classifier.predict_proba(dato)[:,1]\n",
    "            patient_predictions.append(prediction)\n",
    "            patient_predictions1.append(prediction1)\n",
    "            mean=np.mean(patient_predictions1)\n",
    "\n",
    "        patient_scores.append(mean) ## contiene la media delle probabilità\n",
    "        temp_array.append(patient_predictions) ## contiene tutte le probabilità\n",
    "    \n",
    "    best_f1_score = 0\n",
    "    best_threshold = None\n",
    "    best_precision=0\n",
    "    best_recall=0\n",
    "    best_prediction=[]\n",
    "    \n",
    "\n",
    "    # Valuta le performance utilizzando diverse threshold\n",
    "    #thresholds = np.arange(0.001, 0.501, 0.001)\n",
    "    #thresholds=[0.5]\n",
    "    if isinstance(thresholds, (int, float, complex)):\n",
    "        thresholds=[thresholds]\n",
    "\n",
    "    ## se non viene specificato usi il parametro di default \n",
    "    if(len(thresholds)!=1):\n",
    "        for threshold in thresholds:\n",
    "            binary_predictions = prob_to_binary(temp_array, threshold)\n",
    "            f1 = f1_score(y_test, binary_predictions)\n",
    "            if f1 > best_f1_score:\n",
    "                best_f1_score = f1\n",
    "                best_threshold = threshold\n",
    "                best_precision = precision_score(y_test, binary_predictions)\n",
    "                best_recall = recall_score(y_test, binary_predictions)\n",
    "                best_prediction=binary_predictions\n",
    "\n",
    "    else: ## qui vuol dire che è il set di test che usa la threshold migliore\n",
    "        best_threshold = thresholds\n",
    "        best_prediction=prob_to_binary(temp_array, best_threshold)\n",
    "        best_f1_score = f1_score(y_test, best_prediction)\n",
    "        best_precision = precision_score(y_test, best_prediction)\n",
    "        best_recall = recall_score(y_test, best_prediction)\n",
    "\n",
    "    #print(f\"La migliore threshold è {best_threshold} con f1score di {best_f1_score} e precision {best_precision} e recall {best_recall}.\")\n",
    "\n",
    "    y_test= np.array(y_test)\n",
    "    best_prediction=np.array(best_prediction)\n",
    "    test_accuracy = accuracy_score(y_test, best_prediction)\n",
    "\n",
    "\n",
    "    #test_precision = precision_score(y_test, best_prediction)\n",
    "    #test_recall = recall_score(y_test, best_prediction)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, patient_scores)\n",
    "    pr_auc = average_precision_score(y_test, patient_scores)\n",
    "\n",
    "    #fpr, tpr, _ = roc_curve(y_test, best_prediction)\n",
    "    roc_auc= roc_auc_score(y_test, patient_scores)\n",
    "\n",
    "\n",
    "    conf= confusion_matrix(y_test, best_prediction)\n",
    "\n",
    "    return best_f1_score, best_precision, best_recall, conf, test_accuracy, precision, recall, pr_auc, roc_auc, best_threshold, number_features, selected_features, classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold_features(results_rf, selector):\n",
    "    best_thresholds = []\n",
    "    best_num_features=[]\n",
    "    best_alpha=[]\n",
    "\n",
    "    fold_results = results_rf[selector]\n",
    "        \n",
    "        # Inizialmente, tutti gli indici con il massimo F1 score\n",
    "    best_f1_indices = np.where(fold_results['f1'] == np.max(fold_results['f1']))[0]\n",
    "        \n",
    "    if len(best_f1_indices) > 1:\n",
    "            # In caso di parità di F1, considera il pr_auc\n",
    "            max_pr_auc = max(fold_results['pr_auc'][j] for j in best_f1_indices)\n",
    "            best_f1_indices = [j for j in best_f1_indices if fold_results['pr_auc'][j] == max_pr_auc]\n",
    "            # In caso di ulteriore parità, considera l'accuracy\n",
    "            if len(best_f1_indices)!=1:\n",
    "                max_accuracy = max(fold_results['accuracy'][j] for j in best_f1_indices)\n",
    "                best_f1_indices = [j for j in best_f1_indices if fold_results['accuracy'][j] == max_accuracy]\n",
    "                if len(best_f1_indices)!=1:\n",
    "                    max_roc_auc = max(fold_results['roc_auc'][j] for j in best_f1_indices)\n",
    "                    best_f1_indices = [j for j in best_f1_indices if fold_results['roc_auc'][j] == max_roc_auc]\n",
    "                    #best_f1_indices= best_f1_indices[0]\n",
    "           \n",
    "    best_index = best_f1_indices[0]\n",
    "\n",
    "\n",
    "    # Ottieni l'indice finale del miglior F1 score\n",
    "    best_threshold=fold_results['best_threshold'][best_index]\n",
    "\n",
    "    if selector == 'lasso':\n",
    "        mean_param=fold_results['alpha'][best_index]\n",
    "    else:\n",
    "        mean_param=fold_results['num_features'][best_index]\n",
    "\n",
    "\n",
    "\n",
    "    return best_threshold, mean_param\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supponiamo che tu abbia un elenco di colori predefiniti per i fold\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
    "\n",
    "# Supponiamo che results_rf sia un dizionario di dizionari dove:\n",
    "# results_rf[i][selector] contiene i dati per il fold i e il selettore selector.\n",
    "# results_test_rf contiene i dati per il set di test finale per ogni selector.\n",
    "\n",
    "def plot_results(results_rf, results_test_rf, selector):\n",
    "\n",
    "    # Plotta i risultati per PR AUC\n",
    "    if selector == 'lasso':\n",
    "        \n",
    "        plt.figure()\n",
    "        for i in range(len(results_rf)):\n",
    "            fold_results = results_rf[i][selector]\n",
    "            plt.plot(fold_results['alpha'], fold_results['pr_auc'], marker='o', linestyle='-', color=colors[i % len(colors)], label=f'Fold {i+1}')\n",
    "        \n",
    "        # Plot dei risultati del set di test\n",
    "        plt.plot(results_test_rf[selector]['alpha'], results_test_rf[selector]['pr_auc'], marker='x', linestyle='--', color='black', label='Test Set')\n",
    "        \n",
    "        plt.xlabel('Alpha Values')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.title(f'Alpha Values vs PR AUC for {selector} selector')\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotta i risultati per ROC AUC\n",
    "        plt.figure()\n",
    "        for i in range(len(results_rf)):\n",
    "            fold_results = results_rf[i][selector]\n",
    "            plt.plot(fold_results['alpha'], fold_results['roc_auc'], marker='o', linestyle='-', color=colors[i % len(colors)], label=f'Fold {i+1}')\n",
    "        \n",
    "        # Plot dei risultati del set di test\n",
    "        plt.plot(results_test_rf[selector]['alpha'], results_test_rf[selector]['roc_auc'], marker='x', linestyle='--', color='black', label='Test Set')\n",
    "        \n",
    "        plt.xlabel('Alpha Values')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.title(f'Alpha Values vs ROC AUC for {selector} selector')\n",
    "        plt.xscale('log')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    else:\n",
    "        plt.figure()\n",
    "        for i in range(len(results_rf)):\n",
    "            fold_results = results_rf[i][selector]\n",
    "            plt.plot(fold_results['num_features'], fold_results['pr_auc'], marker='o', linestyle='-', color=colors[i % len(colors)], label=f'Fold {i+1}')\n",
    "        \n",
    "        # Plot dei risultati del set di test\n",
    "        plt.plot(results_test_rf[selector]['num_features'], results_test_rf[selector]['pr_auc'], marker='x', linestyle='--', color='black', label='Test Set')\n",
    "        \n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.title(f'Number of Features vs PR AUC for {selector} selector')\n",
    "        plt.xscale('linear')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Plotta i risultati per ROC AUC\n",
    "        plt.figure()\n",
    "        for i in range(len(results_rf)):\n",
    "            fold_results = results_rf[i][selector]\n",
    "            plt.plot(fold_results['num_features'], fold_results['roc_auc'], marker='o', linestyle='-', color=colors[i % len(colors)], label=f'Fold {i+1}')\n",
    "        \n",
    "        # Plot dei risultati del set di test\n",
    "        plt.plot(results_test_rf[selector]['num_features'], results_test_rf[selector]['roc_auc'], marker='x', linestyle='--', color='black', label='Test Set')\n",
    "        \n",
    "        plt.xlabel('Number of Features')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.title(f'Number of Features vs ROC AUC for {selector} selector')\n",
    "        plt.xscale('linear')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## codice con split e cross val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69,)\n",
      "[102  70  95  53 111  78 113 115 129  33  61  27  75 104 146 133 120  84\n",
      " 107  23  24  39 136 135  68  94  81  44  42  15  48 126  41  91  54  35\n",
      " 117  17  65  89  98  82  96  90 119 139 127  43 112  92 118  59 100 144\n",
      " 106 101  62 108  87  74  71  22 128 137 116  52 124 103 105]\n",
      "[147 149 153 155 158 159 161 163 166 168 169 170 171 175 176 178 182 183\n",
      " 188 189 190 197 199 200 205]\n",
      "69\n",
      "64\n",
      "38\n",
      "22\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "#patients_train, patients_test, y_train, y_test, features_train, features_test= train_test_split(loaded_patients, labels, patients, test_size=0.2, shuffle=True, stratify=labels, random_state=46)\n",
    "\n",
    "patients_train, patients_test, y_train, y_test, features_train, features_test= train_test_split(loaded_patients, labels, patients, test_size=0.2, shuffle=False, random_state=1)\n",
    "patients_train, patients_val, y_train, y_val, features_train, features_val= train_test_split(patients_train, y_train, features_train, test_size=0.3, shuffle=True, stratify=y_train, random_state=1)\n",
    "\n",
    "print(patients_train.shape)\n",
    "print(patients_train)\n",
    "print(patients_test)\n",
    "print(len(features_train))\n",
    "print(len(features_train[0][0]))\n",
    "print(len(features_train[1]))\n",
    "print(len(features_train[2]))\n",
    "print(patients_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "alpha_values = np.linspace(0, 0.006, 30).tolist()\n",
    "\n",
    "selectors=['rf', 'logistic', 'lasso', 'mrmr']\n",
    "#selectors=['rf', 'lasso', 'logistic']\n",
    "classifiers=['RandomForest', 'Logistic', 'XgBoost', 'MLP', 'SVM']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOP con tutti i selector e classificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with classifier: RandomForest\n",
      "Doing with selector: rf\n",
      "Doing with selector: logistic\n",
      "Doing with selector: lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\base.py:1152: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "c:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\bsbar\\anaconda3\\envs\\iml\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+02, tolerance: 5.645e-02 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_test=[{} for _ in range(len(classifiers))]\n",
    "results_val = [{} for _ in range(len(classifiers))]\n",
    "i=0\n",
    "for classifier in classifiers:\n",
    "    print(\"Starting with classifier:\", classifier)\n",
    "    for selector in selectors: \n",
    "        print(\"Doing with selector:\", selector)\n",
    "        results_test[i][selector] = {\n",
    "                'classifier': classifier,\n",
    "                'alpha': [],\n",
    "                'num_features': [],\n",
    "                'pr_auc': [],\n",
    "                'best_precision' :[],\n",
    "                'best_recall':[],\n",
    "                'roc_auc':[],\n",
    "                'f1':[],\n",
    "                'accuracy':[],\n",
    "                'confusion_matrix':[],\n",
    "                'best_threshold':[],\n",
    "                'selected_features': []\n",
    "                }\n",
    "        results_val[i][selector] = {\n",
    "                'classifier': classifier,\n",
    "                'alpha': [],\n",
    "                'num_features': [],\n",
    "                'pr_auc': [],\n",
    "                'best_precision' :[],\n",
    "                'best_recall':[],\n",
    "                'roc_auc':[],\n",
    "                'f1':[],\n",
    "                'accuracy':[],\n",
    "                'confusion_matrix':[],\n",
    "                'best_threshold':[],\n",
    "                'selected_features': []\n",
    "                }\n",
    "\n",
    "\n",
    "        features=perform_correlation(features_train, y_train, 64, 0.85)\n",
    "\n",
    "        final_patients_train=remove_features_from_patients(features_train, features)\n",
    "        final_patients_test=remove_features_from_patients(features_test, features)\n",
    "        final_patients_val=remove_features_from_patients(features_val, features)\n",
    "\n",
    "        x_train_expanded, y_train_expanded, _ = continue_array(final_patients_train, y_train)\n",
    "\n",
    "        \n",
    "        if selector == 'lasso':\n",
    "                for alpha in alpha_values:\n",
    "                        if(classifier=='RandomForest'):\n",
    "                             classi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                        if(classifier=='Logistic'):\n",
    "                             classi = LogisticRegression()\n",
    "                        if(classifier=='SVM'):\n",
    "                             classi = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "                        if(classifier=='XgBoost'):\n",
    "                             classi = XGBClassifier()\n",
    "                        if(classifier=='MLP'):\n",
    "                             classi = MLPClassifier(hidden_layer_sizes=(128,64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n",
    "                        \n",
    "                        best_f1_score, best_precision, best_recall, conf, test_accuracy, precision, recall, pr_auc, roc_auc, bt, number_features, selected_features, classifier= classification_method1(\n",
    "                            selector, alpha, classi, x_train_expanded, y_train_expanded, \n",
    "                            patients_val, y_val, final_patients_val, 0\n",
    "                        )\n",
    "\n",
    "                        if(best_f1_score==0 and best_precision==0 and best_recall==0):\n",
    "                            break\n",
    "                    \n",
    "                        results_val[i][selector]['alpha'].append(alpha)\n",
    "                        results_val[i][selector]['selected_features'].append(selected_features)\n",
    "                        results_val[i][selector]['num_features'].append(number_features)\n",
    "                        results_val[i][selector]['pr_auc'].append(pr_auc)\n",
    "                        results_val[i][selector]['best_precision'].append(best_precision)\n",
    "                        results_val[i][selector]['best_recall'].append(best_recall)\n",
    "                        results_val[i][selector]['roc_auc'].append(roc_auc)\n",
    "                        results_val[i][selector]['f1'].append(best_f1_score)\n",
    "                        results_val[i][selector]['accuracy'].append(test_accuracy)\n",
    "                        results_val[i][selector]['confusion_matrix'].append(conf)\n",
    "                        results_val[i][selector]['best_threshold'].append(bt)\n",
    "\n",
    "                        ## classifico il test\n",
    "\n",
    "                        best_f1_score, best_precision, best_recall, conf, test_accuracy, precision, recall, pr_auc, roc_auc, bt, number_features, selected_features, _= classification_method1(\n",
    "                                    selector, alpha, classifier, x_train_expanded, y_train_expanded, \n",
    "                                    patients_test, y_test, final_patients_test, 0, bt, \"Test\", selected_features)\n",
    "                        \n",
    "                        \n",
    "                        results_test[i][selector]['alpha'].append(alpha)\n",
    "                        results_test[i][selector]['num_features'].append(number_features)\n",
    "                        results_test[i][selector]['selected_features'].append(selected_features)\n",
    "                        results_test[i][selector]['pr_auc'].append(pr_auc)\n",
    "                        results_test[i][selector]['best_precision'].append(best_precision)\n",
    "                        results_test[i][selector]['best_recall'].append(best_recall)\n",
    "                        results_test[i][selector]['roc_auc'].append(roc_auc)\n",
    "                        results_test[i][selector]['f1'].append(best_f1_score)\n",
    "                        results_test[i][selector]['accuracy'].append(test_accuracy)\n",
    "                        results_test[i][selector]['confusion_matrix'].append(conf)\n",
    "                        results_test[i][selector]['best_threshold'].append(bt)\n",
    "                        \n",
    "                        \n",
    "                        # Plot dei risultati per 'lasso'\n",
    "                        \n",
    "\n",
    "\n",
    "        else:\n",
    "                    for t in range(2, len(x_train_expanded[0])+1):\n",
    "\n",
    "                        if(classifier=='RandomForest'):\n",
    "                             classi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "                        if(classifier=='Logistic'):\n",
    "                             classi = LogisticRegression()\n",
    "                        if(classifier=='SVM'):\n",
    "                             classi = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "                        if(classifier=='XgBoost'):\n",
    "                             classi = XGBClassifier()\n",
    "                        if(classifier=='MLP'):\n",
    "                             classi = MLPClassifier(hidden_layer_sizes=(128,64, 32), max_iter=1000, random_state=42, early_stopping=True, learning_rate='adaptive')\n",
    "\n",
    "                        best_f1_score, best_precision, best_recall, conf, test_accuracy, precision, recall, pr_auc, roc_auc, bt, _, selected_features, classifier= classification_method1(\n",
    "                            selector, 0, classi, x_train_expanded, y_train_expanded, \n",
    "                            patients_val, y_val, final_patients_val, t\n",
    "                        )\n",
    "\n",
    "                        results_val[i][selector]['num_features'].append(t)\n",
    "                        results_val[i][selector]['pr_auc'].append(pr_auc)\n",
    "                        results_val[i][selector]['selected_features'].append(selected_features)\n",
    "                        results_val[i][selector]['best_precision'].append(best_precision)\n",
    "                        results_val[i][selector]['best_recall'].append(best_recall)\n",
    "                        results_val[i][selector]['roc_auc'].append(roc_auc)\n",
    "                        results_val[i][selector]['f1'].append(best_f1_score)\n",
    "                        results_val[i][selector]['accuracy'].append(test_accuracy)\n",
    "                        results_val[i][selector]['confusion_matrix'].append(conf)\n",
    "                        results_val[i][selector]['best_threshold'].append(bt)\n",
    "\n",
    "                        ## classifico test\n",
    "\n",
    "                        best_f1_score, best_precision, best_recall, conf, test_accuracy, precision, recall, pr_auc, roc_auc, bt, number_features, selected_features, _= classification_method1(\n",
    "                                    selector, 0, classifier, x_train_expanded, y_train_expanded, \n",
    "                                    patients_test, y_test, final_patients_test, t, bt, \"Test\", selected_features)\n",
    "                        \n",
    "                        \n",
    "                        results_test[i][selector]['num_features'].append(t)\n",
    "                        results_test[i][selector]['selected_features'].append(selected_features)\n",
    "                        results_test[i][selector]['pr_auc'].append(pr_auc)\n",
    "                        results_test[i][selector]['best_precision'].append(best_precision)\n",
    "                        results_test[i][selector]['best_recall'].append(best_recall)\n",
    "                        results_test[i][selector]['roc_auc'].append(roc_auc)\n",
    "                        results_test[i][selector]['f1'].append(best_f1_score)\n",
    "                        results_test[i][selector]['accuracy'].append(test_accuracy)\n",
    "                        results_test[i][selector]['confusion_matrix'].append(conf)\n",
    "                        results_test[i][selector]['best_threshold'].append(bt)\n",
    "\n",
    "\n",
    "        #mean_threshold, mean_param  = find_best_threshold_features(results_val[i], selector)\n",
    "        #print(f\"The mean best threshold for {selector} is: {mean_threshold}\")\n",
    "    \n",
    "        \n",
    "    i=i+1\n",
    "\n",
    "\n",
    " \n",
    "        #plot_results(results_rf, results_test_rf, selector)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definizione di colori diversi per ogni selettore\n",
    "colors = {\n",
    "    'lasso': 'blue',\n",
    "    'logistic': 'green',  # sostituire con il nome effettivo del selettore\n",
    "    'mrmr': 'red',    # sostituire con il nome effettivo del selettore\n",
    "    'rf': 'orange'\n",
    "    # aggiungere altri selettori se necessario\n",
    "}\n",
    "\n",
    "# Itera attraverso i classificatori e crea i grafici\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for selector in selectors:\n",
    "        \n",
    "        \n",
    "        \n",
    "        num_features = results_val[i][selector]['num_features']\n",
    "        pr_auc = results_val[i][selector]['pr_auc']\n",
    "\n",
    "        plt.plot(num_features, pr_auc, marker='o', label=selector, color=colors.get(selector, 'black'))\n",
    "\n",
    "    plt.title(f'Performance di PR AUC per il classificatore: {classifier}')\n",
    "    plt.xlabel('Numero di funzionalità')\n",
    "    plt.ylabel('PR AUC')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzazione delle variabili per memorizzare i migliori risultati\n",
    "best_f1 = -1\n",
    "best_pr_auc = -1\n",
    "best_roc_auc = -1\n",
    "best_accuracy = -1\n",
    "best_num_features = -1\n",
    "best_classifier = None\n",
    "best_selector = None\n",
    "\n",
    "# Funzione per confrontare i risultati\n",
    "def is_better(result, best_result):\n",
    "    if result['f1'] > best_result['f1']:\n",
    "        return True\n",
    "    elif result['f1'] == best_result['f1']:\n",
    "        if result['pr_auc'] > best_result['pr_auc']:\n",
    "            return True\n",
    "        elif result['pr_auc'] == best_result['pr_auc']:\n",
    "            if result['roc_auc'] > best_result['roc_auc']:\n",
    "                return True\n",
    "            elif result['roc_auc'] == best_result['roc_auc']:\n",
    "                if result['accuracy'] > best_result['accuracy']:\n",
    "                    return True\n",
    "                elif result['accuracy'] == best_result['accuracy']:\n",
    "                    if result['num_features'] > best_result['num_features']:\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "# Iterare attraverso i classificatori e i selettori\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    for selector in selectors:\n",
    "        num_results = len(results_val[i][selector]['f1'])\n",
    "        \n",
    "        for j in range(num_results):\n",
    "            current_result = {\n",
    "                'f1': results_val[i][selector]['f1'][j],\n",
    "                'pr_auc': results_val[i][selector]['pr_auc'][j],\n",
    "                'roc_auc': results_val[i][selector]['roc_auc'][j],\n",
    "                'accuracy': results_val[i][selector]['accuracy'][j],\n",
    "                'num_features': results_val[i][selector]['num_features'][j],\n",
    "            }\n",
    "            \n",
    "            best_result = {\n",
    "                'f1': best_f1,\n",
    "                'pr_auc': best_pr_auc,\n",
    "                'roc_auc': best_roc_auc,\n",
    "                'accuracy': best_accuracy,\n",
    "                'num_features': best_num_features,\n",
    "            }\n",
    "            \n",
    "            if is_better(current_result, best_result):\n",
    "                best_f1 = current_result['f1']\n",
    "                best_pr_auc = current_result['pr_auc']\n",
    "                best_roc_auc = current_result['roc_auc']\n",
    "                best_accuracy = current_result['accuracy']\n",
    "                best_num_features = current_result['num_features']\n",
    "                best_classifier = classifier\n",
    "                best_selector = selector\n",
    "\n",
    "print(f\"Il miglior classificatore è: {best_classifier}\")\n",
    "print(f\"Il miglior selector è: {best_selector}\")\n",
    "print(f\"F1 score: {best_f1}\")\n",
    "print(f\"PR AUC: {best_pr_auc}\")\n",
    "print(f\"ROC AUC: {best_roc_auc}\")\n",
    "print(f\"Accuracy: {best_accuracy}\")\n",
    "print(f\"Numero di features: {best_num_features}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
